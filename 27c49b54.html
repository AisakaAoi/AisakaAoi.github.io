<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><meta name="baidu-site-verification" content="code-KCMz4b3cnd"><meta name="google-site-verification" content="MTp8U7dJ1uzrfz8Mu6rgqX1CIm3HjqPWd0xaRcv1tFg"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png"><link rel="mask-icon" href="/images/favicon.png" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"example.com",root:"/",scheme:"Pisces",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta property="og:type" content="article"><meta property="og:title" content="前沿改进-高效卷积神经网络设计，AugShuffleNet: Communicate More, Compute Less"><meta property="og:url" content="http://example.com/27c49b54.html"><meta property="og:site_name" content="逢坂葵的个人博客"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://example.com/27c49b54/1.png"><meta property="og:image" content="http://example.com/27c49b54/2.webp"><meta property="og:image" content="http://example.com/27c49b54/3.webp"><meta property="og:image" content="http://example.com/27c49b54/4.webp"><meta property="og:image" content="http://example.com/27c49b54/5.png"><meta property="og:image" content="http://example.com/27c49b54/6.webp"><meta property="og:image" content="http://example.com/27c49b54/7.png"><meta property="og:image" content="http://example.com/27c49b54/8.png"><meta property="og:image" content="http://example.com/27c49b54/9.png"><meta property="og:image" content="http://example.com/27c49b54/10.webp"><meta property="og:image" content="http://example.com/27c49b54/11.png"><meta property="article:published_time" content="2023-06-02T19:49:32.000Z"><meta property="article:modified_time" content="2023-06-07T23:45:29.446Z"><meta property="article:author" content="Aisaka Aoi"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="http://example.com/27c49b54/1.png"><link rel="canonical" href="http://example.com/27c49b54.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>前沿改进-高效卷积神经网络设计，AugShuffleNet: Communicate More, Compute Less | 逢坂葵的个人博客</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?7308ed05421777c301eefa3754da1b42",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="逢坂葵的个人博客" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">逢坂葵葵</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">Aisaka's Blog</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">52</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">509</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div><a href="https://github.com/AisakaAoi" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://example.com/27c49b54.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/manatsu.jpg"><meta itemprop="name" content="Aisaka Aoi"><meta itemprop="description" content="Aisaka's Blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="逢坂葵的个人博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">前沿改进-高效卷积神经网络设计，AugShuffleNet: Communicate More, Compute Less</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-06-03 03:49:32" itemprop="dateCreated datePublished" datetime="2023-06-03T03:49:32+08:00">2023-06-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">🌙进阶学习</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">⭐人工智能 Artificial Intelligence</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-Artificial-Intelligence/%F0%9F%92%AB%E5%89%8D%E6%B2%BF%E6%94%B9%E8%BF%9B-Frontier-Improvement/" itemprop="url" rel="index"><span itemprop="name">💫前沿改进 Frontier Improvement</span></a> </span></span><span id="/27c49b54.html" class="post-meta-item leancloud_visitors" data-flag-title="前沿改进-高效卷积神经网络设计，AugShuffleNet: Communicate More, Compute Less" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/27c49b54.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/27c49b54.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>9.5k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>24 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><img src="/27c49b54/1.png"> <span id="more"></span><h3 id="背景和动机"><a href="#背景和动机" class="headerlink" title="背景和动机"></a>背景和动机</h3><p>ShuffleNetV2是轻量级模型领域中的一个经典案例， 提供了许多实用的轻量化设计指导原则和分析方法。此外，它创造了一种新的轻量级模块设计范式，使得模型能够<strong>不依赖“残差连接”</strong>训练深度网络，也能达到高效和高性能的效果。</p><p>本文主要介绍 ShuffeNetV2 的加强版本 - <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.06589">AugShuffleNet</a></p><p>内容包括：</p><ol><li>分析ShuffleNetv2模型的基本模块Shuffle Block 的设计优点: partial computation和 efficient short paths。</li><li>分析Shuffle Block设计的局限性：a.计算开销和冗余控制能力弱；b.模块中间层的信息浪费。</li></ol><p>AugShuffleNet继承了 ShuffleNetV2的设计优点，通过分析后者的设计缺陷并提出了非常简单的改良方案：</p><ol><li>通过引入split ratio控制计算开销和冗余：压缩Shuffle Block模块前两层卷积的宽度以提高模型效率（计算开销和访存）。</li><li>将第二层的输出通道特征和模块的保留特征进行交换：充分利用中间层的信息避免浪费的可能性，并促进跨层信息混合以提高模型性能。</li></ol><p>在cifar10和cifar100的数据集上，AugShuffleNet可以在不改变网络架构的情况下，在计算量、参数量、推理延时和分类准确率方面都超过ShuffleNetV2。并且，在网络宽度因子为1.5时，AugShuffleNet可以将split ratio降到0.125（降低局部网络宽度）, 即高度压榨模型效率的情况下，仍然能保持对ShuffleNetV2的性能优势。</p><hr><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>本节主要分析：</p><ol><li><strong>通道全连接结构和通道冗余问题</strong></li><li><strong>Shuffle Block的设计优点和缺陷，并理论解释了缺陷来源</strong></li><li><strong>提出Shuffle Block改良版本, Augmented Shuffle Block</strong></li></ol><hr><h4 id="通道全连接和通道冗余"><a href="#通道全连接和通道冗余" class="headerlink" title="通道全连接和通道冗余"></a>通道全连接和通道冗余</h4><p>如图1左所示，标准卷积在通道维度上存在全连接结构（<strong>channel-wise fully connected structure</strong>），在网络较宽时容易造成通道冗余(<strong>channel-wise redundancy</strong>)，进而带来不必要的计算开销，拖慢模型训练和推理速度。</p><p>而许多稀疏化设计方法和压缩算法之所以奏效，本质还是缓解了高维度下（网络太宽，通道数太多）通道全连接结构带来的通道冗余。即使是先进的SOTA大模型都存在相同的问题，在加宽网络时也忽略了通道冗余的存在，因而只能做到部分指标的trade-off，而无法做到全部指标的提升。</p><img src="/27c49b54/2.webp"><div align="center">图1</div><hr><h4 id="Shuffle-Block"><a href="#Shuffle-Block" class="headerlink" title="Shuffle Block"></a>Shuffle Block</h4><p>由于实验设备资源限制，本文将聚焦轻量化模型ShuffleNetV2，借此揭示通道冗余带来的问题。</p><img src="/27c49b54/3.webp"><div align="center">图2 ShuffleNetV1和ShuffleNetV2 模块比较</div><p>如图2, 在模块设计方面来看，ShuffleNetV2的模块Shuffle Block可以看作是ShuffleNetV1模块的一种特殊情况：即进行分组卷积（分组数为2）时，一组保留特征不做计算，另一组进行卷积，并改变了channnel shuffle的位置。</p><img src="/27c49b54/4.webp"><div align="center">图3</div><p>图3左展示了ShuffleNetV2模块的通道示意图，该模块的优点是：</p><ol><li><strong>Partial computation</strong>： 采用了 <strong>channel spit</strong> ，只对输入通道进行部分计算, 可以节省计算开销和访存。</li><li><strong>Short Paths</strong>：利用 Partial computation的结构特点，使用 <strong>channel split</strong> 和 <strong>channel shuffle</strong> 操作相互配合，使得浅层的特征能够有周期规律地混入网络的更深层（ShuffleNetV2原文提到这是特征重用，类似DenseNet. 我更倾向于叫它特征延迟使用，因为它实际上并没有真正地重复使用浅层特征）。与UNET、ResNet和DenseNet等模型类似，这可以保证模型能够不依赖残差连接，也能为网络引入优化过程中的<strong>短路径（short paths）</strong>，降低优化难度，并提升模型性性能。顺便一提，残差的输入是2个张量，输出是一个张量，条件相同情况下其访存成本比卷积层还高，残差连接数量过多会影响模型推理延时。</li></ol><p>下面分析其模块缺点：</p><ol><li>计算开销和冗余的控制能力很弱。因为模块中3层卷积都要求保持输入输出通道数量相等。用宽度因子粗暴地加宽网络时，Shuffle Block模块计算分支容易产生通道冗余。</li><li>中间信息层信息没有被有效利用。后一层如果只需要少许中间层的通道信息，那么其他通道可能就被浪费。尽管模块只有3层，但是整个网络有十几个模块，浪费是相当可观的。此外，万一在反向传播中梯度陷入了中间某一层，就相当于无效学习了。这可以看作是沿着网络深度方向的“冗余风险”。</li></ol><p>下面会更加详细地理论分析Shuffle Block的通道冗余。冗余来自于不合理的计算分支的设计。</p><img src="/27c49b54/5.png"><div align="center">图4 ShuffleNetV2 Shuffle Block计算分支的通道依赖图</div><p>如图4,其计算分支有3个卷积：1×1 regular convolution, 3×3 depth-wise convolution, 1×1 regualr convolution。 而且，三层卷积的输入和输出通道数量被强制要保持相当。这实际上是不合理的设计原则，也是ShuffleNetV2冗余的导火索。如图4，<strong>由于模块中首尾两个标准卷积存在通道全连接结构（depth-wise convolution相当于通道上一对一的scale因子，可忽略），这个规定会放大整个模块的通道冗余，在加宽网络时尤为严重。</strong></p><hr><h3 id="Augmented-Shuffle-Block"><a href="#Augmented-Shuffle-Block" class="headerlink" title="Augmented Shuffle Block"></a>Augmented Shuffle Block</h3><img src="/27c49b54/6.webp"><div align="center">图3</div><p>为解决上述问题，AugShufleNet提出了改良版本的Shuffle Block，如上图右（免得翻页，文章重复插入图片一遍，其改进点如下：</p><ol><li>将channel split 的分割率split ratio(小于0.5)设置为变量而不是0.5,这可以灵活调整模块的计算开销，控制计算冗余。具体地，split ratio控制模块前两层卷积（ 1×1 convolution 和 3×3 depth-wise convolution）的宽度，前两层的输入和输出通道数量保持相等。减少 r 值，可以按照比例减少整整两层的计算开销和访存成本，用来提升模型效率（包括计算量参数量，计算量，训练和推理延时）。</li><li>在depth-wise convolution之后引入channel crossover, 将输出特征和模块输入保留的特征通道交叉互换一半。这样一来，第三层 1×1 convolution的输入通道其实正好等于整个模块输入通道数量的一半。因此，改良的模块就不需要修改架构参数来构建模型，从而和原始ShuffleNetV2模型进行公平的比较。</li><li>去除第一层卷积的激活函数，节省了整整一层的计算时间和访存时间，这可以进一步加速训练和推理。</li></ol><p>可以看到，该模块通过调整 split ratio可以控制冗余（起到”通道降维”作用），配合channel crossover（起到”通道升维”和交换信息的作用），整个模块计算分支呈现BottleNeck结构。</p><p>值得一提的是，这种通道维度的“升降”不像其他BottleNeck变种一样依赖两个 1×1 convolution。如上文所述，连续的 1×1 convolution在通道上是全连接结构，前一层的输出通道数量等于后一层的输入数量，网络达到一定宽度时，不可避免产生通道冗余，这不利于灵活控制计算开销和冗余。</p><p>本文的模块中所谓的“升维”其实和特征重用Concat没什么区别，只是顺便交换了信息, 和channel-split配合之下（只取局部通道进行计算）产生的BottleNeck结构是可以比其他BottleNeck结构更能灵活控制计算开销和冗余。此外，channel crossover也充分利用了中间层的信息，使其部分特征也能流入到更深层的网络。</p><p>因此在各种操作配合下，该模块能更加灵活控制地控制计算开销，提升模型效率，并利用特征跨层混合的优势提高模型性能。</p><hr><h4 id="模块理论效率分析"><a href="#模块理论效率分析" class="headerlink" title="模块理论效率分析"></a>模块理论效率分析</h4><img src="/27c49b54/7.png"><div align="center">图5 模块效率分析</div><p>图5分析了改良模块相对于原始 Shuffle Block 的效率（计算量和参数量）。总而言之，channel split 的通道分割率 r，决定了效率, r 越小，其效率就比原始 Shuffle Block 更高。</p><p>文中暂时没有给出延时的分析，实际上也是差不多的。由于split ratio小于0.5（本文实验默认是0.375，也做了split ratio为0.25和0.125的实验）, 改良模块前两层卷积 1×1 convolution 和 3×3 depth-wise convolution输入和输出通道数量保持相等，同时受到split ratio控制，再加上额外消除了一个ReLU激活函数。这些都是对推理速度的正面作用。而channel crossover作为负面作用会增加一点延时，但是相比于节省下来的两层卷积和一层激活函数的计算时间和访存时间是更小的，所以绝大多数情况下可以保证改良模块的训练和推理速度更快。（之所以不能绝对保证是因为可以设定一些极端的条件，比如模型宽度本身很小，只有几个通道，而计算单元性能又超级高，那就有可能导致channel crossover引入的延时高于节省下来的延时）。</p><hr><h3 id="网络架构和实验结果"><a href="#网络架构和实验结果" class="headerlink" title="网络架构和实验结果"></a>网络架构和实验结果</h3><p>上文分析了效率优势，那么模型性能又如何呢？</p><p>在修改的模块中其实存在两种设计因素的博弈。split ratio的引入迫使模块中前两层卷积比原始Shuffle Block更窄，虽然能提升效率但也会造成性能损失（在冗余比较大的情况下，性能损失可能比较小）。channel crossover交换信息，能提升模型性能。因此，模型最终效果还取决于网络宽度因子和通道分割率（split ratio）。</p><p>实验表明，Cifar10和Cifar100上，AugShuffleNet模型性能和效率都优于ShuffleNetV2。</p><p>其架构参数参照了ShuffleNetV2。如图6，0.5和1.5宽度因子下，通道数量和ShuffleNetV2相等，这是指整个模块的输入输出相等，而模块内部我们实际使用了更窄的网络。1.0宽度因子的网络通道数量比ShuffleNetV2增加了一点，这是考虑到shufflenetv2原始的通道数量乘以通道分割率不是整数。</p><p>默认情况下，分割率为0.375，改良模块会代替原始ShuffleNetV2中Stage3和Stage4中不包括下采样的Shuffle Block，替代了10个模块，所以在计算量，参数量和延时方面的改善是相当可观的。Stage2不替换是因为浅层通道特征很重要，破坏了伤害模型表现，通道数量太少，替换了又提升不了多少效率，换了得不偿失。</p><img src="/27c49b54/8.png"><div align="center">图6 网络架构</div><img src="/27c49b54/9.png"><div align="center">图7 分类效果</div><p>AugShuffleNet各种指标都超过ShuffleNetV2, 延时暂时没给结果，笔记本电脑上实际测试还是更快的。</p><hr><h4 id="测试Split-ratio对模型的影响"><a href="#测试Split-ratio对模型的影响" class="headerlink" title="测试Split ratio对模型的影响"></a>测试Split ratio对模型的影响</h4><img src="/27c49b54/10.webp"><div align="center">图8</div><img src="/27c49b54/11.png"><div align="center">图9</div><p>如图8和9所示, 我们基于AugShuffleNet 1.5x 继续降低split ratio和ShuffleNetV2进行比较。这本质是在证明ShuffleNetV2的冗余性。实验设置了0.375, 0.25, 0.125三种slit ratio参数，数值越小，AugShuffleNet就被压缩得越狠 。</p><p>可以看到，在通过split ratio压缩模型的情况下，AugShuffleNet的效率和性能优势仍在，这说明ShufffleNetV2 1.5x 确实存在比较多的冗余。</p><p>即使在分割率最小为0.125（蓝线最左边那个数据点）的情况下，AugShuffleNet 1.5x cifar10和cifar100上准确率仍能领先ShuffleNetV2 1.5x 0.29%和0.91%。cifar10上，前者的计算量和参数量仅为后者的79.6%和76.7%；cifar100上，前者的计算量和参数量则是后者的79.6%和77.9%。</p><p>还没测延时，因为AugShuffleNet 1.5x分割率0.125很低，相对于0.5分割率 的ShuffleNetV2 1.5x,可以改善20多层卷积的计算时间和访存时间，外加10层激活函数的时间。所以可以肯定, AugShuffleNet训练和推理速度会更快。</p><hr><h3 id="结论和思考"><a href="#结论和思考" class="headerlink" title="结论和思考"></a>结论和思考</h3><p>本文的设计策略很简单，即通过通道分割率 r 调节计算开销和控制冗余，提升模型效率；中间层信息的交换促进了跨层信息的混合，提升模型性能。总的来说，AugShuffleNet 改良的模块可以比 ShuffleNetV2 的 Shuffle Block 更具有优势。</p><p>但是这种优势是在特殊的情况下才成立的，即模型规模相对于数据任务一定要达到一定程度的“大”。这种大不是指模型相对于数据集达到了过拟合的那种，而是“大”到模型达到能产生“冗余”和浪费的程度。即使看上去很小的模型也能达到这种冗余程度，这取决于模型规模和数据集规模（或者任务难度）的相对程度。这种相对程度更“大”则 AugShuffleNet 的优势会更加明显，反之优势则不明显，极端情况下优势甚至不存在。</p><p>举个例子，我在 imagenet 上实现了 AugShuffleNet 1.0x 和 ShuffleNetV2 1.0x 的比较（由于 batch size 不同，没有 复现好 shuffleNetV2 的准确率，但是不影响推断），由于模型宽度很小，表示能力相对大规模数据集非常有限。AugShuffleNet 只能在分割率为 0.45 的情况下，在推理速度和准确率有一点优势，计算量和参数量则会超出少许（计算量貌似是 5M 以下，参数量也比较少），但是相对于 ShuffleNetV2 的优势就没这么明显了。而且，这种情况下 ShuffleNetV2 自身微调一下宽度和深度也是大概率能改善一点点指标的，毕竟 random seed 的影响是如此之大。</p><p>如果增加模型宽度，优势大概率会显现出来。上述观点也能从 cifar10 和 cifar100 的实验中得到支持：</p><ol><li>网络宽度因子从 1.5, 1.0 和 0.5 依次下降的时候，AugShuffleNet 相对于 ShuffleNetV2 的优势差距在逐渐下降。如果宽度因子继续减少，例如变成 0.125（这个数字不太合理，导致分割通道很难是整数，但是只是用来代表很窄的网络），很有可能就不能保持全面的效率和性能优势了。</li><li>在网络宽度因子设置为 1.5x 时候，两个网络都足够宽，对 cifar10 和 cifar100 都达到了前面所说的“模型相对数据集足够的大”。split ratio 为 0.125 的时候，可以把 AugShuffleNet 1.5x 的计算开销大幅度压缩，在准确率上却仍然能保持对 ShufflenetV2 的些微优势。由于两个模型架构相同，这也侧面说明 ShuffleNetV2 1.5x 已经产生了冗余，这个冗余来自不合理的结构设计和不灵活的开销控制。</li></ol><hr><h3 id="设计原则总结"><a href="#设计原则总结" class="headerlink" title="设计原则总结"></a>设计原则总结</h3><p>除了工程trick，本文大概也暗示了一些通用的设计原则（同时适用CPU和GPU上的模型设计）：</p><ol><li>加宽网络（高维度）时，标准卷积的通道全连接结构会容易造成通道冗余，尽可能规避这种情况。</li><li>鼓励用split ratio灵活控制计算开销和冗余。前一层的输出通道数量等于后一层的输入通道数量，这种规定限制了设计的灵活性。另外尽可能在网络深层（通道数量较多）使用。通道数量很少时，split ratio不但节省不了多少开销，还会伤害模型性能。</li><li>合理利用跨层信息的混合来提升模型性能。</li><li>重视残差的访存开销，有两种比较高效率的方案：<ul><li>和ShuffleNtV2一样利用channel split 和shuffle, shuffle可以考虑换成channel shift</li><li>利用dirac conv, 把残差藏进卷积核中</li></ul></li></ol><hr><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>改良的 Shuffle Block 代码如下(代码不太规范，推理速度可能可以继续优化，pytorch 现在自带 channel shuffle 了)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ShuffleBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, groups=<span class="number">4</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ShuffleBlock, self).__init__()</span><br><span class="line">        self.groups = groups</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;Channel shuffle: [N,C,H,W] -&gt; [N,g,C/g,H,W] -&gt; [N,C/g,g,H,w] -&gt; [N,C,H,W]&#x27;&#x27;&#x27;</span></span><br><span class="line">        N, C, H, W = x.size()</span><br><span class="line">        g = self.groups</span><br><span class="line">        <span class="keyword">return</span> x.view(N, g, C//g, H, W).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>).reshape(N, C, H, W)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SplitBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ratio=(<span class="params"><span class="number">3</span>/<span class="number">8</span></span>)</span>):</span><br><span class="line">        <span class="built_in">super</span>(SplitBlock, self).__init__()</span><br><span class="line">        self.ratio = ratio</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment">## AugshuffleNet的分割方式，为了实现channel crossover,输入通道提前被分割成3份。</span></span><br><span class="line">        <span class="keyword">if</span> self.ratio != <span class="number">0.5</span>:</span><br><span class="line"></span><br><span class="line">           c = x.size(<span class="number">1</span>)</span><br><span class="line">           c1 = <span class="built_in">int</span>(c * self.ratio)</span><br><span class="line">           c2 = c3 = <span class="built_in">int</span>(c * ((<span class="number">1</span>-self.ratio)/<span class="number">2</span>))</span><br><span class="line">        </span><br><span class="line">           out = torch.split(x, [c1,c2,c3], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">## ShuffleNetV2的分割方式，分成两半</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">             out = torch.chunk(x, <span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, split_ratio=(<span class="params"><span class="number">3</span>/<span class="number">8</span></span>)</span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line">        self.split_ratio = split_ratio</span><br><span class="line">        self.split = SplitBlock(split_ratio)</span><br><span class="line">        cin = <span class="built_in">int</span>(in_channels * split_ratio)</span><br><span class="line"></span><br><span class="line">        self.conv0 = nn.Conv2d(cin, cin,kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn0 = nn.BatchNorm2d(cin)</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(cin, cin,</span><br><span class="line">                               kernel_size = <span class="number">3</span>,</span><br><span class="line">                               stride = <span class="number">1</span>,</span><br><span class="line">                               padding= <span class="number">1</span>,</span><br><span class="line">                               groups = cin,</span><br><span class="line">                               bias = <span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(cin)</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="built_in">int</span>(<span class="number">0.5</span>*in_channels),<span class="built_in">int</span>(<span class="number">0.5</span>*in_channels),kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(<span class="built_in">int</span>(<span class="number">0.5</span>*in_channels))</span><br><span class="line">        self.shuffle = ShuffleBlock(<span class="number">4</span>) <span class="keyword">if</span> split ratio&lt;<span class="number">0.5</span> <span class="keyword">else</span> ShuffleBlock(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment">## Augmented Shuffle Block in AugShuffleNet</span></span><br><span class="line">        <span class="keyword">if</span> self.split_ratio != <span class="number">0.5</span>:</span><br><span class="line">            <span class="keyword">assert</span> self.split_ratio &lt; <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">            x1, x2, x3 = self.split(x)</span><br><span class="line">            out = self.bn0(self.conv0(x1))</span><br><span class="line"></span><br><span class="line">            out = self.bn1(self.conv1(out))</span><br><span class="line">            c1,c2 = torch.chunk(out,<span class="number">2</span>,<span class="number">1</span>) </span><br><span class="line">            out = torch.cat([c2, x2], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            out = F.relu(self.bn2(self.conv2(out)))</span><br><span class="line">            out = torch.cat([out,x3,c1],dim=<span class="number">1</span>)</span><br><span class="line">            out = self.shuffle(out)</span><br><span class="line"></span><br><span class="line">        <span class="comment">## Shuffle Block in ShuffleNetV2</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            x1, x2 = self.split(x)</span><br><span class="line">            out = F.relu(self.bn0(self.conv0(x1)))</span><br><span class="line">            out = self.bn1(self.conv1(out))</span><br><span class="line"></span><br><span class="line">            out = F.relu(self.bn2(self.conv2(out)))</span><br><span class="line">            out = torch.cat([out,x2],dim=<span class="number">1</span>)</span><br><span class="line">            out = self.shuffle(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><hr><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/614027115">https://zhuanlan.zhihu.com/p/614027115</a></p></blockquote></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-item"><a href="/fc667301.html" rel="prev" title="机器学习-学好机器学习需要哪些数学知识？"><i class="fa fa-chevron-left"></i> 机器学习-学好机器学习需要哪些数学知识？</a></div><div class="post-nav-item"><a href="/1f9c90df.html" rel="next" title="前沿改进-ReduceNet: 按照VanillaNet的方式极限压缩网络深度至单层（有修改见最新ReduceNet）">前沿改进-ReduceNet: 按照VanillaNet的方式极限压缩网络深度至单层（有修改见最新ReduceNet） <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let t=CONFIG.comments["activeClass"];var e;(t=CONFIG.comments.storage?localStorage.getItem("comments_active")||t:t)&&(e=document.querySelector(`a[href="#comment-${t}"]`))&&e.click()}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%83%8C%E6%99%AF%E5%92%8C%E5%8A%A8%E6%9C%BA"><span class="nav-number">1.</span> <span class="nav-text">背景和动机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-number">2.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%9A%E9%81%93%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%92%8C%E9%80%9A%E9%81%93%E5%86%97%E4%BD%99"><span class="nav-number">2.1.</span> <span class="nav-text">通道全连接和通道冗余</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Shuffle-Block"><span class="nav-number">2.2.</span> <span class="nav-text">Shuffle Block</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Augmented-Shuffle-Block"><span class="nav-number">3.</span> <span class="nav-text">Augmented Shuffle Block</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9D%97%E7%90%86%E8%AE%BA%E6%95%88%E7%8E%87%E5%88%86%E6%9E%90"><span class="nav-number">3.1.</span> <span class="nav-text">模块理论效率分析</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%92%8C%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-number">4.</span> <span class="nav-text">网络架构和实验结果</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95Split-ratio%E5%AF%B9%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="nav-number">4.1.</span> <span class="nav-text">测试Split ratio对模型的影响</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%93%E8%AE%BA%E5%92%8C%E6%80%9D%E8%80%83"><span class="nav-number">5.</span> <span class="nav-text">结论和思考</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%E6%80%BB%E7%BB%93"><span class="nav-number">6.</span> <span class="nav-text">设计原则总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">7.</span> <span class="nav-text">代码实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">8.</span> <span class="nav-text">参考资料</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Aisaka Aoi" src="/images/manatsu.jpg"><p class="site-author-name" itemprop="name">Aisaka Aoi</p><div class="site-description" itemprop="description">逢坂葵的个人博客</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">509</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">52</span> <span class="site-state-item-name">分类</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/AisakaAoi" title="GitHub 👨‍💻 → https:&#x2F;&#x2F;github.com&#x2F;AisakaAoi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👨‍💻</a> </span><span class="links-of-author-item"><a href="https://github.com/AisakaManatsu" title="GitHub 👩‍💻 → https:&#x2F;&#x2F;github.com&#x2F;AisakaManatsu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👩‍💻</a> </span><span class="links-of-author-item"><a href="mailto:chenzongnan@m.scnu.edu.cn" title="E-Mail 🏫 → mailto:chenzongnan@m.scnu.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 🏫</a> </span><span class="links-of-author-item"><a href="mailto:aisakaaoi@qq.com" title="E-Mail 📧 → mailto:aisakaaoi@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 📧</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/91560309" title="Bilibili 📺 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;91560309" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 📺</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/198562921" title="Bilibili 🎮 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;198562921" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 🎮</a> </span><span class="links-of-author-item"><a href="https://www.youtube.com/channel/UCALvyn5Cl76GCotO9pczvjg" title="YouTube 📺 → https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCALvyn5Cl76GCotO9pczvjg" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube 📺</a></span></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Aisaka Aoi</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">1.6m</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">65:52</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll(".pdfobject-container").forEach(e=>{var t=e.dataset.target,a="#"+Object.entries({navpanes:0,toolbar:0,statusbar:0,pagemode:"thumbs",view:"FitH"}).map(([e,t])=>e+"="+encodeURIComponent(t)).join("&"),r="/lib/pdf/web/viewer.html?file="+encodeURIComponent(t)+a;NexT.utils.supportsPDFs()?e.innerHTML=`<embed class="pdfobject" src="${t+a}" type="application/pdf" style="height: ${e.dataset.height};">`:e.innerHTML=`<iframe src="${r}" style="height: ${e.dataset.height};" frameborder="0"></iframe>`})</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//unpkg.com/valine/dist/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!0,notify:!0,appId:"UqjWdRYbIUEUQRXhBUUIh1QE-gzGzoHsz",appKey:"gj89JXC485PFbpdHLKVkz6dm",placeholder:"这里可以发送评论~（上面可以输入昵称、邮箱）",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script></body></html>