<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><meta name="baidu-site-verification" content="code-KCMz4b3cnd"><meta name="google-site-verification" content="MTp8U7dJ1uzrfz8Mu6rgqX1CIm3HjqPWd0xaRcv1tFg"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png"><link rel="mask-icon" href="/images/favicon.png" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"aisakaaoi.github.io",root:"/",scheme:"Pisces",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="该论文发表于Information Fusion（中科院1区，IF&#x3D;14.7），题目为《Identifying the Hierarchical Emotional Areas in the Human Brain Through Information Fusion》。 中国科学院自动化研究所多模态人工智能系统国家重点实验室脑图谱与类脑智能组的黄中昱为此文第一作者，何晖光教授为此文"><meta property="og:type" content="article"><meta property="og:title" content="INFORM FUSION | 使用信息融合识别人脑的层次情绪区域"><meta property="og:url" content="https://aisakaaoi.github.io/e32de4c6.html"><meta property="og:site_name" content="逢坂葵的个人博客"><meta property="og:description" content="该论文发表于Information Fusion（中科院1区，IF&#x3D;14.7），题目为《Identifying the Hierarchical Emotional Areas in the Human Brain Through Information Fusion》。 中国科学院自动化研究所多模态人工智能系统国家重点实验室脑图谱与类脑智能组的黄中昱为此文第一作者，何晖光教授为此文"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/1.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/2.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/3.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/4.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/5.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/6.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/7.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/8.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/9.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/10.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/11.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/12.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/13.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/14.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/15.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/16.webp"><meta property="og:image" content="https://aisakaaoi.github.io/e32de4c6/17.webp"><meta property="article:published_time" content="2024-11-03T20:58:30.000Z"><meta property="article:modified_time" content="2026-01-23T11:02:53.755Z"><meta property="article:author" content="Aisaka Aoi"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://aisakaaoi.github.io/e32de4c6/1.webp"><link rel="canonical" href="https://aisakaaoi.github.io/e32de4c6.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>INFORM FUSION | 使用信息融合识别人脑的层次情绪区域 | 逢坂葵的个人博客</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?7308ed05421777c301eefa3754da1b42",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="逢坂葵的个人博客" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">aoi学院</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">Aisaka's Blog, School of Aoi, Aisaka University</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">20</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">1020</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div><a href="https://github.com/AisakaAoi" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://aisakaaoi.github.io/e32de4c6.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/manatsu.jpg"><meta itemprop="name" content="Aisaka Aoi"><meta itemprop="description" content="Aisaka's Blog, School of Aoi, Aisaka University"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="逢坂葵的个人博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">INFORM FUSION | 使用信息融合识别人脑的层次情绪区域</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2024-11-04 04:58:30" itemprop="dateCreated datePublished" datetime="2024-11-04T04:58:30+08:00">2024-11-04</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">🌙进阶学习</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%A0%94%E7%A9%B6%E5%9B%A2%E9%98%9F%EF%BC%88BCI%E5%9B%A2%E9%98%9F%EF%BC%89/" itemprop="url" rel="index"><span itemprop="name">⭐脑机接口与混合智能研究团队（BCI团队）</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%A0%94%E7%A9%B6%E5%9B%A2%E9%98%9F%EF%BC%88BCI%E5%9B%A2%E9%98%9F%EF%BC%89/%F0%9F%92%AB%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/" itemprop="url" rel="index"><span itemprop="name">💫学习报告</span></a> </span></span><span id="/e32de4c6.html" class="post-meta-item leancloud_visitors" data-flag-title="INFORM FUSION | 使用信息融合识别人脑的层次情绪区域" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/e32de4c6.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/e32de4c6.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>4.5k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>11 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><img src="/e32de4c6/1.webp"><p>该论文发表于Information Fusion（中科院1区，IF&#x3D;14.7），题目为《Identifying the Hierarchical Emotional Areas in the Human Brain Through Information Fusion》。</p><p>中国科学院自动化研究所多模态人工智能系统国家重点实验室脑图谱与类脑智能组的黄中昱为此文第一作者，何晖光教授为此文的通讯作者。</p><p>论文链接：<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S1566253524003919">https://www.sciencedirect.com/science/article/pii/S1566253524003919</a></p><span id="more"></span><hr><h3 id="论文概要"><a href="#论文概要" class="headerlink" title="论文概要"></a>论文概要</h3><p>以往的研究中对于大脑区域之间的关系采用的方法通常只模拟两个大脑区域之间的成对关系，而忽略了多个大脑区域之间的相互作用和信息融合——这是心理建构主义假说的关键思想之一。为了研究情绪背后的大脑机制（即情绪编码），作者首先测量和收集受试者在经历视听多源情绪刺激时的大脑信号，利用收集到的fMRI信号构建一个大脑网络，并从这个大脑网络中提取一棵大脑树。然后，将整个大脑树分解为不同级别的主干（即分层主干），每个主干促进大脑区域之间的信息融合。在分解之后将脑树中的这些分层主干恢复到人脑中的分层情绪区域，完成给定数据集上分层情绪区域的识别。最后，使用所提出的模型HemoN（建立在前述识别的分层情绪区域上），在其他具有挑战性的数据集上执行跨数据集情绪解码。结果表明，所识别的分层情绪区域，从较低到较高，主要促进情绪感知的基本过程、基本心理操作的构建以及这些操作的协调和整合。总的来说，作者的发现为基于心理建构主义假设的特定情绪背后的大脑机制提供了独特的见解。模型整体实现如下图所示：</p><img src="/e32de4c6/2.webp"><div align="center">图1 识别人脑层次情绪区域的流程图</div><hr><h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>关于情绪的脑基础和神经表征的研究主要集中在两种假说上：位置主义论和心理建构论。位置主义论表明，离散的情绪类别一致且具体地对应于不同的大脑区域，这意味着大脑区域和情绪类别之间存在一对一的映射。相反，心理建构主义论认为，离散的情绪类别是从更一般的大脑网络中构建的，即不同大脑区域之间的相互作用，而不是特定的大脑区域。虽然这两个假设的时代相同，但支持位置主义假设的证据相对较少。相比之下，大量研究表明情绪的神经表征是分布式的，从而得出结论，心理建构主义假说在揭示情绪的大脑基础方面具有更大的潜力。</p><hr><h3 id="方法分析"><a href="#方法分析" class="headerlink" title="方法分析"></a>方法分析</h3><h4 id="通过使用收集到的fMRI信号构建一个大脑网络"><a href="#通过使用收集到的fMRI信号构建一个大脑网络" class="headerlink" title="通过使用收集到的fMRI信号构建一个大脑网络"></a>通过使用收集到的fMRI信号构建一个大脑网络</h4><p>在这个网络中，节点被定义为感兴趣的大脑区域（regions of interest , ROIs），通常来自现有的大脑分割，如Power Atlas。边被定义为这些ROI之间的功能连接，通常被计算为两个ROI之间的fMRI时间序列的成对相关性。然而，传统的大脑网络可能会受到各种限制，如阈值问题、虚假和噪声连接、缩放效应和方法偏差。而解决这些问题的一个有效的方法就是生成树算法（spanning tree algorithm）。具体来说，对于目标大脑网络，首先根据权重对所有边进行降序排序。从使用权重最高的边开始，从剩余边中选择权重最高的边。如果新选择的边与先前选择的边形成循环，则丢弃；否则，将其添加到大脑树中。迭代上述过程，直到在脑树中存在NG-1条边。最后，将脑树中的所有边权重设置为值1。这样，作者便将脑网络G&#x3D;（V，E）转化为脑树T&#x3D;（V，R），其中，表示T的顶点集，与G的顶点集相同，而R表示T的边集。</p><hr><h4 id="理论分析：脑树中的相互作用和信息融合"><a href="#理论分析：脑树中的相互作用和信息融合" class="headerlink" title="理论分析：脑树中的相互作用和信息融合"></a>理论分析：脑树中的相互作用和信息融合</h4><p>心理建构主义假说强调多个大脑区域之间的相互作用和信息融合。由于这些相互作用本质上可以被认为是一个大脑区域（即节点）对另一个大脑区域的信息影响，作者将随机游走（Random Walk）作为脑树中信息传播的一般规则，以此定量描述任意一对节点u和v之间的信息影响。节点影响定义如下。</p><p>定义1（节点影响）：在随机游走的k步之后，节点v对节点u的节点影响I（u，v）被定义为雅可比矩阵∂h（k）u&#x2F;∂h（0）v的范数：</p><img src="/e32de4c6/3.webp"><p>其中范数‖⋅‖是任意诱导范数。</p><p>节点影响量化了节点v的信息的变化如何影响节点u的信息，节点影响力越大，表示信息从一个节点传播到另一个节点的效果越显著。</p><p>以下定理给出了节点影响的解析表达式。</p><p>定理1：给定一棵树T，在随机游走的k&#x3D;dist(u，v)步之后，节点影响节点v的IT(u，v)对节点u的影响为：</p><img src="/e32de4c6/4.webp"><p>其中节点u和v之间的唯一路径表示为（u，v1，v2，…，vk-1，v）；avivj是节点vi和vj之间的边权重，N（u）是u的1跳邻居的集合。由于脑树中所有边的权重均为1，上述公式可进一步简化为：</p><img src="/e32de4c6/5.webp"><p>式中，du为节点u的度数。上式表明节点影响随着节点之间的距离k和节点度数的增加而减小，这一点符合直觉。更准确地说，节点影响IT（u，v）随着节点u和v之间距离的增加呈指数下降，随着连接u和v的路径上节点度数的增加呈多项式下降。作者的目标是最大化大脑树中的节点影响IT（u，v），这一点可以通过解决以下优化问题来实现：</p><img src="/e32de4c6/6.webp"><p>显而易见，最优解是^du&#x3D;1，^dvi&#x3D;2，其对应于节点u和v之间的路径。由于树中任何一对节点之间都一定存在至少一条路径，此时u和v之间的路径即是最短路径。上述分析表明，信息应该沿着最短路径传播。该如何量化路径携带的信息总量呢？如下定义路径信息。</p><p>定义2（路径信息）：设P表示长度为m的路径，其顶点序列为（v0，v1，…，vm）。路径P的路径信息I(P)定义为路径上每对节点之间的节点影响的总和：</p><img src="/e32de4c6/7.webp"><p>路径信息量化了路径P上节点之间的信息融合程度。作者的目标是最大化路径信息，从而尽可能增强大脑区域之间的信息融合。下面的定理给出了具有最大路径信息的路径。</p><p>定义2：给定树T，最长最短路径（the longest shortest path）^P 具有最大路径信息：</p><img src="/e32de4c6/8.webp"><p>其中δ为树T的直径。</p><p>定义2表明，在脑树中所有可能的路径中，最长最短路径（在给定的加权图中找到从源点到所有其他顶点的最短路径中最长的一条）具有最大的信息量。因此，沿着大脑树上的最长最短路径传播信息可以最大化大脑区域之间的相互作用和信息融合。</p><p>定义2表明，在脑树中所有可能的路径中，最长最短路径（在给定的加权图中找到从源点到所有其他顶点的最短路径中最长的一条）具有最大的信息量。因此，沿着大脑树上的最长最短路径传播信息可以最大化大脑区域之间的相互作用和信息融合。</p><hr><h4 id="识别层次情绪区域"><a href="#识别层次情绪区域" class="headerlink" title="识别层次情绪区域"></a>识别层次情绪区域</h4><p>作者将整个大脑树分解成分层的主干，并利用它们来识别分层的情绪区域。具体来说，作者将最长的最短路径指定为第1级主干t1。剩下的第lth（l≥2）级的主干t l被认为是整个脑树的一个分支，在第lth级通常有多个分支。作者将第l级的主干集表示为T l,与该主干上所有节点相对应的脑区构成了主要情绪区，表示为A1。将主干移除，剩余的部分便组成了一个森林。这个森林包含至少一个（通常是多个）连接的组件，每个组件都是一棵（子）树。为了识别第l（l≥2）级的树干，作者在移除所有先前（l−1）级的树干后，在森林的每个连接组件中搜索最长的最短路径。类似地，与这些第l级干上的所有节点相对应的大脑区域构成了第l级情绪区域，表示为l。此过程迭代运行，并在删除树中的所有节点后结束。这一过程用伪代码和图例表示如下：</p><img src="/e32de4c6/9.webp"> <img src="/e32de4c6/10.webp"><div align="center">图2 大脑树识别图例</div><hr><h4 id="HemoN的构建"><a href="#HemoN的构建" class="headerlink" title="HemoN的构建"></a>HemoN的构建</h4><p>基于上述分析，作者提出了分层情绪网络（Hierarchical Emotion Network，HEmoN），由于最长最短路径（即主干）上的节点形成一个长序列，作者使用长短期记忆（LSTM）来有效地捕捉长期依赖性并识别复杂模式，从而促进情绪解码的表征学习过程。在（3）中获得每个级别的中继之后，通过LSTM来学习沿着其相应中继路径的每个中继的表示，最后组合所有的主干表示来创建脑树的表示，公式为</p><img src="/e32de4c6/11.webp"> <img src="/e32de4c6/12.webp"><p>其中Tl是第l级的主干集，tl是Tl中的单个主干，x（tl）vi表示主干tl上节点vi的特征向量，W(l)表示第l级的可学习加权矩阵，h（l）T表示第l级的主干表示。由于Tl中所有主干上的节点构成第l级情绪区域，h（l）T也作为第l级情绪区域的表示。</p><hr><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>作者在两个大规模数据集上进行实验，这两个数据集都包含视听多源自然主义刺激。整个实验评价包括两个阶段。在第一阶段，根据数据集1中所有情绪的整体体验来识别分层情绪区域。在第二阶段，使用提出的模型HEmoN，该模型建立在已识别的分层情绪区域上，对数据集2执行跨数据集情绪解码。实验代码可以在<a target="_blank" rel="noopener" href="https://github.com/zhongyu1998/HEmoN%E4%B8%8A%E5%85%AC%E5%BC%80%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/zhongyu1998/HEmoN上公开获得。</a></p><p>首先初始化等式中的可学习加权矩阵和使用Xavier初始值设定项的所有模型权重，然后用线性变换将情绪刺激预先映射到64个维度，并使用一批32个情绪刺激作为模型输入。作者的HEmoN模型由3个LSTM层和1个最后的全连接层组成。每个LSTM层包含64个隐藏单元，除最后一层之外，每个LSTM层的输出应用0.2的丢弃比。该模型使用Adam优化器进行训练，初始学习率为0.0005。</p><p>为了识别分层情绪区域，作者在数据集1上进行实验，并使用Power Atlas来定义ROI。功率图谱包括分布在13个功能系统和一个不确定系统中的264个假定功能区域（即ROI）。随后，构建大脑网络并提取大脑树，识别分层情绪区域。下图展示了所有基本情绪的整体体验的识别结果，以及最具代表性的积极和消极情绪（快乐和悲伤）的单一体验的识别结果, 节点根据图例着色，1级、2级和3级情绪区域内的内部联系分别用绿色、蓝色和红色突出显示:</p><img src="/e32de4c6/13.webp"> <img src="/e32de4c6/14.webp"> <img src="/e32de4c6/15.webp"><div align="center">图3 基本情绪的整体体验的识别结果</div><p>通过在数据集1上建立的HemoN，作者在数据集2上进行性能测试和评价，以回归任务中广泛使用的平均绝对误差（MAE）作为评估度量，MAE值越低表示误差越小。MAE值α计算如下：</p><img src="/e32de4c6/16.webp"><p>其中yi和^yi分别表示第i个刺激的真实和预测情绪评级向量，Ns表示刺激的数量。</p><p>最后，将HEmoN与多个竞争基线进行了比较，包括全连接神经网络（FNN）、图卷积网络（GCN）、图同构网络（GIN）、BrainNetCNN、BrainGNN、脑网络转换器（BrainNetTF）和图增强情绪解码（GED）。比较结果如下图所示。</p><img src="/e32de4c6/17.webp"><div align="center">图4 不同算法的对比结果</div><p>其中，后缀“-EA1”和“-DFT”分别表示第一级情绪区域和深度优先遍历，这两次实验的是消融研究, 目的是用于评估模型中各个组成部分的重要性和贡献。可见，HemoN的MAE最低，取得了较好的性能。且HEmoNEA1和HEmoN-DFT的消融研究证明了分层情绪区域和所提出的信息融合规则的有效性</p><hr><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>在本研究中，作者通过多源信息融合和图机器学习方法来调查人脑中的分层情绪区域。此外，作者基于心理建构主义假说，对特定情绪背后的大脑机制提供了初步的见解。所提出的HemoN模型在情绪解码上始终优于BrainNetTF和GED等高级模型，在所有情况下都取得了出色的性能，优越表现凸显了整合来自多个脑区信息的重要性。</p><hr><h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote><p><a target="_blank" rel="noopener" href="https://www.scholat.com/teamwork/showPostMessage.html?id=16387">https://www.scholat.com/teamwork/showPostMessage.html?id=16387</a></p></blockquote></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-item"><a href="/52e49617.html" rel="prev" title="IEEE TPAMI | 基于专家知识融入深度学习网络架构的多级可解释睡眠阶段评分系统"><i class="fa fa-chevron-left"></i> IEEE TPAMI | 基于专家知识融入深度学习网络架构的多级可解释睡眠阶段评分系统</a></div><div class="post-nav-item"><a href="/b1968da5.html" rel="next" title="Neural Networks | SFT - SGAT一种用于情绪识别和意识检测的半监督微调自监督图注意网络">Neural Networks | SFT - SGAT一种用于情绪识别和意识检测的半监督微调自监督图注意网络 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let t=CONFIG.comments["activeClass"];var e;(t=CONFIG.comments.storage?localStorage.getItem("comments_active")||t:t)&&(e=document.querySelector(`a[href="#comment-${t}"]`))&&e.click()}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E6%A6%82%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text">论文概要</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF"><span class="nav-number">2.</span> <span class="nav-text">研究背景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E5%88%86%E6%9E%90"><span class="nav-number">3.</span> <span class="nav-text">方法分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%9A%E8%BF%87%E4%BD%BF%E7%94%A8%E6%94%B6%E9%9B%86%E5%88%B0%E7%9A%84fMRI%E4%BF%A1%E5%8F%B7%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%A4%A7%E8%84%91%E7%BD%91%E7%BB%9C"><span class="nav-number">3.1.</span> <span class="nav-text">通过使用收集到的fMRI信号构建一个大脑网络</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90%EF%BC%9A%E8%84%91%E6%A0%91%E4%B8%AD%E7%9A%84%E7%9B%B8%E4%BA%92%E4%BD%9C%E7%94%A8%E5%92%8C%E4%BF%A1%E6%81%AF%E8%9E%8D%E5%90%88"><span class="nav-number">3.2.</span> <span class="nav-text">理论分析：脑树中的相互作用和信息融合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%86%E5%88%AB%E5%B1%82%E6%AC%A1%E6%83%85%E7%BB%AA%E5%8C%BA%E5%9F%9F"><span class="nav-number">3.3.</span> <span class="nav-text">识别层次情绪区域</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HemoN%E7%9A%84%E6%9E%84%E5%BB%BA"><span class="nav-number">3.4.</span> <span class="nav-text">HemoN的构建</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C"><span class="nav-number">4.</span> <span class="nav-text">实验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%93%E8%AE%BA"><span class="nav-number">5.</span> <span class="nav-text">结论</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E6%96%87%E9%93%BE%E6%8E%A5"><span class="nav-number">6.</span> <span class="nav-text">原文链接</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Aisaka Aoi" src="/images/manatsu.jpg"><p class="site-author-name" itemprop="name">Aisaka Aoi</p><div class="site-description" itemprop="description">逢坂葵的个人博客</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">1020</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">20</span> <span class="site-state-item-name">分类</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/AisakaAoi" title="GitHub 👨‍💻 → https:&#x2F;&#x2F;github.com&#x2F;AisakaAoi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👨‍💻</a> </span><span class="links-of-author-item"><a href="https://github.com/Aisakaorz" title="GitHub 👩‍💻 → https:&#x2F;&#x2F;github.com&#x2F;Aisakaorz" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👩‍💻</a> </span><span class="links-of-author-item"><a href="mailto:aisakaaoi@qq.com" title="E-Mail 📧 → mailto:aisakaaoi@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 📧</a> </span><span class="links-of-author-item"><a href="mailto:chenzongnan@m.scnu.edu.cn" title="E-Mail 🏫 → mailto:chenzongnan@m.scnu.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 🏫</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/91560309" title="Bilibili 📺 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;91560309" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 📺</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/198562921" title="Bilibili 🎮 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;198562921" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 🎮</a> </span><span class="links-of-author-item"><a href="https://www.youtube.com/channel/UCALvyn5Cl76GCotO9pczvjg" title="YouTube 📺 → https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCALvyn5Cl76GCotO9pczvjg" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube 📺</a></span></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2026</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Aisaka Aoi</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">3.8m</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">158:10</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll(".pdfobject-container").forEach(e=>{var t=e.dataset.target,a="#"+Object.entries({navpanes:0,toolbar:0,statusbar:0,pagemode:"thumbs",view:"FitH"}).map(([e,t])=>e+"="+encodeURIComponent(t)).join("&"),r="/lib/pdf/web/viewer.html?file="+encodeURIComponent(t)+a;NexT.utils.supportsPDFs()?e.innerHTML=`<embed class="pdfobject" src="${t+a}" type="application/pdf" style="height: ${e.dataset.height};">`:e.innerHTML=`<iframe src="${r}" style="height: ${e.dataset.height};" frameborder="0"></iframe>`})</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//unpkg.com/valine/dist/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!0,notify:!0,appId:"UqjWdRYbIUEUQRXhBUUIh1QE-gzGzoHsz",appKey:"gj89JXC485PFbpdHLKVkz6dm",placeholder:"这里可以发送评论~（上面可以输入昵称、邮箱）",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{jsonPath:"/live2dw/assets/assets/haru02.model.json"},display:{position:"right",width:208,height:520},mobile:{show:!1},log:!1})</script></body></html>