<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><meta name="baidu-site-verification" content="code-KCMz4b3cnd"><meta name="google-site-verification" content="MTp8U7dJ1uzrfz8Mu6rgqX1CIm3HjqPWd0xaRcv1tFg"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png"><link rel="mask-icon" href="/images/favicon.png" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"aisakaaoi.github.io",root:"/",scheme:"Pisces",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="该论文发表于《IEEE TRANSACTIONS ON FUZZY SYSTEMS》（中科院一区，IF&#x3D;10.7），题目为《A Comprehensive Adaptive Interpretable Takagi–Sugeno–Kang Fuzzy Classifier for Fatigue Driving Detection》。 成都信息工程大学计算机学院科研团队的郜东瑞为此论"><meta property="og:type" content="article"><meta property="og:title" content="IEEE TFS | 一种用于疲劳驾驶检测的自适应可解释模糊分类器"><meta property="og:url" content="https://aisakaaoi.github.io/fd0d48b6.html"><meta property="og:site_name" content="逢坂葵的个人博客"><meta property="og:description" content="该论文发表于《IEEE TRANSACTIONS ON FUZZY SYSTEMS》（中科院一区，IF&#x3D;10.7），题目为《A Comprehensive Adaptive Interpretable Takagi–Sugeno–Kang Fuzzy Classifier for Fatigue Driving Detection》。 成都信息工程大学计算机学院科研团队的郜东瑞为此论"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/1.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/2.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/3.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/4.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/5.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/6.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/7.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/8.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/9.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/10.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/11.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/12.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/13.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/14.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/15.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/16.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/17.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/18.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/19.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/20.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/21.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/22.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/23.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/24.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/25.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/26.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/27.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/28.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/29.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/30.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/31.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/32.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/33.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/34.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/35.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/36.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/37.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/38.webp"><meta property="og:image" content="https://aisakaaoi.github.io/fd0d48b6/39.webp"><meta property="article:published_time" content="2025-02-20T18:43:32.000Z"><meta property="article:modified_time" content="2026-01-23T11:02:57.364Z"><meta property="article:author" content="Aisaka Aoi"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://aisakaaoi.github.io/fd0d48b6/1.webp"><link rel="canonical" href="https://aisakaaoi.github.io/fd0d48b6.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>IEEE TFS | 一种用于疲劳驾驶检测的自适应可解释模糊分类器 | 逢坂葵的个人博客</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?7308ed05421777c301eefa3754da1b42",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="逢坂葵的个人博客" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">aoi学院</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">Aisaka's Blog, School of Aoi, Aisaka University</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">20</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">1026</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div><a href="https://github.com/AisakaAoi" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://aisakaaoi.github.io/fd0d48b6.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/manatsu.jpg"><meta itemprop="name" content="Aisaka Aoi"><meta itemprop="description" content="Aisaka's Blog, School of Aoi, Aisaka University"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="逢坂葵的个人博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">IEEE TFS | 一种用于疲劳驾驶检测的自适应可解释模糊分类器</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2025-02-21 02:43:32" itemprop="dateCreated datePublished" datetime="2025-02-21T02:43:32+08:00">2025-02-21</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">🌙进阶学习</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%A0%94%E7%A9%B6%E5%9B%A2%E9%98%9F%EF%BC%88BCI%E5%9B%A2%E9%98%9F%EF%BC%89/" itemprop="url" rel="index"><span itemprop="name">⭐脑机接口与混合智能研究团队（BCI团队）</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%A0%94%E7%A9%B6%E5%9B%A2%E9%98%9F%EF%BC%88BCI%E5%9B%A2%E9%98%9F%EF%BC%89/%F0%9F%92%AB%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/" itemprop="url" rel="index"><span itemprop="name">💫学习报告</span></a> </span></span><span id="/fd0d48b6.html" class="post-meta-item leancloud_visitors" data-flag-title="IEEE TFS | 一种用于疲劳驾驶检测的自适应可解释模糊分类器" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/fd0d48b6.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/fd0d48b6.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>8.7k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>22 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><img src="/fd0d48b6/1.webp"><p>该论文发表于《IEEE TRANSACTIONS ON FUZZY SYSTEMS》（中科院一区，IF&#x3D;10.7），题目为《A Comprehensive Adaptive Interpretable Takagi–Sugeno–Kang Fuzzy Classifier for Fatigue Driving Detection》。</p><p>成都信息工程大学计算机学院科研团队的郜东瑞为此论文的第一作者。成都信息工程大学计算机学院科研团队的张永清教授为此论文的通讯作者。</p><p>论文链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/10528899">https://ieeexplore.ieee.org/document/10528899</a></p><span id="more"></span><hr><h3 id="论文概要"><a href="#论文概要" class="headerlink" title="论文概要"></a>论文概要</h3><p>脑电图（EEG）信号作为一种可靠的生物指标，由于能够反映驾驶员的认知和神经反应状态，已被广泛用于疲劳驾驶检测。然而，EEG信号存在数据分布不平衡、个体间差异显著以及场景复杂等问题，这些都会影响检测效果。输入对象之间的微小共性可以被解释为整个样本的重要信息。因此，为了尽可能保留信息，本研究设计了一种新的模糊特征整合方法，即综合自适应可解释Takagi-Sugeno-Kang模糊分类器（CAI-TSK-FC），用于整合模糊特征。该方法不仅能够更高效地捕获多个子分类器的特征，缓解数据集不平衡问题，还可以通过随机保留模糊规则和归一化减少错误信息的积累。最终，本研究将多个子分类器的结果线性组合，综合考虑多个子分类器的学习效果，以适应不同个体和数据集。在自制数据集和公共数据集上的实验表明，CAI-TSK-FC在不同的EEG疲劳驾驶数据集上具有良好的性能和可解释性。与现有方法相比，其准确率分别提高了3.15%和1.52%，特异性分别提高了4.72%和0.91%。</p><hr><h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>驾驶疲劳是交通事故中最重要的影响因素之一，不仅危及驾驶员的生命，也危及其他道路使用者的安全。而开发一种有效的算法来检测驾驶员的疲劳状态已成为减少交通事故发生的一种手段。早期的疲劳检测算法可分为主观检测方法和客观检测方法。主观检测方法受到个体意愿和判断的极大影响，缺乏足够的说服力；客观检测方法包括生理信号、面部特征和车辆轨迹。面部特征和车辆轨迹计算分别受到光照和驾驶员技术的影响。使用生理信号进行分析可以避免上述问题。在生理信号中，脑电图（EEG）信号能够捕捉有关神经生理脑活动的信息，并准确反映驾驶员的心理状态。现有的研究使用深度学习方法来表征疲劳状态下的EEG信号，尽管这些研究取得了令人满意的结果，但它们并不能完全解释所学习到的特征。近年来，Takagi-Sugeno-Kang（TSK）模糊系统在EEG领域展现了独特的能力，但仍存在一些限制，具体如下：</p><ol><li>EEG信号容易受到复杂环境的影响，不同场景下EEG信号的特征存在差异，这限制了模型的泛化能力。</li><li>疲劳驾驶过程中产生的EEG数据存在采样不平衡，正负EEG采样差异对模型预测精度的影响尚未明确。</li><li>传统的堆叠TSK模糊分类器会持续积累错误信息，从而影响后续层的特征提取效果。</li></ol><p>为了解决这些问题，本研究提出了一种新的用于检测疲劳的方法，即综合自适应可解释TSK模糊分类器（CAI-TSK-FC）。CAI-TSK-FC利用一种新的模糊特征整合方法从数据集中提取更多信息，以解决不平衡带来的学习资源不足问题。此外，为了减少错误信息的积累，本研究开发了模糊规则随机保留和线性组合方法，以增强模型的自适应性能，同时将错误信息对结果的影响降至最低。本研究的模型通过整合低阶TSK模糊系统实现了与深度学习技术相当的性能。此外，本研究利用TSK模糊系统的语言规则可解释性来提高可解释性，减少深度学习“黑箱问题”的影响。</p><hr><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>作为一种非平稳信号，EEG对生理和环境因素非常敏感，获取的信息存在许多不确定性。基于模糊集合理论的模糊分类器能够缓解不确定性问题，因此本研究将其用于信号分类。图1和图2共同展示了本文的整体算法框架。图1展示了EEG预处理过程，图2展示了CAI-TSK-FC模型的总体结构。</p><img src="/fd0d48b6/2.webp"><p>图1 EEG处理。预处理是一个包含滤波和模糊化两个步骤的过程，目标是尽可能去除伪迹并将数据转换为模糊属性。其中，N表示输入样本的数量，OD表示原始特征的维度，D表示处理后的特征维度，且D≤OD。</p><img src="/fd0d48b6/3.webp"><p>图2 CAI-TSK-FC结构。 输入数据X和目标T进入第一个子分类器OP-TSK1。保留部分模糊规则R1及其学习结果Y1，并计算此时的分类性能。如果达到了预期结果，则训练停止。否则，将R1、Y1和原始数据X输入到下一个子分类器，进行多个子分类器结果的线性组合。这一过程会不断循环，直到模型产生预期的结果。</p><p>在预处理阶段，本研究首先对原始数据进行滤波以去除伪迹，然后使用主成分分析（PCA）对数据进行降维处理，最后使用模糊C均值方法（FCM）对获得的数据进行模糊化操作，以得到模糊属性数据。</p><hr><h4 id="TSK模糊分类器"><a href="#TSK模糊分类器" class="headerlink" title="TSK模糊分类器"></a>TSK模糊分类器</h4><p>经典的TSK模糊分类器由一组规则组成，其中第r条模糊规则如下：</p><img src="/fd0d48b6/4.webp"><p>在TSK模糊分类器中，输入向量X，Ar是从输入向量X映射到输出空间的模糊集合。输入空间的模糊子集Ar通过TSK模糊分类器转换为输出空间的模糊集合fr(x)。R是模糊规则的数量，D是样本的维度数。A_i_r是输入向量x的第i维对应的第r条规则的模糊子集。</p><p>如果fr(x)是p_0^r，则TSK模糊分类器为零阶。本研究选择零阶TSK模糊分类器作为构建CAI-TSK-FC的基本结构。研究证明，零阶TSK模糊分类器的集成等同于高阶TSK模糊分类器，并且具有更好的可解释性。本研究采用高斯函数作为模糊隶属函数，使模糊隶属度计算更加平滑，并能更好地适应不同数据。TSK模糊分类的输出可以表示为：</p><img src="/fd0d48b6/5.webp"><p>其中，μrd(xd)是通过高斯隶属函数计算的模糊规则的结果，μr(x)是通过模糊规则标准化后的模糊隶属函数，μr(x)是通过模糊规则的前件部分经过模糊化运算得到的，即：</p><img src="/fd0d48b6/6.webp"><p>其中，μrd(xd)可以通过高斯函数计算模糊隶属函数表示为：</p><img src="/fd0d48b6/7.webp"><p>其中，mrd和σrd分别是高斯隶属函数的中心和标准差。</p><p>本研究使用五个高斯隶属函数来表示每条模糊规则。这些隶属函数的中心（MF1, MF2, MF3, MF4, MF5）分别为0、0.25、0.5、0.75和1。因此，可以从语言学上解释模糊规则，即（非常低、低、中等、高、非常高）。基于这些结果，可以提高零阶TSK模糊分类器的可解释性。</p><hr><h4 id="优化TSK模糊分类器"><a href="#优化TSK模糊分类器" class="headerlink" title="优化TSK模糊分类器"></a>优化TSK模糊分类器</h4><p>传统的TSK模糊分类器对某些不平衡样本的识别率较低。为了解决这一问题，本研究提出了一个优化的零阶TSK模糊分类器作为CAI-TSK-FC的子分类器。主要框架如图3所示。</p><img src="/fd0d48b6/8.webp"><div align="center">图3 利用BN和指数函数优化TSK模糊分类器的计算过程。</div><p>预处理后的数据将输入到本研究提出的TSK子模糊分类器中，接下来的部分中，用z(l)表示第l层子分类器的输出，l &#x3D; 1, 2, …, 7。</p><ol><li>输入层：预处理后的EEG特征数据可以表示为X &#x3D; (x₁, x₂, …, xn)，该层的数据是输入数据，不参与计算：</li></ol><img src="/fd0d48b6/9.webp"><p>其中i &#x3D; 1, 2, …, n表示第i个样本。</p><ol start="2"><li>隶属函数层：为了提高模型对数据的适应能力，该层将输入数据映射到高斯隶属函数。此外，逻辑关系建模在模糊规则构建中也起着重要作用，这一层也实现了这一功能。对于EEG信号而言，不同数据所表示的信息存在差异和相似性。通过计算隶属函数，可以识别不同数据之间的相似性和差异性，从而提高模型的分类能力。在这一层，使用高斯隶属函数计算输入数据的隶属度值如下：</li></ol><img src="/fd0d48b6/10.webp"><p>其中r是第r条模糊规则，d是第d个特征。</p><p>在TSK模糊分类器的模糊规则生成中，并非所有子分类器的规则都需要进行后续计算。因此，本研究在CAI-TSK-FC的每个Op-TSKˡ (l &#x3D; 1, 2, …, L)中添加了一个特征选择矩阵[FDM]d×R。该矩阵的作用是控制每条模糊规则的后件计算。其格式如下：“如果x₁是低的且fdm1r &#x3D; 1 ∧ x₂是高的且fdm2r &#x3D; 1 ∧ x₃是中等的且fdm3r &#x3D; 0 ∧ x₄是非常低的且fdm4r &#x3D; 1 ∧ x₅是低的且fdm5r &#x3D; 0，则yr &#x3D; po^r属于类别c。r &#x3D; 1, 2, …, R。”当fdmdr &#x3D; 0时，忽略第r条模糊规则的贡献；只有当fdm1r &#x3D; 1时才应用该规则。此外，本研究还添加了一个模糊规则矩阵[FRM]D×5×R。在这个矩阵中，每个元素的值随机分配为0或1，以决定每条模糊规则使用哪个高斯隶属函数。例如，FRM[4, 2, 3] &#x3D; 1表示第三条模糊规则中的第四个输入特征使用“低”隶属函数。</p><img src="/fd0d48b6/11.webp"><p>其中k是第k个高斯隶属函数的中心值[0, 0.25, 0.5, 0.75, 1]。l表示第l层子分类器。</p><ol start="3"><li>空间激发层：这一层的主要功能是计算空间激发强度。基于前一层的函数计算，可以获得输入数据每个特征的隶属度值。传统的空间激发强度是通过连续累积乘法方法计算的。这种方法受到维度诅咒的影响，无法适应高维数据，公式如下：</li></ol><img src="/fd0d48b6/12.webp"><p>其中，当|Zir(2)|的差异较小时，Zr(3)会收敛到0，此时Zr(3)&lt;&lt;1。同样，当Zir(2)&gt;&gt;1时，即数据是高维的情况下，Zr(3)的值会非常大，导致溢出。</p><p>在EEG信号分类任务中，更多的数据可能会带来更好的分类性能。为了解决这一问题，本研究修改了这一层的函数。公式如下：</p><img src="/fd0d48b6/13.webp"><p>为了使计算结果更加平滑，本研究将连续累积乘法方法改为求和公式。这种方法仍然能够很好地辨别各种数据差异，同时保持原有功能。</p><ol start="4"><li>归一化层：在这一层中，本研究对前一层的激发水平进行归一化处理。由于(xid-mrd)^2 &#x2F; 2σrd^2的结果始终为正，连续求和可能会产生饱和问题，因此进行归一化处理。在后续计算中使用平均值，并且在计算中，平均值的计算会是指数形式。具体公式如下：</li></ol><img src="/fd0d48b6/14.webp"><p>其中D是特征的数量，R是模糊规则的数量。</p><ol start="5"><li>批量归一化（BN）层：BN是一种在深度学习中广泛使用的优化技术，被引入到TSK模糊分类优化中。它可以加快模型的收敛速度，并提高其泛化能力。对于获得的模糊规则样本Zir(4)的BN结果如下：</li></ol><img src="/fd0d48b6/15.webp"><p>其中mB是样本的均值，σB是其标准差。γ和m是学习参数，ϵ是一个小常数，用于防止分母为零。</p><p>可以使用BN操作来优化TSK模糊系统，因为不同实验对象之间的数据分布问题。本研究通过对不同规则的激发水平计算均值和标准差，使用BN操作获得新的规则水平。最后，使用新的规则水平计算分类结果。</p><ol start="6"><li>去模糊化层：这一层实现了使用最小学习机（LLM）计算后验参数。LLM是用于加速单层或多层前馈神经网络的训练速度的一种算法。假设R₁, R₂, …, RL表示第l层子层随机选择的模糊规则，β₁, β₂, …, βL表示第l层的输出权重。对于训练集D &#x3D; {X, T}，T是二分类问题对应的分类标签。后验参数β。</li></ol><p>为了快速求解后验参数β，本研究提前确定子层的数量，获得前一层的输出，然后计算当前层的参数。最后求解带有给定常数C的岭回归问题，使用LLM算法快速求解：</p><img src="/fd0d48b6/16.webp"><p>如果用矩阵形式表示：</p><img src="/fd0d48b6/17.webp"><p>得到βL的解析公式为：</p><img src="/fd0d48b6/18.webp"><p>研究证明证明，使用LLM算法的优点是学习可以通过输出层进行，而无需更多耗时的迭代操作。同时，本研究的重点是EEG，即高维数据。如公式（14）所示，这种形式可以减少由于大量样本数据而导致的许多复杂操作。</p><hr><h4 id="所有子分类器的线性组合"><a href="#所有子分类器的线性组合" class="headerlink" title="所有子分类器的线性组合"></a>所有子分类器的线性组合</h4><p>疲劳驾驶是一个连续的过程，它会影响驾驶员的EEG信号。随着时间序列的增加，这些不确定性所导致的特征重要性会发生变化。为了解决这一问题，每个子分类器的输入是由原始输入空间的随机投影和前一个子分类器生成的。然而，每个子分类器所学习到的特征仍然存在不确定性。因此，为了确保更好的整体分类结果，建议对多个子分类器进行线性组合。</p><p>在CAI-TSK-FC中，训练从零阶子分类器Op-TSK₁开始，它以原始数据作为输入。初始假设是Op-TSK₁仅包含五条模糊规则，其输出为Y₁，这与后续高层子分类器不同。接下来，CAI-TSK-FC将输入提供给下一个TSK子分类器。当第一层的TSK子分类器未能达到预期结果时，CAI-TSK-FC将使用当前层的输入和输出来形成下一层的输入，并随机选择当前层的一条模糊规则来计算下一层的模糊规则。此时，输入为(X, Y1) ∈ Rd+1。如果第l层的TSK子分类器未能达到所需的性能，则CAI-TSK-FC将继续训练第l + 1层的数据，并重复该过程，直到在第L层获得预期结果。</p><p>如果用Y₁, Y₂, Y₃, …, YL表示所有子分类器基于输入数据的输出，则最后一层的输出为：</p><img src="/fd0d48b6/19.webp"><p>其中λl是每层的组合系数。考虑以下因素：</p><ol><li>Yl应尽可能接近真实标签；</li><li>第一层的输出应与真实标签进行正则化；</li><li>第二层及后续子分类器的输出应尽可能接近前一层的最大输出。</li></ol><p>公式如下：</p><img src="/fd0d48b6/20.webp"><p>其中ε和ξ是两个正则化系数。它们可以手动设置并自动调整。上述公式等价于：</p><img src="/fd0d48b6/21.webp"><p>其中</p><img src="/fd0d48b6/22.webp"> <img src="/fd0d48b6/23.webp"> <img src="/fd0d48b6/24.webp"><p>对λ求导并令其导数为零，可以得到λ的解析解：</p><img src="/fd0d48b6/25.webp"><p>可以得到λ的解析解如下：</p><img src="/fd0d48b6/26.webp"><hr><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>本文的实验基于SEED-VIG公开数据集和自制数据集。本研究将CAI-TSK-FC与其他五种基于EEG的TSK模糊系统分类器进行了比较，包括FS-FCSVM、MV-TSKFC、MV-TSK-FS-HSIC、TSK-JDA-FLS和TSK-TL。在所有TSK模糊系统模型中将模糊规则的数量设置为5，并将层数的初始值设置为3。</p><p>本研究将数据集随机划分为20%的测试集和80%的训练集，并进行了五折交叉验证，使用平均结果来评估性能。准确率、召回率、特异性、精确率和F1分数被用作分类性能指标。</p><hr><h4 id="分类结果"><a href="#分类结果" class="headerlink" title="分类结果"></a>分类结果</h4><p>表1和表2分别展示了上述方法在自制数据集和SEED-VIG公开数据集上的分类结果。</p><div align="center">表1 自制数据集上不同方法的检测结果对比</div><img src="/fd0d48b6/27.webp"><div align="center">表2 SEED-VIG数据集上不同方法的检测结果对比</div><img src="/fd0d48b6/28.webp"><p>可以看出，CAI-TSK-FC模型具有优越的分类性能。与次优方法相比，CAI-TSK-FC在自制数据集和SEED-VIG公开数据集上的准确率分别提高了3.15%和1.52%。这表明CAI-TSK-FC具有较高的识别性能，主要原因如下：</p><ol><li>CAI-TSK-FC采用深度集成框架，能够获取更多的数据特征信息，从而更全面地区分不同的疲劳状态。此外，CAI-TSK-FC在每一层中保留了一份模糊规则，并将其添加到下一层。</li><li>提出的CAI-TSK-FC优化了每个子分类器中的原始TSK模糊系统，并引入了批量归一化（BN）和最小学习机（LLM），以提高模型的计算能力。</li></ol><p>为了全面评估模型的分类性能，图4和图5中分别展示了两个数据集中每个受试者的分类准确率。</p><img src="/fd0d48b6/29.webp"><div align="center">图4 自制数据集中14名受试者的准确率对比</div><img src="/fd0d48b6/30.webp"><div align="center">图5 SEED-VIG数据集中14名受试者的准确率对比</div><p>可以看出，CAI-TSK-FC分类器在不同受试者之间具有显著优势。基线模型FS-FCSVM的分类效果最低。对于自制数据集，第二名受试者的分类性能低于其他受试者，而第八名受试者的分类效果较高。对于SEED-VIG公开数据集，第三名受试者的分类效果低于其他受试者，而第四名受试者的分类效果优于其他受试者。这表明不同模型在个体受试者之间存在差异。上述结果表明，基于EEG的驾驶疲劳分类在不同受试者之间具有良好的效果。</p><hr><h4 id="不平衡数据集的评估结果"><a href="#不平衡数据集的评估结果" class="headerlink" title="不平衡数据集的评估结果"></a>不平衡数据集的评估结果</h4><p>接收者操作特征（ROC）曲线可以直观地反映分类器的性能，并提供在不同阈值下的性能比较，因此可以用来评估分类器在不平衡数据集上的性能。本研究使用测试集的预测结果计算真正例（TP）、假正例（FP）、真负例（TN）和假负例（FN），然后绘制ROC曲线，并计算G均值和曲线下面积（AUC）值。</p><p>图6和表3显示了本研究的方法在ROC曲线上的表现良好。</p><img src="/fd0d48b6/31.webp"><div align="center">图6 自制数据集上不同方法的ROC曲线</div><div align="center">表3 自制数据集上不同方法的AUC和G均值</div><img src="/fd0d48b6/32.webp"><p>此外，AUC值和G均值分别为0.9046和0.8197，也高于其他方法。同时，本研究的模型在公开数据集上的表现更好。不平衡数据集对模型效果的影响主要是由于学习资源不足以及正负样本之间的差异较大。为了解决这一问题，本研究利用改进的零阶TSK模糊系统提取关键特征，并积累多层模糊规则，增强模型的学习资源。此外，在训练过程中使用BN来压缩错误信息的积累。最后，通过线性组合减少每个模块提取的错误信息的权重，从而实现更有效的分类。这种方法导致AUC和G均值得分的提高。同样，图7和表4也验证了本研究的结果。</p><img src="/fd0d48b6/33.webp"><div align="center">图7 SEED-VIG数据集上不同方法的ROC曲线</div><div align="center">表4 SEED-VIG数据集上不同方法的AUC和G均值</div><img src="/fd0d48b6/34.webp"><p>总之，本研究的方法在解决不平衡问题方面优于其他比较方法。</p><hr><h4 id="不同场景下的实验效果"><a href="#不同场景下的实验效果" class="headerlink" title="不同场景下的实验效果"></a>不同场景下的实验效果</h4><p>根据受试者的实验结果，不同场景下的数据不平衡程度存在差异。表5显示了14名受试者的正负样本数量。表5表明，三种场景下的正负样本数量存在显著差异，同时也表明不同场景下不平衡问题的严重程度不同。</p><div align="center">表5 不同场景下正负样本的数量</div><img src="/fd0d48b6/35.webp"><p>在本实验中，每种比较方法均进行了十折交叉验证，并计算平均准确率以评估其分类效果。图8中的柱状图显示了六种比较方法在三种不同场景下的分类效果。</p><img src="/fd0d48b6/36.webp"><div align="center">图8 不同场景下六种方法的分类准确率</div><p>本研究的方法的分类效果优于其他任何方法。根据图8可以看到，在LS场景下的准确率略低于其他两种场景。这可能是由于受试者在开放道路场景下的疲劳程度较低，且其数据集的不平衡性较为明显，导致模型学习资源不足。然而，本研究提出的CAI-TSK-FC仍然表现良好，这表明本研究采用的深度集成结构能够缓解这一问题。</p><hr><h4 id="可解释性"><a href="#可解释性" class="headerlink" title="可解释性"></a>可解释性</h4><p>为了更好地展示CAI-TSK-FC的可解释性，在表6中列出了自制数据集第二层中每个子分类器的两条可解释规则。</p><div align="center">表6 CAI-TSK-FC在自制数据集第二层的模糊规则可解释性结果</div><img src="/fd0d48b6/37.webp"><p>其中，F1、F2和F25表示原始数据集的特征，F26表示前一层的输出特征。当把输入特征划分为五个模糊子集时，它们的语义可以解释为非常低（VL）、低（L）、中等（M）、高（H）和非常高（VH）。每一行都可以转换为具有非线性部分的模糊规则。例如，根据公式（7），第二层的五条模糊规则如表6所示。</p><img src="/fd0d48b6/38.webp"><div align="center">图9 当层数为3时，模型的模糊规则可解释性结果展示</div><p>如图9所示，经过预处理后，EEG信号数据在第二层有25个特征。在第一层输出后，增加了1-D特征，特征数量增加到26个。同时，本研究使用前一层的模糊规则对当前层进行累积计算，并使用公式（13）得到当前层的分类结果。为了在每个TSK子分类器中展示易于理解的输出表达式，在表VI中详细列出了CAI-TSK-FC结构的前三层的前五条模糊规则。随机生成的模糊规则是所涉及特征的总和，包括特征空间中的模糊划分。FRM和FDM分别表示规则生成矩阵和特征选择矩阵。以L&#x3D;1的第一条FRM为例，FRM[1,4,1]&#x3D;1表示第一条模糊规则中第一个特征的高斯隶属函数中心为非常高（VH），而FDM[5,1]&#x3D;1表示第一条模糊规则中第五个输入特征被选中进入下一步计算，否则跳过该特征的计算。其他层的模糊规则具有类似的含义。</p><img src="/fd0d48b6/39.webp"><div align="center">图10 模糊隶属矩阵特征的可视化</div><p>此外，本研究还可视化了模糊隶属矩阵特征的前三个特征，如图10所示。在模糊隶属矩阵特征的可视化中，三个特征分别表示为x轴、y轴和z轴。根据这三个特征的值，确定每个样本在3-D空间中的位置。例如，如果一个样本在特征1上值较高，在特征2上值较低，在特征3上值中等，则其在3-D图中的位置可能更靠近x轴的顶部、y轴的底部和z轴的中部。这个3-D图解释了基于这三个特征的样本分布。还可以根据点的颜色和大小确定样本在模糊集合中的隶属度，红色表示值为1，蓝色表示值为0。样本点在特征上的值越大，其对结果的影响就越大。</p><p>例如，在图9中，第二层的FRM第一条模糊规则显示，第一条模糊规则中的第一个和第二个特征采用高斯隶属函数中的非常高（VH）。第26个特征采用高斯隶属函数中的高（H）。同样，第二条、第三条、第四条和第五条模糊规则也可以进行解释。根据上述内容，可以看到CAI-TSK-FC具有良好的可解释性。</p><p>上述实验结果证实，本研究提出的CAI-TSK-FC在预测驾驶疲劳方面具有良好的分类效果、泛化能力和高可解释性，能够应对不同场景下的问题。</p><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本研究提出了一种基于脑电信号的综合自适应可解释Takagi-Sugeno-Kang模糊分类器（CAI-TSK-FC），用于疲劳驾驶检测。该方法通过以下策略实现显著的效果检测：</p><ol><li><strong>多子分类器堆叠</strong>：设计多个子分类器并保留中间层的模糊规则，增强学习资源，减少数据不平衡对性能的影响。</li><li><strong>批量归一化与优化规则</strong>：在每个子分类器中应用批量归一化（BN）和优化的模糊规则，压缩错误特征信息，防止数值溢出和下溢，同时通过线性组合子分类器结果，降低错误数据对分类的影响。</li><li><strong>可解释性评估</strong>：通过模糊规则矩阵和特征决策矩阵评估模型的可解释性，实验结果表明该方法在不平衡数据集上具有较高的分类准确性和泛化能力。</li></ol><p>尽管该方法在跨受试者和场景分类中表现良好，但在噪声数据处理和模型性能方面仍有改进空间。未来研究将探索如何适应原始数据集，以提升实时分类能力。</p><hr><h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote><p><a target="_blank" rel="noopener" href="https://www.scholat.com/teamwork/showPostMessage.html?id=16698">https://www.scholat.com/teamwork/showPostMessage.html?id=16698</a></p></blockquote></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-item"><a href="/6153cdaa.html" rel="prev" title="IEEE TAFFC | Grop：用于脑电情绪识别的图正交净化网络"><i class="fa fa-chevron-left"></i> IEEE TAFFC | Grop：用于脑电情绪识别的图正交净化网络</a></div><div class="post-nav-item"><a href="/96834198.html" rel="next" title="VALSE Webinar 25-04期（总第375期）AI方向投稿Nature/Science系期刊的经验及相关工作分享">VALSE Webinar 25-04期（总第375期）AI方向投稿Nature/Science系期刊的经验及相关工作分享 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let t=CONFIG.comments["activeClass"];var e;(t=CONFIG.comments.storage?localStorage.getItem("comments_active")||t:t)&&(e=document.querySelector(`a[href="#comment-${t}"]`))&&e.click()}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E6%A6%82%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text">论文概要</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF"><span class="nav-number">2.</span> <span class="nav-text">研究背景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#TSK%E6%A8%A1%E7%B3%8A%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">3.1.</span> <span class="nav-text">TSK模糊分类器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E5%8C%96TSK%E6%A8%A1%E7%B3%8A%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">3.2.</span> <span class="nav-text">优化TSK模糊分类器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%80%E6%9C%89%E5%AD%90%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%BF%E6%80%A7%E7%BB%84%E5%90%88"><span class="nav-number">3.3.</span> <span class="nav-text">所有子分类器的线性组合</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-number">4.</span> <span class="nav-text">实验结果</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E7%BB%93%E6%9E%9C"><span class="nav-number">4.1.</span> <span class="nav-text">分类结果</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8D%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E8%AF%84%E4%BC%B0%E7%BB%93%E6%9E%9C"><span class="nav-number">4.2.</span> <span class="nav-text">不平衡数据集的评估结果</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8D%E5%90%8C%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%95%88%E6%9E%9C"><span class="nav-number">4.3.</span> <span class="nav-text">不同场景下的实验效果</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7"><span class="nav-number">4.4.</span> <span class="nav-text">可解释性</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">5.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E6%96%87%E9%93%BE%E6%8E%A5"><span class="nav-number">6.</span> <span class="nav-text">原文链接</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Aisaka Aoi" src="/images/manatsu.jpg"><p class="site-author-name" itemprop="name">Aisaka Aoi</p><div class="site-description" itemprop="description">逢坂葵的个人博客</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">1026</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">20</span> <span class="site-state-item-name">分类</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/AisakaAoi" title="GitHub 👨‍💻 → https:&#x2F;&#x2F;github.com&#x2F;AisakaAoi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👨‍💻</a> </span><span class="links-of-author-item"><a href="https://github.com/Aisakaorz" title="GitHub 👩‍💻 → https:&#x2F;&#x2F;github.com&#x2F;Aisakaorz" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👩‍💻</a> </span><span class="links-of-author-item"><a href="mailto:aisakaaoi@qq.com" title="E-Mail 📧 → mailto:aisakaaoi@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 📧</a> </span><span class="links-of-author-item"><a href="mailto:chenzongnan@m.scnu.edu.cn" title="E-Mail 🏫 → mailto:chenzongnan@m.scnu.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 🏫</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/91560309" title="Bilibili 📺 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;91560309" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 📺</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/198562921" title="Bilibili 🎮 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;198562921" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 🎮</a> </span><span class="links-of-author-item"><a href="https://www.youtube.com/channel/UCALvyn5Cl76GCotO9pczvjg" title="YouTube 📺 → https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCALvyn5Cl76GCotO9pczvjg" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube 📺</a></span></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2026</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Aisaka Aoi</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">4m</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">167:37</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll(".pdfobject-container").forEach(e=>{var t=e.dataset.target,a="#"+Object.entries({navpanes:0,toolbar:0,statusbar:0,pagemode:"thumbs",view:"FitH"}).map(([e,t])=>e+"="+encodeURIComponent(t)).join("&"),r="/lib/pdf/web/viewer.html?file="+encodeURIComponent(t)+a;NexT.utils.supportsPDFs()?e.innerHTML=`<embed class="pdfobject" src="${t+a}" type="application/pdf" style="height: ${e.dataset.height};">`:e.innerHTML=`<iframe src="${r}" style="height: ${e.dataset.height};" frameborder="0"></iframe>`})</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//unpkg.com/valine/dist/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!0,notify:!0,appId:"UqjWdRYbIUEUQRXhBUUIh1QE-gzGzoHsz",appKey:"gj89JXC485PFbpdHLKVkz6dm",placeholder:"这里可以发送评论~（上面可以输入昵称、邮箱）",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{jsonPath:"/live2dw/assets/assets/haru02.model.json"},display:{position:"right",width:208,height:520},mobile:{show:!1},log:!1})</script></body></html>