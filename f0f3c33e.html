<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><meta name="baidu-site-verification" content="code-KCMz4b3cnd"><meta name="google-site-verification" content="MTp8U7dJ1uzrfz8Mu6rgqX1CIm3HjqPWd0xaRcv1tFg"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png"><link rel="mask-icon" href="/images/favicon.png" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"aisakaaoi.top",root:"/",scheme:"Pisces",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="本次的学习报告分享，是基于IEEE在2021年4月发布的《An Attention-Based Deep Learning Approach for Sleep Stage Classification With Single-Channel EEG》论文进行的讲解。本论文旨在介绍一种基于注意力的单通道脑电睡眠分期的深度学习算法，作者提出了一种新的基于注意力的深度学习架构，利用单通道脑电图信号对睡"><meta property="og:type" content="article"><meta property="og:title" content="学习报告：一种基于注意力的单通道脑电睡眠分期的深度学习算法"><meta property="og:url" content="https://aisakaaoi.top/f0f3c33e.html"><meta property="og:site_name" content="逢坂葵的个人博客"><meta property="og:description" content="本次的学习报告分享，是基于IEEE在2021年4月发布的《An Attention-Based Deep Learning Approach for Sleep Stage Classification With Single-Channel EEG》论文进行的讲解。本论文旨在介绍一种基于注意力的单通道脑电睡眠分期的深度学习算法，作者提出了一种新的基于注意力的深度学习架构，利用单通道脑电图信号对睡"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://aisakaaoi.top/f0f3c33e/1.webp"><meta property="og:image" content="https://aisakaaoi.top/f0f3c33e/2.webp"><meta property="og:image" content="https://aisakaaoi.top/f0f3c33e/3.webp"><meta property="og:image" content="https://aisakaaoi.top/f0f3c33e/4.webp"><meta property="og:image" content="https://aisakaaoi.top/f0f3c33e/5.webp"><meta property="og:image" content="https://aisakaaoi.top/f0f3c33e/6.webp"><meta property="og:image" content="https://aisakaaoi.top/f0f3c33e/7.webp"><meta property="og:image" content="https://aisakaaoi.top/f0f3c33e/8.webp"><meta property="article:published_time" content="2022-04-28T17:30:49.000Z"><meta property="article:modified_time" content="2025-07-21T17:38:53.625Z"><meta property="article:author" content="Aisaka Aoi"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://aisakaaoi.top/f0f3c33e/1.webp"><link rel="canonical" href="https://aisakaaoi.top/f0f3c33e.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>学习报告：一种基于注意力的单通道脑电睡眠分期的深度学习算法 | 逢坂葵的个人博客</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?7308ed05421777c301eefa3754da1b42",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="逢坂葵的个人博客" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">aoi学院</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">Aisaka's Blog, School of Aoi, Aisaka University</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">50</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">9</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">864</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div><a href="https://github.com/AisakaAoi" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://aisakaaoi.top/f0f3c33e.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/manatsu.jpg"><meta itemprop="name" content="Aisaka Aoi"><meta itemprop="description" content="Aisaka's Blog, School of Aoi, Aisaka University"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="逢坂葵的个人博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">学习报告：一种基于注意力的单通道脑电睡眠分期的深度学习算法</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-04-29 01:30:49" itemprop="dateCreated datePublished" datetime="2022-04-29T01:30:49+08:00">2022-04-29</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">🌙进阶学习</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%A0%94%E7%A9%B6%E5%9B%A2%E9%98%9F%EF%BC%88BCI%E5%9B%A2%E9%98%9F%EF%BC%89/" itemprop="url" rel="index"><span itemprop="name">⭐脑机接口与混合智能研究团队（BCI团队）</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%A0%94%E7%A9%B6%E5%9B%A2%E9%98%9F%EF%BC%88BCI%E5%9B%A2%E9%98%9F%EF%BC%89/%F0%9F%92%AB%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/" itemprop="url" rel="index"><span itemprop="name">💫学习报告</span></a> </span></span><span id="/f0f3c33e.html" class="post-meta-item leancloud_visitors" data-flag-title="学习报告：一种基于注意力的单通道脑电睡眠分期的深度学习算法" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/f0f3c33e.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/f0f3c33e.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>6.2k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>15 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>本次的学习报告分享，是基于IEEE在2021年4月发布的《An Attention-Based Deep Learning Approach for Sleep Stage Classification With Single-Channel EEG》论文进行的讲解。本论文旨在介绍一种基于注意力的单通道脑电睡眠分期的深度学习算法，作者提出了一种新的基于注意力的深度学习架构，利用单通道脑电图信号对睡眠时期进行分类。结果表明，作者提出的AttnSleep框架在不同的评估指标方面均优于最先进的技术。</p><p>原文链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9417097">https://ieeexplore.ieee.org/abstract/document/9417097</a></p><span id="more"></span><hr><h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>睡眠对人类来说是一个重要的过程，因为它影响着他们日常活动的各个方面。研究表明，睡眠质量好的人类享有更好的健康和大脑功能[1]。另一方面，睡眠时间中断会导致一些睡眠障碍，如失眠或睡眠呼吸暂停症的[2]。特别是，睡眠阶段（如轻度睡眠和深度睡眠），对免疫系统、记忆、新陈代谢等都很重要。[3]–[5]。因此，通过睡眠监测和睡眠阶段分类来测量睡眠质量是非常理想的。睡眠专家通常根据多导睡眠描记术(PSG)来确定睡眠阶段，其中包括脑电图(EEG)、眼电图(EOG)、肛门肌电图(EMG)和心电图(ECG)[6]。单通道脑电图由于其易于使用，最近已成为睡眠监测的吸引力。特别是，PSG或单通道脑电图记录通常分为30秒的段，每个段由睡眠专家手动检查，然后分为六个阶段之一，即觉醒(W)、快速眼动(REM)和四个非快速眼动阶段(N1、N2、N3和N4)[7]。这个手工过程非常详尽、乏味和耗时。因此，需要自动睡眠阶段分类系统来帮助睡眠专家。</p><p>许多研究采用了传统的机器学习方法，将脑电图信号分类为相应的睡眠阶段。这些方法通常包括人工特征提取和睡眠阶段分类两个步骤。首先，他们从时域和频域中设计和提取各种特征。特征选择算法经常被用于进一步选择最具鉴别性的特征。其次，将所选的特征输入传统的机器学习模型用于睡眠阶段分类，如朴素贝叶斯[8]、支持向量机(SVM)[9]、[10]、随机森林(RF)[7]、[11]，甚至是基于集成学习的类因符[12]。然而，这些方法需要领域知识来提取最佳的代表性特征。</p><hr><h3 id="提出的方法"><a href="#提出的方法" class="headerlink" title="提出的方法"></a>提出的方法</h3><p>作者提出了一种新的AttnSleep架构，用于自动睡眠阶段分类。首先提出了一种新的基于多分辨率CNN(MRCNN)和自适应特征重新校准(AFR)的特征提取模块。MRCNN从不同频带中提取低、高频对应的特征，AFR对特征的相互依赖性进行建模，以增强特征学习。其次提出了一种新的时间上下文编码器(TCE)，它部署了一个具有因果卷积的多头注意，以有效地捕获所提取的特征中的时间依赖性。作者还设计了一个类感知的损失函数，以有效地解决数据不平衡的问题，而不需要额外的计算。</p><img src="/f0f3c33e/1.webp"><div align="center">图一：提出的自动睡眠阶段分类的附加睡眠模型的总体框架。</div><p>作者提出的模型由三个主要的块组成，即1.特征提取、2.时间上下文编码器和3.分类。首先，利用具有双分支CNN体系结构的MRCNN，从一个30秒的脑电图信号中提取特征。特别是，它通过小核卷积提取高频特征，通过宽核卷积提取低频特征。在MRCNN之后，提出了一个AFR模块来建模由MRCNN提取的特征之间的相互依赖关系。</p><p>此外，AFR还可以自适应地选择和突出最重要的特征，这有助于提高分类性能。其次，作者开发了一个TCE模块来捕获输入特性中的长期依赖关系。TCE的核心成分是由因果卷积支持的多头注意力。第三，分类决策是由一个具有softmax激活函数的全连通层来完成的。利用一个类感知的成本敏感损失函数来处理数据不平衡问题。</p><img src="/f0f3c33e/2.webp"><div align="center">图二：用于特征提取的MRCNN和AFR模块，每个卷积块之后都有一个批处理归一化。</div><p>多分辨率CNN（MRCNN）：为了提取不同类型的特征，作者开发了一个多分辨率的CNN架构，如图一所示，实现了两个具有不同核大小的卷积层的分支，其中核大小的选择与脑电图信号的采样率有关，旨在探索不同的频带。自适应特征重新校准(AFR)：AFR旨在重新校准MRCNN学习到的特性，以提高其性能。特别是AFR对特征之间的相互依赖关系进行建模，并通过残差挤压和激励块自适应地选择最具鉴别性的特征。</p><img src="/f0f3c33e/3.webp"><div align="center">图三：提出的多头注意事项的结构</div><p>TCE层旨在捕获输入特征中的时间依赖性。如图一所示，TCE层由一个多头注意(MHA)层、一个归一化层和两个FC层组成。此外，TCE堆叠了两个相同的结构来生成最终的特征。</p><hr><h3 id="实验及结果"><a href="#实验及结果" class="headerlink" title="实验及结果"></a>实验及结果</h3><p>在实验中，使用了三个公共数据集，即sleep-edf-20、sleep-edf-78和睡眠心脏健康研究(SHHS)，如表一所示。对于每个数据集，我们在不同的实验中使用了单一的脑电图通道。</p><img src="/f0f3c33e/4.webp"><div align="center">表一：在我们的实验中使用的三个数据集的细节（每个样本是一个30秒的时期）</div><p>表二、表三和表四显示了所提模型在Fpz-Cz信道上的应用的混淆矩阵，sleep-edf数据集和SHHS数据集中的C4-A1通道。混淆矩阵的计算方法是将测试数据的所有评分值相加。每一行表示专家分类的样本数量，而每一列表示我们的模型预测的时代数。表格中还显示了每个类的精度、查全率、F1分数和GM平均值。</p><img src="/f0f3c33e/5.webp"><div align="center">表二：在edf-20数据集的fpz-cz通道上应用的模型的混淆矩阵</div><img src="/f0f3c33e/6.webp"><div align="center">表三：在edf-78数据集的fpz-cz信道上应用的模型的混淆矩阵</div><img src="/f0f3c33e/7.webp"><div align="center">表四：在SHHS数据集的c4-a1通道上提出的模型的混淆矩阵</div><p>值得注意的是，睡眠阶段N1在F1小于50%时获得的性能，其中它经常被错误地分类为W、REM和N2类。同样，N3类对Sleep-EDF-20和SHHS数据集的性能最好，但对Sleep-EDF-78的性能下降，因为它是该数据集上的少数类。不同数据集中的大多数错误分类都是N2类，因为它是大多数类。</p><hr><h3 id="与最先进方法的比较"><a href="#与最先进方法的比较" class="headerlink" title="与最先进方法的比较"></a>与最先进方法的比较</h3><p>表五显示了DeppSleepNet[20]、SleepEEGNet24]、ResnetnetLSTM[43]、MultitaskCNN[17]和我们的AttnSleep之间的比较。我们观察到，我们的AttnSleep由于其强大的特征提取模块，比其他四种方法具有更好的分类性能。特别是，我们的AttnSleep在Sleep-EDF-78和SHHS上实现了更好的MF1和MGm，这表明设计的成本敏感损失函数有助于处理不平衡的数据。此外，我们可以观察到，我们的AttnSleep在N1类中的表现低于[20]，[24]。因此，我们的AttnSleep倾向于将N1错误地归类为其他类别，包括W和REM，这也在表二、表三和表四中的混淆矩阵中得到了证明。</p><img src="/f0f3c33e/8.webp"><div align="center">表五：AttnSleep模型与最先进模型之间的比较。每个数据集上的最佳值将以粗体突出显示</div><hr><h3 id="学习总结"><a href="#学习总结" class="headerlink" title="学习总结"></a>学习总结</h3><p>该论文作者提出了一种新的睡眠阶段分类结构，称为AttnSleep。AttnSleep依赖于利用多分辨率卷积神经网络(MRCNN)和自适应特征重新校准(AFR)两个模块来提取脑特征。这两个模块之后是时间上下文编码器(TCE)模块，该模块通过使用多头注意(MHA)机制来捕获所提取的特征之间的时间依赖性。在三个公共数据集上的实验结果表明了该模型在各种评估矩阵下优于最先进的方法。</p><p>此外，还进行了消融研究，以证明该方法中各模块的有效性。最后进行了敏感性分析来证明MHA中头部数量的影响。结果表明，该方法在不同的头数下是相当稳定的。对于未来的发展方向，将考虑迁移学习和领域自适应技术，该技术采用在标记数据集上训练的模型，以对其他数据集中的未标记睡眠数据进行分类。</p><hr><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><blockquote><p>[1] F. S. Luyster, P. J. Strollo, P. C. Zee, and J. K. Walsh, “Sleep: A health imperative,” Sleep, vol. 35, no. 6, pp. 727–734, Jun. 2012.<br>[2] P. H. Finan et al., “Partial sleep deprivation attenuates the positive affective system: Effects across multiple measurement modalities,” Sleep, vol. 40, no. 1, pp. 1–9, Jan. 2017.<br>[3] G. Rauchs, B. Desgranges, J. Foret, and F. Eustache, “The relationship between memory systems and sleep stages,” J. Sleep Res., vol. 14, no. 2, pp. 123–140, 2005.<br>[4] S. Sharma and M. Kavuru, “Sleep and metabolism: An overview,” Int.J. Endocrinol., vol. 2010, pp. 1–12, Oct. 2010.<br>[5] J. Tank et al., “Relationship between blood pressure, sleep Kcomplexes, and muscle sympathetic nerve activity in humans,” Amer. J. Physiol.-Regulatory, Integrative Comparative Physiol., vol. 285, no. 1, pp. R208–R214, Jul. 2003.<br>[6] A. S. Keenan, “An overview of polysomnography,” in Handbook of Clinical Neurophysiology, vol. 6. Amsterdam, The Netherlands: Elsevier, 2005, ch. 3, pp. 33–50.<br>[7] P. Memar and F. Faradji, “A novel multi-class EEG-based sleep stage classifification system,” IEEE Trans. Neural Syst. Rehabil. Eng., vol. 26, no. 1, pp. 84–95, Jan. 2018.<br>[8] S. I. Dimitriadis, C. Salis, and D. Linden, “A novel, fast and effificient single-sensor automatic sleep-stage classifification based on complementary cross-frequency coupling estimates,” Clin. Neurophysiol., vol. 129, no. 4, pp. 815–828, Apr. 2018.<br>[9] G. Zhu, Y. Li, and P. Wen, “Analysis and classifification of sleep stages based on difference visibility graphs from a single-channel EEG signal,” IEEE J. Biomed. Health Informat., vol. 18, no. 6, pp. 1813–1821, Nov. 2014.<br>[10] S. Seifpour, H. Niknazar, M. Mikaeili, and A. M. Nasrabadi, “A new automatic sleep staging system based on statistical behavior of local extrema using single channel EEG signal,” Expert Syst. Appl., vol. 104, pp. 277–293, Aug. 2018.<br>[11] X. Li, L. Cui, S. Tao, J. Chen, X. Zhang, and G.-Q. Zhang, “HyCLASSS: A hybrid classififier for automatic sleep stage scoring,” IEEE J. Biomed. Health Informat., vol. 22, no. 2, pp. 375–385, Mar. 2018.<br>[12] A. R. Hassan and M. I. H. Bhuiyan, “Computer-aided sleep staging using complete ensemble empirical mode decomposition with adaptive noise and bootstrap aggregating,” Biomed. Signal Process. Control, vol. 24, pp. 1–10, Feb. 2016.<br>[20] A. Supratak, H. Dong, C. Wu, and Y. Guo, “DeepSleepNet: A model for automatic sleep stage scoring based on raw single-channel EEG,” IEEE Trans. Neural Syst. Rehabil. Eng., vol. 25, no. 11, pp. 1998–2008, Nov. 2017.<br>[24] S. Mousavi, F. Afghah, and U. R. Acharya, “SleepEEGNet: Automated sleep stage scoring with sequence to sequence deep learning approach,” PLoS ONE, vol. 14, no. 5, May 2019, Art. no. e0216456.<br>[43] Y. Sun, B. Wang, J. Jin, and X. Wang, “Deep convolutional network method for automatic sleep stage classifification based on neurophysiological signals,” in Proc. 11th Int. Congr. Image Signal Process., Biomed. Eng. Informat. (CISP-BMEI), Oct. 2018, pp. 1–5.</p></blockquote><hr><h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote><p><a target="_blank" rel="noopener" href="https://www.scholat.com/teamwork/showPostMessage.html?id=11633">https://www.scholat.com/teamwork/showPostMessage.html?id=11633</a></p></blockquote></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-item"><a href="/a9f4bc51.html" rel="prev" title="跟李沐学AI-读论文-视频理解论文串讲（下） 论文精读"><i class="fa fa-chevron-left"></i> 跟李沐学AI-读论文-视频理解论文串讲（下） 论文精读</a></div><div class="post-nav-item"><a href="/3e0089b7.html" rel="next" title="脑机接口与混合智能-新闻-植入脑机接口离临床应用还有多远？">脑机接口与混合智能-新闻-植入脑机接口离临床应用还有多远？ <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let t=CONFIG.comments["activeClass"];var e;(t=CONFIG.comments.storage?localStorage.getItem("comments_active")||t:t)&&(e=document.querySelector(`a[href="#comment-${t}"]`))&&e.click()}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF"><span class="nav-number">1.</span> <span class="nav-text">研究背景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8F%90%E5%87%BA%E7%9A%84%E6%96%B9%E6%B3%95"><span class="nav-number">2.</span> <span class="nav-text">提出的方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E5%8F%8A%E7%BB%93%E6%9E%9C"><span class="nav-number">3.</span> <span class="nav-text">实验及结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%8E%E6%9C%80%E5%85%88%E8%BF%9B%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83"><span class="nav-number">4.</span> <span class="nav-text">与最先进方法的比较</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93"><span class="nav-number">5.</span> <span class="nav-text">学习总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">6.</span> <span class="nav-text">参考文献</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E6%96%87%E9%93%BE%E6%8E%A5"><span class="nav-number">7.</span> <span class="nav-text">原文链接</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Aisaka Aoi" src="/images/manatsu.jpg"><p class="site-author-name" itemprop="name">Aisaka Aoi</p><div class="site-description" itemprop="description">逢坂葵的个人博客</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">864</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">50</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">9</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/AisakaAoi" title="GitHub 👨‍💻 → https:&#x2F;&#x2F;github.com&#x2F;AisakaAoi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👨‍💻</a> </span><span class="links-of-author-item"><a href="https://github.com/AisakaManatsu" title="GitHub 👩‍💻 → https:&#x2F;&#x2F;github.com&#x2F;AisakaManatsu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👩‍💻</a> </span><span class="links-of-author-item"><a href="mailto:chenzongnan@m.scnu.edu.cn" title="E-Mail 🏫 → mailto:chenzongnan@m.scnu.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 🏫</a> </span><span class="links-of-author-item"><a href="mailto:aisakaaoi@qq.com" title="E-Mail 📧 → mailto:aisakaaoi@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 📧</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/91560309" title="Bilibili 📺 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;91560309" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 📺</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/198562921" title="Bilibili 🎮 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;198562921" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 🎮</a> </span><span class="links-of-author-item"><a href="https://www.youtube.com/channel/UCALvyn5Cl76GCotO9pczvjg" title="YouTube 📺 → https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCALvyn5Cl76GCotO9pczvjg" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube 📺</a></span></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Aisaka Aoi</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">2.7m</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">112:21</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll(".pdfobject-container").forEach(e=>{var t=e.dataset.target,a="#"+Object.entries({navpanes:0,toolbar:0,statusbar:0,pagemode:"thumbs",view:"FitH"}).map(([e,t])=>e+"="+encodeURIComponent(t)).join("&"),r="/lib/pdf/web/viewer.html?file="+encodeURIComponent(t)+a;NexT.utils.supportsPDFs()?e.innerHTML=`<embed class="pdfobject" src="${t+a}" type="application/pdf" style="height: ${e.dataset.height};">`:e.innerHTML=`<iframe src="${r}" style="height: ${e.dataset.height};" frameborder="0"></iframe>`})</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//unpkg.com/valine/dist/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!0,notify:!0,appId:"UqjWdRYbIUEUQRXhBUUIh1QE-gzGzoHsz",appKey:"gj89JXC485PFbpdHLKVkz6dm",placeholder:"这里可以发送评论~（上面可以输入昵称、邮箱）",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{jsonPath:"/live2dw/assets/assets/haru02.model.json"},display:{position:"right",width:208,height:520},mobile:{show:!1},log:!1})</script></body></html>