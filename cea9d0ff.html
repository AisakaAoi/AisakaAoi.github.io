<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><meta name="baidu-site-verification" content="code-KCMz4b3cnd"><meta name="google-site-verification" content="MTp8U7dJ1uzrfz8Mu6rgqX1CIm3HjqPWd0xaRcv1tFg"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png"><link rel="mask-icon" href="/images/favicon.png" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"aisakaaoi.github.io",root:"/",scheme:"Pisces",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="DeepID1: Deep Learning Face Representation from Predicting 10,000 Classes(CVPR2014) DeepID2: Deep Learning Face Representation by Joint Identification-Verification(CVPR2015) DeepID2+: Deeply learned f"><meta property="og:type" content="article"><meta property="og:title" content="人脸识别-DeepID1 DeepID2 DeepID2+ DeepID3"><meta property="og:url" content="https://aisakaaoi.github.io/cea9d0ff.html"><meta property="og:site_name" content="逢坂葵的个人博客"><meta property="og:description" content="DeepID1: Deep Learning Face Representation from Predicting 10,000 Classes(CVPR2014) DeepID2: Deep Learning Face Representation by Joint Identification-Verification(CVPR2015) DeepID2+: Deeply learned f"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/1.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/2.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/3.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/4.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/5.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/6.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/7.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/8.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/9.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/10.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/11.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/12.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/13.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/14.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/15.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/16.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/17.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/18.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/19.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/20.webp"><meta property="og:image" content="https://aisakaaoi.github.io/cea9d0ff/21.webp"><meta property="article:published_time" content="2022-10-13T18:36:10.000Z"><meta property="article:modified_time" content="2024-09-04T10:21:28.579Z"><meta property="article:author" content="Aisaka Aoi"><meta property="article:tag" content="☄️人脸识别 Face Recognition"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://aisakaaoi.github.io/cea9d0ff/1.webp"><link rel="canonical" href="https://aisakaaoi.github.io/cea9d0ff.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>人脸识别-DeepID1 DeepID2 DeepID2+ DeepID3 | 逢坂葵的个人博客</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?7308ed05421777c301eefa3754da1b42",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="逢坂葵的个人博客" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">aoi学院</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">Aisaka's Blog, School of Aoi, Aisaka University</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">50</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">9</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">865</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div><a href="https://github.com/AisakaAoi" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://aisakaaoi.github.io/cea9d0ff.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/manatsu.jpg"><meta itemprop="name" content="Aisaka Aoi"><meta itemprop="description" content="Aisaka's Blog, School of Aoi, Aisaka University"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="逢坂葵的个人博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">人脸识别-DeepID1 DeepID2 DeepID2+ DeepID3</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-10-14 02:36:10" itemprop="dateCreated datePublished" datetime="2022-10-14T02:36:10+08:00">2022-10-14</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">🌙进阶学习</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">⭐人工智能 Artificial Intelligence</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-Artificial-Intelligence/%F0%9F%92%AB%E7%A0%94%E7%A9%B6%E9%A2%86%E5%9F%9F-Research-Area/" itemprop="url" rel="index"><span itemprop="name">💫研究领域 Research Area</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-Artificial-Intelligence/%F0%9F%92%AB%E7%A0%94%E7%A9%B6%E9%A2%86%E5%9F%9F-Research-Area/%F0%9F%9B%B0%EF%B8%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">🛰️计算机视觉 Computer Vision</span></a> </span></span><span id="/cea9d0ff.html" class="post-meta-item leancloud_visitors" data-flag-title="人脸识别-DeepID1 DeepID2 DeepID2+ DeepID3" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/cea9d0ff.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/cea9d0ff.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>4.7k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>12 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>DeepID1: <a target="_blank" rel="noopener" href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Sun_Deep_Learning_Face_2014_CVPR_paper.pdf">Deep Learning Face Representation from Predicting 10,000 Classes(CVPR2014)</a></p><p>DeepID2: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1406.4773">Deep Learning Face Representation by Joint Identification-Verification(CVPR2015)</a></p><p>DeepID2+: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1412.1265">Deeply learned face representations are sparse, selective, and robust</a></p><p>DeepID3: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.00873">Face Recognition with Very Deep Neural Networks</a></p><span id="more"></span><hr><h3 id="DeepID1"><a href="#DeepID1" class="headerlink" title="DeepID1"></a>DeepID1</h3><h4 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h4><ol><li>DeepID1通过深度学习学习到一组高级特征表示集合（被称为Deep hidden IDentitiy feature）用于face verification。</li><li>然而，文章并没有用二类分类实现，而是通过学习一个多类（10000类，每个类大约有20个实例）人脸识别任务来学习特征，并把特征泛化到face varification和其他unseen新的identification。<strong>同时指出，随着训练时要预测的人脸类越多，DeepID的泛化能力就越强。</strong>对所有的identities进行多类分类，而不是二值分类，<strong>基于两个考虑：一是，把一个训练样本训练成多个类中的一类，比进行二值分类更困难，这个挑战能够充分利用神经网络的超级学习能力以提取有效特征；二是，隐含的对ConvNet上增加了强规则化，帮助产生对分类有效的共享隐藏层表示。因此，学习到的特征有好的泛化能力。</strong></li><li>关于网络。沿着特征抽取的层次，不断的减少神经元的个数，就会逐渐在高层形成紧致的和identity有关的只有少量隐藏神经元的特征。DeepID特征取自最后一个隐藏层的激活值。<strong>使DeepID 明显少于预测的类别数，对学习到高度紧致和具有判别性的特征很重要。</strong>从多个人脸区域中抽取特征，形成相互补充和超完备的表示。</li><li>DeepID和其他的人脸分类器（如 Joint Bayesian）相整合。</li></ol><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><img src="/cea9d0ff/1.webp"><p>一共4个卷积层，其中前三个卷积层后都有一个max-pooling layer。注意最后一个卷积层相当小（1*2的feature map）。正因为太小，是信息传递的瓶颈，所以，第一个全连接层（DeepID层，160维）同时全连接到最后一个卷积层和第三个卷积层（池化后）。最后一个全连接层是学习类别分布的，若类别数是10000，则该层维度是10000。</p><p><strong>注意：DeepID只有160维，而类别数却较大，正是因为这样，帮助学习到紧致和具有判别性的特征。</strong></p><h4 id="Face-verification"><a href="#Face-verification" class="headerlink" title="Face verification"></a>Face verification</h4><p>进行人脸确认，要有两个步骤：特征抽取+确认学习</p><h5 id="Feature-extraction"><a href="#Feature-extraction" class="headerlink" title="Feature extraction"></a>Feature extraction</h5><p>从人脸图像中选取10个区域，3个尺度，RGB和gray图像块共60个块，每个块及其水平翻转抽取160维的特征。这样整个DeepID的长度是160 * 60 * 2。</p><h5 id="face-verification"><a href="#face-verification" class="headerlink" title="face verification"></a>face verification</h5><p>分别采用Joint Bayesian和构建深度网络分别进行。实验表明Joint Bayesian较好。<br>用于face verification的深度网络如图：</p><img src="/cea9d0ff/2.webp"><p>实验表明，块提取的越多，性能就又进一步提高。</p><img src="/cea9d0ff/3.webp"><p>最后，通过扩充CelebFace数据库到CelebFace+,包含10177个人202599张图片。最终在LFW上获得了97.45%的准确率。</p><h4 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h4><p>为了表明提出算法的有效性，进行了如下几个方面的实验：</p><h5 id="Multi-scale-ConvNets"><a href="#Multi-scale-ConvNets" class="headerlink" title="Multi-scale ConvNets"></a>Multi-scale ConvNets</h5><p>验证第三个卷积层（池化后）全连接到DeepID层的有效性，通过去掉这个连接和带上这个连接进行比较。</p><img src="/cea9d0ff/4.webp"><h5 id="Learning-effective-features"><a href="#Learning-effective-features" class="headerlink" title="Learning effective features"></a>Learning effective features</h5><p>表明：同时对大量的identities进行分类对学习到具有判别性和紧致的隐藏特征是关键。<br>做法：指数级增加identity classes，通过top-1验证误差率观察分类能力，通过测试集的确认精确度观察学习到的隐藏层特征的性能。</p><img src="/cea9d0ff/5.webp"><h5 id="Over-complete-representation"><a href="#Over-complete-representation" class="headerlink" title="Over-complete representation"></a>Over-complete representation</h5><p>评估：多少个块的组合对性能的贡献大<br>做法：分别从有k（k&#x3D;1,5,15,30,60）个块组成的特征训练face verification model.<br>表明：越多的特征，性能越好</p><h5 id="Method-comparison"><a href="#Method-comparison" class="headerlink" title="Method comparison"></a>Method comparison</h5><p>和其他算法比较性能。</p><hr><h3 id="DeepID2"><a href="#DeepID2" class="headerlink" title="DeepID2"></a>DeepID2</h3><p>人脸识别的关键挑战是开发有效的特征表示以减少类内变化增大类间变化。作者同时使用face identification 和 verification信号进行监督学习。face identification增大类间的变化，face verification减少类内变化。在LFW数据库上得到了99.15%人脸确认率。</p><p>4个实验：</p><h4 id="Balancing-the-identification-and-verification-signals"><a href="#Balancing-the-identification-and-verification-signals" class="headerlink" title="Balancing the identification and verification signals"></a>Balancing the identification and verification signals</h4><p>调查两种信号间的相互作用，通过在verification signal上加个系数λ，让λ从0变化到+∞。</p><p>（1）首先报告了随着λ变化，face verification accuracy 的变化曲线，说明单独使用一种信号都是不是最优的，两者的结合能够达取得有效的特征。</p><p>（2）分析产生这个现象的原因。</p><p>一方面进行分析：类内类间的方差对应相应散度矩阵的特征值。如果所有的特征方差集中在一小部分的特征向量上，意味着类内或类间的变化很小。</p><p>另一方面，以图示的方式展示6个identities的PCA特征的前两维。λ&#x3D;0.05的时候簇的效果要好一些。</p><h4 id="Rich-identity-information-improves-feature-learning"><a href="#Rich-identity-information-improves-feature-learning" class="headerlink" title="Rich identity information improves feature learning"></a>Rich identity information improves feature learning</h4><p>指数增加参与训练的identity数，报告随着类别数的增加，verification accuracy 的增加。</p><h4 id="Investigating-the-verification-signals"><a href="#Investigating-the-verification-signals" class="headerlink" title="Investigating the verification signals"></a>Investigating the verification signals</h4><p>比较加入verification signal，不加verification signal，只加入L2+（只减少同一类的距离），只加入L2-（只增加不同类间的距离），采用L1 norm 的verification signal和 采用cosine verification signal的verification accuracy.</p><p>表明：（1）采用L2norm的verification signal要比L1 norm 和 cosine 的好；（2）加入verification 比不加好；（3）L2+的效果和L2 norm 接近，而L2-的效果要差，说明：verification主要是增加类内的紧致度，而identification是反应类间的变化。</p><h4 id="和其他方法的比较。"><a href="#和其他方法的比较。" class="headerlink" title="和其他方法的比较。"></a>和其他方法的比较。</h4><hr><h3 id="DeepID2-1"><a href="#DeepID2-1" class="headerlink" title="DeepID2+"></a>DeepID2+</h3><h4 id="与DeepID2相比的变化"><a href="#与DeepID2相比的变化" class="headerlink" title="与DeepID2相比的变化"></a>与DeepID2相比的变化</h4><p>有三点：</p><ol><li>隐藏层的maps数增加。4个卷积层（原来的feature maps 分别是 20,40,60,80）在原来基础上再增加128； fc4层从160增加到512。</li><li>训练数据增加了CelebFaces+ dataset，WDRef，和一些新收集到的个体。<br>这个数据集有12，000个个体的大约290,000张图片。（原来的8,000个个体，160,000张图片）</li><li>监督信号不仅在FC4上有，DeepID2+在早期的每个卷积层的后面都加了一个512为的全连接层，并添加identification-verification的监督信号。</li></ol><img src="/cea9d0ff/6.webp"><h4 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h4><p>这是这篇paper的亮点，分析了提取特征的特点，应当说是填补了目前深度学习研究的一个空白。需要仔细研究作者的处理方法和理解问题角度。</p><h5 id="分析DeepID2-nets网络的高性能"><a href="#分析DeepID2-nets网络的高性能" class="headerlink" title="分析DeepID2+ nets网络的高性能"></a>分析DeepID2+ nets网络的高性能</h5><p>如果是我，我可能只会想到用自己算法的结果跟别的算法比较，而作者除此以外，将他们的三个改进分别去掉一个，和三个改进都用上的结构分别比较，结果表明作者这三个方面的任何一个地方去掉都会对性能有影响。并且报告了fc1 fc2 fc3 fc4上的结果。</p><img src="/cea9d0ff/7.webp"><h5 id="神经元激活值的中等稀疏性"><a href="#神经元激活值的中等稀疏性" class="headerlink" title="神经元激活值的中等稀疏性"></a>神经元激活值的中等稀疏性</h5><p>稀疏性体现在两个方面：一是，每个图像，大约有一半的神经元是被激活的；二是，对每个神经元，在大约一半的图像是是被激活的。</p><p>图像的中等稀疏性，使得不同身份的人脸图像具有最大的可区分性；神经元的中等稀疏性，使得他们能够有最大的判别能力。</p><p><strong>作者的验证方法：一是，计算验证集中46，594张图像的被激活的神经元数（下图左）；二是，计算每个神经元是激活状态的图像数。</strong></p><img src="/cea9d0ff/8.webp"><p>理解上图：left的单个bar表示有多少的图像的激活状态的神经元个数是x（横轴坐标）—&gt;反应每张图像对应的激活状态的神经元个数。</p><p>right的单个bar表示有多少个神经元在x（横轴坐标）上是被激活的—&gt;反应每个神经元是激活状态的图像数。</p><p><strong>另，进一步验证激活模式：验证神经元是否被激活比其精确值更重要。通过阈值的方式把激活值二值化，发现accuracy大约只下降1%。</strong></p><img src="/cea9d0ff/9.webp"><h5 id="对身份和属性的选择性"><a href="#对身份和属性的选择性" class="headerlink" title="对身份和属性的选择性"></a>对身份和属性的选择性</h5><p>作者通过以下三个方面进行分析：<br><strong>一、神经元的判别能力</strong><br><strong>二、神经元的兴奋与抑制</strong><br><strong>三、神经元激活值的分布</strong></p><h6 id="一、神经元的判别能力"><a href="#一、神经元的判别能力" class="headerlink" title="一、神经元的判别能力"></a>一、神经元的判别能力</h6><p>为了验证DeepID2+特征中每个神经元的判别能力，作者进行了两方面的实验：身份的二值分类（即是否属于某个人），属性的二值分类（是否拥有某个属性）。<br>Fig.8：属性分类的精确性，和不同维度的LBP特征进行比较。这部分用的特征是单个DeepID2+net产生的fc4特征+水平翻转图像的特征。<br>Fig.9：身份分类精度<br>Fig 10：属性分类精度。 Fig.9 和Fig. 10用的特征是：展示做好的一个特征（神经元）产生的分类精度，强有力的表明了学习到的特征对身份和属性的选择性。</p><img src="/cea9d0ff/10.webp"><h6 id="二、神经元的兴奋与抑制"><a href="#二、神经元的兴奋与抑制" class="headerlink" title="二、神经元的兴奋与抑制"></a>二、神经元的兴奋与抑制</h6><p>发现：是由于神经元对特定的身份和属性的兴奋与抑制模式，使得它们对身份和属性具有强的判别性。例如，在某个人或属性上兴奋的神经元，在其他人或属性上可能是抑制的。</p><img src="/cea9d0ff/11.webp"> <img src="/cea9d0ff/12.webp"> <img src="/cea9d0ff/13.webp"><p>上图中，由于特征取自图像及其水平翻转的fc4，因此，特征的维度是512*2&#x3D;1024.</p><h6 id="三、神经元的激活值分布"><a href="#三、神经元的激活值分布" class="headerlink" title="三、神经元的激活值分布"></a>三、神经元的激活值分布</h6><p>通过一些神经元值分布的例子，表明在某个身份或属性上兴奋的神经元，在其他的身份或属性上是抑制的。<br>Fig.13. 和Fig.14. 这里只粘了Fig.13</p><img src="/cea9d0ff/14.webp"> <img src="/cea9d0ff/15.webp"><p>上图中，每个直方图的横坐标，表示这个神经元的激活值。</p><h5 id="特征的鲁棒性"><a href="#特征的鲁棒性" class="headerlink" title="特征的鲁棒性"></a>特征的鲁棒性</h5><p>测试DeepID2+特征对遮挡的鲁棒性，发现：尽管特征是在没有人为遮挡的图像上训练的net上提取的，但是却自动地学习到了对遮挡鲁棒的特征。<br>做法：<br>将人脸进行如下两种人为遮挡，将遮挡的图像用于测试，将DeepID2+特征和LBP特征在LFW的结果进行比较。</p><img src="/cea9d0ff/16.webp"> <img src="/cea9d0ff/17.webp"> <img src="/cea9d0ff/18.webp"><p>另外，还给出了遮挡情况下每个神经元被激活的情况，图18和19.</p><img src="/cea9d0ff/19.webp"> <img src="/cea9d0ff/20.webp"><hr><h3 id="DeepID3"><a href="#DeepID3" class="headerlink" title="DeepID3"></a>DeepID3</h3><p>本文调查极深神经网络对人脸识别的作用。论文提出了用于人脸识别的两个非常深的神经网络结构（被称为DeepID3）。这两个结构在VGG和GooLeNet的基础上进行构建合适的结构，使得方便人脸识别。结果发现DeepID3的结果和DeepID2+相当，或许当有更多的训练数据时，能够提高性能，需要进一步研究。</p><img src="/cea9d0ff/21.webp"><hr><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote><p>版权声明：本文为CSDN博主「CH-Yuan」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/yuanchheneducn/article/details/51034463">https://blog.csdn.net/yuanchheneducn/article/details/51034463</a></p></blockquote></div><div class="popular-posts-header">相关文章</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="\3373677a.html" rel="bookmark">人脸识别-人脸识别技术全面总结：从传统方法到深度学习</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\fbc5e959.html" rel="bookmark">人脸识别-DeepID2-强大的人脸分类算法</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\d5ea2bb7.html" rel="bookmark">人脸识别-人脸识别系列（三）：DeepID2</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\ebc4aeea.html" rel="bookmark">人脸识别-DeepID3 face recognition</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\efc0281c.html" rel="bookmark">人脸识别-FaceNet-Google的人脸识别</a></div></li></ul><footer class="post-footer"><div class="post-tags"><a href="/tags/%E2%98%84%EF%B8%8F%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB-Face-Recognition/" rel="tag"># ☄️人脸识别 Face Recognition</a></div><div class="post-nav"><div class="post-nav-item"><a href="/727e6209.html" rel="prev" title="算法设计与分析-第5章"><i class="fa fa-chevron-left"></i> 算法设计与分析-第5章</a></div><div class="post-nav-item"><a href="/1d27acc4.html" rel="next" title="CCF学生领航计划（SPP）第十六期-《学术研究的基础经验交流》">CCF学生领航计划（SPP）第十六期-《学术研究的基础经验交流》 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let t=CONFIG.comments["activeClass"];var e;(t=CONFIG.comments.storage?localStorage.getItem("comments_active")||t:t)&&(e=document.querySelector(`a[href="#comment-${t}"]`))&&e.click()}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#DeepID1"><span class="nav-number">1.</span> <span class="nav-text">DeepID1</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E6%80%9D%E6%83%B3"><span class="nav-number">1.1.</span> <span class="nav-text">主要思想</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-number">1.2.</span> <span class="nav-text">网络结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Face-verification"><span class="nav-number">1.3.</span> <span class="nav-text">Face verification</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Feature-extraction"><span class="nav-number">1.3.1.</span> <span class="nav-text">Feature extraction</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#face-verification"><span class="nav-number">1.3.2.</span> <span class="nav-text">face verification</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Experiments"><span class="nav-number">1.4.</span> <span class="nav-text">Experiments</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Multi-scale-ConvNets"><span class="nav-number">1.4.1.</span> <span class="nav-text">Multi-scale ConvNets</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Learning-effective-features"><span class="nav-number">1.4.2.</span> <span class="nav-text">Learning effective features</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Over-complete-representation"><span class="nav-number">1.4.3.</span> <span class="nav-text">Over-complete representation</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Method-comparison"><span class="nav-number">1.4.4.</span> <span class="nav-text">Method comparison</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DeepID2"><span class="nav-number">2.</span> <span class="nav-text">DeepID2</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Balancing-the-identification-and-verification-signals"><span class="nav-number">2.1.</span> <span class="nav-text">Balancing the identification and verification signals</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Rich-identity-information-improves-feature-learning"><span class="nav-number">2.2.</span> <span class="nav-text">Rich identity information improves feature learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Investigating-the-verification-signals"><span class="nav-number">2.3.</span> <span class="nav-text">Investigating the verification signals</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%92%8C%E5%85%B6%E4%BB%96%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83%E3%80%82"><span class="nav-number">2.4.</span> <span class="nav-text">和其他方法的比较。</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DeepID2-1"><span class="nav-number">3.</span> <span class="nav-text">DeepID2+</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8EDeepID2%E7%9B%B8%E6%AF%94%E7%9A%84%E5%8F%98%E5%8C%96"><span class="nav-number">3.1.</span> <span class="nav-text">与DeepID2相比的变化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90"><span class="nav-number">3.2.</span> <span class="nav-text">实验分析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%86%E6%9E%90DeepID2-nets%E7%BD%91%E7%BB%9C%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD"><span class="nav-number">3.2.1.</span> <span class="nav-text">分析DeepID2+ nets网络的高性能</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E5%85%83%E6%BF%80%E6%B4%BB%E5%80%BC%E7%9A%84%E4%B8%AD%E7%AD%89%E7%A8%80%E7%96%8F%E6%80%A7"><span class="nav-number">3.2.2.</span> <span class="nav-text">神经元激活值的中等稀疏性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AF%B9%E8%BA%AB%E4%BB%BD%E5%92%8C%E5%B1%9E%E6%80%A7%E7%9A%84%E9%80%89%E6%8B%A9%E6%80%A7"><span class="nav-number">3.2.3.</span> <span class="nav-text">对身份和属性的选择性</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E7%A5%9E%E7%BB%8F%E5%85%83%E7%9A%84%E5%88%A4%E5%88%AB%E8%83%BD%E5%8A%9B"><span class="nav-number">3.2.3.1.</span> <span class="nav-text">一、神经元的判别能力</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E7%A5%9E%E7%BB%8F%E5%85%83%E7%9A%84%E5%85%B4%E5%A5%8B%E4%B8%8E%E6%8A%91%E5%88%B6"><span class="nav-number">3.2.3.2.</span> <span class="nav-text">二、神经元的兴奋与抑制</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E7%A5%9E%E7%BB%8F%E5%85%83%E7%9A%84%E6%BF%80%E6%B4%BB%E5%80%BC%E5%88%86%E5%B8%83"><span class="nav-number">3.2.3.3.</span> <span class="nav-text">三、神经元的激活值分布</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E7%9A%84%E9%B2%81%E6%A3%92%E6%80%A7"><span class="nav-number">3.2.4.</span> <span class="nav-text">特征的鲁棒性</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DeepID3"><span class="nav-number">4.</span> <span class="nav-text">DeepID3</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">5.</span> <span class="nav-text">参考资料</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Aisaka Aoi" src="/images/manatsu.jpg"><p class="site-author-name" itemprop="name">Aisaka Aoi</p><div class="site-description" itemprop="description">逢坂葵的个人博客</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">865</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">50</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">9</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/AisakaAoi" title="GitHub 👨‍💻 → https:&#x2F;&#x2F;github.com&#x2F;AisakaAoi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👨‍💻</a> </span><span class="links-of-author-item"><a href="https://github.com/Aisakaorz" title="GitHub 👩‍💻 → https:&#x2F;&#x2F;github.com&#x2F;Aisakaorz" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👩‍💻</a> </span><span class="links-of-author-item"><a href="mailto:aisakaaoi@qq.com" title="E-Mail 📧 → mailto:aisakaaoi@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 📧</a> </span><span class="links-of-author-item"><a href="mailto:chenzongnan@m.scnu.edu.cn" title="E-Mail 🏫 → mailto:chenzongnan@m.scnu.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 🏫</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/91560309" title="Bilibili 📺 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;91560309" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 📺</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/198562921" title="Bilibili 🎮 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;198562921" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 🎮</a> </span><span class="links-of-author-item"><a href="https://www.youtube.com/channel/UCALvyn5Cl76GCotO9pczvjg" title="YouTube 📺 → https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCALvyn5Cl76GCotO9pczvjg" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube 📺</a></span></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Aisaka Aoi</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">2.7m</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">112:48</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll(".pdfobject-container").forEach(e=>{var t=e.dataset.target,a="#"+Object.entries({navpanes:0,toolbar:0,statusbar:0,pagemode:"thumbs",view:"FitH"}).map(([e,t])=>e+"="+encodeURIComponent(t)).join("&"),r="/lib/pdf/web/viewer.html?file="+encodeURIComponent(t)+a;NexT.utils.supportsPDFs()?e.innerHTML=`<embed class="pdfobject" src="${t+a}" type="application/pdf" style="height: ${e.dataset.height};">`:e.innerHTML=`<iframe src="${r}" style="height: ${e.dataset.height};" frameborder="0"></iframe>`})</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//unpkg.com/valine/dist/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!0,notify:!0,appId:"UqjWdRYbIUEUQRXhBUUIh1QE-gzGzoHsz",appKey:"gj89JXC485PFbpdHLKVkz6dm",placeholder:"这里可以发送评论~（上面可以输入昵称、邮箱）",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{jsonPath:"/live2dw/assets/assets/haru02.model.json"},display:{position:"right",width:208,height:520},mobile:{show:!1},log:!1})</script></body></html>