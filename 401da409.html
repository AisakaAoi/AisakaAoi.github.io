<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><meta name="baidu-site-verification" content="code-KCMz4b3cnd"><meta name="google-site-verification" content="MTp8U7dJ1uzrfz8Mu6rgqX1CIm3HjqPWd0xaRcv1tFg"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png"><link rel="mask-icon" href="/images/favicon.png" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"aisakaaoi.github.io",root:"/",scheme:"Pisces",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="本篇学习报告来源：《Cross-subject EEG emotion recognition combined with connectivity features and meta-transfer learning》，论文发表在《Computers in Biology and Medicine》期刊上（SCI Q1，中科院二区，IF: 6.7438）。作者是来自华南理工大学电子信息工程学院"><meta property="og:type" content="article"><meta property="og:title" content="一种新的元学习算法的跨被试脑电跨情绪识别"><meta property="og:url" content="https://aisakaaoi.github.io/401da409.html"><meta property="og:site_name" content="逢坂葵的个人博客"><meta property="og:description" content="本篇学习报告来源：《Cross-subject EEG emotion recognition combined with connectivity features and meta-transfer learning》，论文发表在《Computers in Biology and Medicine》期刊上（SCI Q1，中科院二区，IF: 6.7438）。作者是来自华南理工大学电子信息工程学院"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://aisakaaoi.github.io/401da409/1.webp"><meta property="og:image" content="https://aisakaaoi.github.io/401da409/2.webp"><meta property="og:image" content="https://aisakaaoi.github.io/401da409/3.webp"><meta property="og:image" content="https://aisakaaoi.github.io/401da409/4.webp"><meta property="og:image" content="https://aisakaaoi.github.io/401da409/5.webp"><meta property="og:image" content="https://aisakaaoi.github.io/401da409/6.webp"><meta property="og:image" content="https://aisakaaoi.github.io/401da409/7.webp"><meta property="og:image" content="https://aisakaaoi.github.io/401da409/8.webp"><meta property="og:image" content="https://aisakaaoi.github.io/401da409/9.webp"><meta property="og:image" content="https://aisakaaoi.github.io/401da409/10.webp"><meta property="article:published_time" content="2023-02-26T14:02:09.000Z"><meta property="article:modified_time" content="2026-01-23T11:02:50.382Z"><meta property="article:author" content="Aisaka Aoi"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://aisakaaoi.github.io/401da409/1.webp"><link rel="canonical" href="https://aisakaaoi.github.io/401da409.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>一种新的元学习算法的跨被试脑电跨情绪识别 | 逢坂葵的个人博客</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?7308ed05421777c301eefa3754da1b42",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="逢坂葵的个人博客" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">aoi学院</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">Aisaka's Blog, School of Aoi, Aisaka University</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">20</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">1006</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div><a href="https://github.com/AisakaAoi" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://aisakaaoi.github.io/401da409.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/manatsu.jpg"><meta itemprop="name" content="Aisaka Aoi"><meta itemprop="description" content="Aisaka's Blog, School of Aoi, Aisaka University"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="逢坂葵的个人博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">一种新的元学习算法的跨被试脑电跨情绪识别</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-02-26 22:02:09" itemprop="dateCreated datePublished" datetime="2023-02-26T22:02:09+08:00">2023-02-26</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">🌙进阶学习</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%A0%94%E7%A9%B6%E5%9B%A2%E9%98%9F%EF%BC%88BCI%E5%9B%A2%E9%98%9F%EF%BC%89/" itemprop="url" rel="index"><span itemprop="name">⭐脑机接口与混合智能研究团队（BCI团队）</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%A0%94%E7%A9%B6%E5%9B%A2%E9%98%9F%EF%BC%88BCI%E5%9B%A2%E9%98%9F%EF%BC%89/%F0%9F%92%AB%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/" itemprop="url" rel="index"><span itemprop="name">💫学习报告</span></a> </span></span><span id="/401da409.html" class="post-meta-item leancloud_visitors" data-flag-title="一种新的元学习算法的跨被试脑电跨情绪识别" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/401da409.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/401da409.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>4.1k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>10 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>本篇学习报告来源：《Cross-subject EEG emotion recognition combined with connectivity features and meta-transfer learning》，论文发表在《Computers in Biology and Medicine》期刊上（SCI Q1，中科院二区，IF: 6.7438）。作者是来自华南理工大学电子信息工程学院的Jinyu Li等人。作者提出了一种结合连接特征的残差网络和新的元迁移学习（学习新的被试）的跨被试脑电情绪识别方法。</p><span id="more"></span><hr><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>因脑电信号个体差异巨大而跨被试情绪识别一直是一项巨大的挑战。激活特征已经成为脑电情绪识别的典型特征，而CNN的不同感受野可以捕获不同大脑区域的相互作用，因此连接特征可能存在很多可识别的潜在信息。传统的元学习方法是在学习一个在新的类上表现良好的模型，应用元学习方法去学习一个新的被试而不是一个新的类别是一个新的思路。</p><hr><h3 id="作者贡献-x2F-创新点"><a href="#作者贡献-x2F-创新点" class="headerlink" title="作者贡献&#x2F;创新点"></a>作者贡献&#x2F;创新点</h3><p>（1）提出了一个结合了 MSRN、MTL 和连接特征优点的模型。该模型采用MTL策略减少个体差异的影响，多尺度捕捉不同情绪状态下不同脑区之间的相互作用，对于提高泛化能力和解释情绪的生理意义具有重要意义识别模型。</p><p>（2）在 DEAP 和 SEED 数据集上进行了实验，在Valence和Arousal任务上都比传统方法获得了更高的准确性。</p><p>（3）验证了相位特征在脑电情绪识别中更有效，这指导我们后续工作探索情绪变化时不同脑区的协同作用。</p><hr><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>本文提出的是结合MSRN和MTL策略的MTL-MSRN方法。MSRN由多尺度残差块构建，以提取 EEG 信号的连接特征，利用 CNN 的不同感受野来捕获不同脑区的合作。 MTL 策略结合了元学习和迁移学习的优点，以缓解跨学科个体差异的问题。</p><h4 id="MSRN"><a href="#MSRN" class="headerlink" title="MSRN"></a>MSRN</h4><p>将连通性特征与 MSRN 相结合，提出了一个 MSRN 模型来区分情绪类别，如图 1 所示。在 MSRN 中，首先从预处理的 32 通道 EEG 信号中提取连通性特征。连通性特征的尺寸为 4×32×32。数字 4 代表四个频带（θ（4-7 Hz）、α（8-13 Hz）、β（14-30 Hz）和 γ（31- 50 Hz））用于EEG信号的分解，而32代表EEG通道数。因此，32×32 表示 EEG 通道之间的连接特征。每个值代表特定频段内两个 EEG 通道之间的连接特征。在 MSRN 模型中，第一层是具有 64 个过滤器且卷积大小为 3×3 的普通卷积层，然后是最大池化层。多尺度（MS）模块主要用于通过融合不同脑区特征来提取多尺度连接特征。设置全局平均池化层以展平特征并减少模型的工作量，然后是两个全连接的层。最后，使用 softmax 层来区分情绪类别。</p><img src="/401da409/1.webp"><div align="center">图1，MSRN的框架图。第一卷积层和maxpooling层用于下采样和去除冗余信息。MS模块主要用于多尺度连通性特征的提取。全局平均池化层被设置为平滑特征并减少模型的工作量。使用softmax层来区分情绪的类别。</div><p>如图2所示，多尺度模块主要由三个分支组成：3×3残差块、5×5残差块和7×7残差块，卷积核大小分别为3×3、5×5和 7 × 7。残差网络的框架可以通过跳跃连接的结构更好地捕获和融合脑电信号的特征。粗体“×3”表示残差块将使用不同的过滤器重复训练三次。</p><img src="/401da409/2.webp"><div align="center">图2，多尺度模块框架。该模块主要包含三个分支：3×3 Residual Block、5×5 Residual Block、7×7 Residual Block；每个残差块用不同的过滤器重复训练3次，通过融合不同的脑区特征来提取多尺度连接特征；最终输出的大小为 768。</div><p>功能连接特征反映了不同脑电通道的相关性，维度为32×32，每个节点代表不同脑电通道的活动强度。采用多尺度方法，每个分支的卷积层大小不同，意味着不同通道的连通性特征可以用不同的感受野被充分捕获，这可以充分反映不同大脑区域的相互作用。</p><hr><h4 id="MTL-strategy"><a href="#MTL-strategy" class="headerlink" title="MTL strategy"></a>MTL strategy</h4><p><strong>预热阶段：</strong>传统的元学习算法，如 MAML，总是以随机的方式初始化模型的权重，这需要大量相似的任务来表示特征。在预热阶段，使用了预训练的方法。源域中的所有训练样本都用于训练初始模型，从而能够在后续阶段快速收敛。定义一个特征提取器 Θ（MSRN 中的卷积层）和一个分类器 θ（MSRN 中的最后一个全连接层）。然后，使用等式 (1)、(2) 中的梯度下降优化特征提取器 Θ。其中LD为交叉熵损失函数，α为学习率。</p><img src="/401da409/3.webp"> <img src="/401da409/4.webp"><p>在预热阶段，通过梯度下降学习特征提取器 Θ。因此，该模型可以从源域中的所有被试学习脑电信号的共同情绪模式。通过迁移学习，模型可以学习到脑电特征的浅层语义特征，这对模型的鲁棒性有显着贡献，使模型能够在元训练阶段快速收敛。</p><p><strong>元训练阶段：</strong>提出的方法可以通过梯度下降的小步骤来优化模型的参数，从而在未知的被试中取得了良好的性能。更具体地说，优化的目标如下：</p><img src="/401da409/5.webp"><p>在元训练阶段，将从源域（涉及的被试）采样的任务分为支持集和查询集两部分，分别训练两个模块，分别命名为base-learner和meta-learner。支持集中的主题与查询集中的被试不同。训练base-learner以学习不同被试之间的共同脑电图特征。此外，在base-learner的训练过程中，特征提取器 Θ 会再次更新。meta-learner可以学习跨被试的个体脑电图特征。在meta-learner的训练过程中，特征提取器θ被冻结以确保学习到的共同脑电特征保持不变，而分类器θ可以从查询集中学习以微调个体脑电特征。</p><p>在元训练阶段使用了二次梯度更新方法。支持集首先用于完成第一次梯度更新。此后，使用查询集和从第一次梯度更新中获得的参数计算第二次梯度更新。使用 Adam 优化器，将第二次梯度更新期间计算的梯度直接应用于 MSRN 模型。使用查询集进行第二次梯度更新，以增强模型对未见主题的适应性。借助元学习，模型可以避免对某一受试者的脑电数据过度拟合，更多地了解脑电特征的通用性。</p><p><strong>元测试阶段：</strong>元测试阶段的进展与元训练阶段相似。来自目标域的数据也分为支持集和查询集，但数据未标记。元测试阶段有两个差异。在元训练阶段训练的参数[Θ*; θ*]最初用于元测试阶段，而不是以随机初始化的方式使用。其次，支持集用于更新特征提取器θ，但是由于从测试集中采样的查询集数据未标记，分类器θ没有更新。查询集由在元学习阶段微调的分类器分类。最后，评估了测试集的准确性。</p><hr><h4 id="数据集和特征提取"><a href="#数据集和特征提取" class="headerlink" title="数据集和特征提取"></a>数据集和特征提取</h4><p>使用DEAP数据集，提取4个频带θ (4–7 Hz)、α (8–13 Hz)、β (14–30 Hz) 和 γ (31–50 Hz)的三种特征：PCC、PLV和PLI。每种类型的连接特征的维度为4×32×32。数字4代表脑电信号分解中使用的四个频段，而32代表脑电通道数。使用LOSO验证策略。</p><p><strong>PCC：</strong>是一个线性相关系数，反映了不同通道脑电信号之间的线性相关性，可以描述为</p><img src="/401da409/6.webp"><p>其中 x 和 y 表示来自不同通道的两个 EEG 信号，cov(x,y) 是 x 和 y 之间的协方差，σx and σy分别表示 x 和 y 的标准差。 PCC的值位于-1和1之间，绝对值越大，线性相关性越强。</p><p><strong>PLV：</strong>通过计算相位差的平均值来描述两个EEG信号之间的相位同步，可以描述为</p><img src="/401da409/7.webp"><p>其中 N 表示 EEG 信号的采样点，并且Δ∅n表示第 n 个采样点的相位差。使用Hilbert–Huang变换来计算两个 EEG 信号之间的相位差。 PLV 的值位于 0 和 1 之间。如果两个信号完全相位同步，则 PLV 为 1。</p><p><strong>PLI：</strong>是另一种衡量两个信号之间相位同步的方法，通过计算相位差的平均值和符号函数，可以描述为</p><img src="/401da409/8.webp"><p>其中N为脑电信号的采样点数，sign(.)表示sign的函数，Δ∅n表示第 n 个采样点的相位差。</p><hr><h4 id="模型的实现细节"><a href="#模型的实现细节" class="headerlink" title="模型的实现细节"></a>模型的实现细节</h4><p>在训练阶段，选择了 Adam 优化器作为训练优化器，同时将 dropout 设置为 0.2 来解决过拟合问题。实验的批量大小设置为 64。预热阶段的 epoch 设置为 10，而元训练阶段的 epoch 设置为 50。base-learner的学习率设置为 5 × 10−3，而meta-learner的学习率在元训练和元测试阶段均设置为 5 × 10−4。学习率每 100 步衰减两次，以确保梯度下降的稳定性。使用提前停止方法来避免过度拟合。最大池化层的内核大小设置为 3 × 3，步幅设置为 2，填充设置为 1。对于 3 × Residual Block，每层的形状为 (4, 32, 32)，（64、32、32）、（64、16、16）、（128、8、8）、（256、4、4）和（256、1、1）；对于5×Residual Block，每一层的形状为(4, 32, 32)、(64, 32, 32)、(64, 15, 15)、(128, 6, 6)、(256, 2, 2)和 (256, 1, 1)。对于7×Residual Block，每一层的形状为(4, 32, 32)、(64, 32, 32)、(64, 14, 14)、(128, 6, 6)、(256, 2, 2)和(256, 1, 1)。最终连接到全连接层的输出为768。由于采用了LOSO交叉验证，每个实验的训练集包含31名受试者的数据，24800个样本，测试集包含1名受试者的数据，有 800 个样本。</p><hr><h3 id="实验与结果"><a href="#实验与结果" class="headerlink" title="实验与结果"></a>实验与结果</h3><p>提出的方法在DEAP数据集的Valence方面达到了 71.29% 的准确率，在Arousal方面达到了 71.92% 的准确率。与同行相比如下表1。</p><div align="center">表1，跨被试EEG情绪识别准确率及相关工作的标准差比较(基于DEAP数据集)。</div><img src="/401da409/9.webp"><p>在SEED数据集上，跨被试准确率87.05%，与其它方法的比较如下图3。</p><img src="/401da409/10.webp"><div align="center">图3，SEED数据集上与其它方法的准确率比较图</div><p>另外，作者还实验证明了所使用的特征中PLV的特征效果最好。</p><hr><h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote><p><a target="_blank" rel="noopener" href="https://www.scholat.com/teamwork/showPostMessage.html?id=13212">https://www.scholat.com/teamwork/showPostMessage.html?id=13212</a></p></blockquote></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-item"><a href="/4c00ad63.html" rel="prev" title="设计模式-20软工第2周安排-创建型模式-工厂模式三兄弟"><i class="fa fa-chevron-left"></i> 设计模式-20软工第2周安排-创建型模式-工厂模式三兄弟</a></div><div class="post-nav-item"><a href="/9472583e.html" rel="next" title="CSIG云上微表情-第37期-欺骗 or 伪装：谁是高端玩家？">CSIG云上微表情-第37期-欺骗 or 伪装：谁是高端玩家？ <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let t=CONFIG.comments["activeClass"];var e;(t=CONFIG.comments.storage?localStorage.getItem("comments_active")||t:t)&&(e=document.querySelector(`a[href="#comment-${t}"]`))&&e.click()}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%83%8C%E6%99%AF"><span class="nav-number">1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%9C%E8%80%85%E8%B4%A1%E7%8C%AE-x2F-%E5%88%9B%E6%96%B0%E7%82%B9"><span class="nav-number">2.</span> <span class="nav-text">作者贡献&#x2F;创新点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MSRN"><span class="nav-number">3.1.</span> <span class="nav-text">MSRN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MTL-strategy"><span class="nav-number">3.2.</span> <span class="nav-text">MTL strategy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-number">3.3.</span> <span class="nav-text">数据集和特征提取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82"><span class="nav-number">3.4.</span> <span class="nav-text">模型的实现细节</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E4%B8%8E%E7%BB%93%E6%9E%9C"><span class="nav-number">4.</span> <span class="nav-text">实验与结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E6%96%87%E9%93%BE%E6%8E%A5"><span class="nav-number">5.</span> <span class="nav-text">原文链接</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Aisaka Aoi" src="/images/manatsu.jpg"><p class="site-author-name" itemprop="name">Aisaka Aoi</p><div class="site-description" itemprop="description">逢坂葵的个人博客</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">1006</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">20</span> <span class="site-state-item-name">分类</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/AisakaAoi" title="GitHub 👨‍💻 → https:&#x2F;&#x2F;github.com&#x2F;AisakaAoi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👨‍💻</a> </span><span class="links-of-author-item"><a href="https://github.com/Aisakaorz" title="GitHub 👩‍💻 → https:&#x2F;&#x2F;github.com&#x2F;Aisakaorz" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👩‍💻</a> </span><span class="links-of-author-item"><a href="mailto:aisakaaoi@qq.com" title="E-Mail 📧 → mailto:aisakaaoi@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 📧</a> </span><span class="links-of-author-item"><a href="mailto:chenzongnan@m.scnu.edu.cn" title="E-Mail 🏫 → mailto:chenzongnan@m.scnu.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 🏫</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/91560309" title="Bilibili 📺 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;91560309" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 📺</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/198562921" title="Bilibili 🎮 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;198562921" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 🎮</a> </span><span class="links-of-author-item"><a href="https://www.youtube.com/channel/UCALvyn5Cl76GCotO9pczvjg" title="YouTube 📺 → https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCALvyn5Cl76GCotO9pczvjg" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube 📺</a></span></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2026</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Aisaka Aoi</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">3.5m</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">145:57</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll(".pdfobject-container").forEach(e=>{var t=e.dataset.target,a="#"+Object.entries({navpanes:0,toolbar:0,statusbar:0,pagemode:"thumbs",view:"FitH"}).map(([e,t])=>e+"="+encodeURIComponent(t)).join("&"),r="/lib/pdf/web/viewer.html?file="+encodeURIComponent(t)+a;NexT.utils.supportsPDFs()?e.innerHTML=`<embed class="pdfobject" src="${t+a}" type="application/pdf" style="height: ${e.dataset.height};">`:e.innerHTML=`<iframe src="${r}" style="height: ${e.dataset.height};" frameborder="0"></iframe>`})</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//unpkg.com/valine/dist/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!0,notify:!0,appId:"UqjWdRYbIUEUQRXhBUUIh1QE-gzGzoHsz",appKey:"gj89JXC485PFbpdHLKVkz6dm",placeholder:"这里可以发送评论~（上面可以输入昵称、邮箱）",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/haru02.model.json"},"display":{"position":"right","width":208,"height":520},"mobile":{"show":false},"log":false});</script></body></html>