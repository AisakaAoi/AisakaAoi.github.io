<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><meta name="baidu-site-verification" content="code-KCMz4b3cnd"><meta name="google-site-verification" content="MTp8U7dJ1uzrfz8Mu6rgqX1CIm3HjqPWd0xaRcv1tFg"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png"><link rel="mask-icon" href="/images/favicon.png" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"aisakaaoi.top",root:"/",scheme:"Pisces",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="在之前的文章中，我们介绍了三类基础知识蒸馏算法以及知识蒸馏的迁移学习应用。今天我们一起来学习如何使用 MMRazor 实现知识蒸馏。 MMRazor 是 OpenMMLab 生态的面向模型压缩的开源算法库，目前主要涵盖了知识蒸馏、剪枝、NAS 三类算法，近期会进一步支持一系列模型量化算法。  https:&#x2F;&#x2F;github.com&#x2F;open-mmlab&#x2F;mmrazor&#x2F;tree&#x2F;dev-1.x  我"><meta property="og:type" content="article"><meta property="og:title" content="深度学习-经典模型压缩方法：知识蒸馏系列（三）：使用 MMRazor 实现知识蒸馏算法"><meta property="og:url" content="https://aisakaaoi.top/c980cb7e.html"><meta property="og:site_name" content="逢坂葵的个人博客"><meta property="og:description" content="在之前的文章中，我们介绍了三类基础知识蒸馏算法以及知识蒸馏的迁移学习应用。今天我们一起来学习如何使用 MMRazor 实现知识蒸馏。 MMRazor 是 OpenMMLab 生态的面向模型压缩的开源算法库，目前主要涵盖了知识蒸馏、剪枝、NAS 三类算法，近期会进一步支持一系列模型量化算法。  https:&#x2F;&#x2F;github.com&#x2F;open-mmlab&#x2F;mmrazor&#x2F;tree&#x2F;dev-1.x  我"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://aisakaaoi.top/c980cb7e/1.webp"><meta property="og:image" content="https://aisakaaoi.top/c980cb7e/2.webp"><meta property="og:image" content="https://aisakaaoi.top/c980cb7e/3.webp"><meta property="og:image" content="https://aisakaaoi.top/c980cb7e/4.webp"><meta property="og:image" content="https://aisakaaoi.top/c980cb7e/5.webp"><meta property="article:published_time" content="2023-01-03T21:33:07.000Z"><meta property="article:modified_time" content="2024-09-04T10:06:34.944Z"><meta property="article:author" content="Aisaka Aoi"><meta property="article:tag" content="☄️蒸馏学习 Knowledge Distillation"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://aisakaaoi.top/c980cb7e/1.webp"><link rel="canonical" href="https://aisakaaoi.top/c980cb7e.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>深度学习-经典模型压缩方法：知识蒸馏系列（三）：使用 MMRazor 实现知识蒸馏算法 | 逢坂葵的个人博客</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?7308ed05421777c301eefa3754da1b42",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="逢坂葵的个人博客" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">aoi学院</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">Aisaka's Blog, School of Aoi, Aisaka University</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">50</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">9</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">840</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div><a href="https://github.com/AisakaAoi" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://aisakaaoi.top/c980cb7e.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/manatsu.jpg"><meta itemprop="name" content="Aisaka Aoi"><meta itemprop="description" content="Aisaka's Blog, School of Aoi, Aisaka University"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="逢坂葵的个人博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">深度学习-经典模型压缩方法：知识蒸馏系列（三）：使用 MMRazor 实现知识蒸馏算法</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-01-04 05:33:07" itemprop="dateCreated datePublished" datetime="2023-01-04T05:33:07+08:00">2023-01-04</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">🌙进阶学习</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">⭐人工智能 Artificial Intelligence</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-Artificial-Intelligence/%F0%9F%92%AB%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-Learning-Methodology/" itemprop="url" rel="index"><span itemprop="name">💫学习方法 Learning Methodology</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-Artificial-Intelligence/%F0%9F%92%AB%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-Learning-Methodology/%F0%9F%9B%B0%EF%B8%8F%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0-Transfer-Learning/" itemprop="url" rel="index"><span itemprop="name">🛰️迁移学习 Transfer Learning</span></a> </span></span><span id="/c980cb7e.html" class="post-meta-item leancloud_visitors" data-flag-title="深度学习-经典模型压缩方法：知识蒸馏系列（三）：使用 MMRazor 实现知识蒸馏算法" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/c980cb7e.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/c980cb7e.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>16k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>40 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>在之前的文章中，我们介绍了三类基础知识蒸馏算法以及知识蒸馏的迁移学习应用。今天我们一起来学习<strong>如何使用 MMRazor 实现知识蒸馏</strong>。</p><p>MMRazor 是 OpenMMLab 生态的面向模型压缩的开源算法库，目前主要涵盖了知识蒸馏、剪枝、NAS 三类算法，近期会进一步支持一系列模型量化算法。</p><blockquote><p><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmrazor/tree/dev-1.x">https://github.com/open-mmlab/mmrazor/tree/dev-1.x</a></p></blockquote><p>我们接下来将从 <strong>MMRazor 知识蒸馏框架介绍，基于 MMRazor 的知识蒸馏实战教程</strong>两个方面展开分享。</p><span id="more"></span><hr><h3 id="MMRazor-知识蒸馏框架介绍"><a href="#MMRazor-知识蒸馏框架介绍" class="headerlink" title="MMRazor 知识蒸馏框架介绍"></a>MMRazor 知识蒸馏框架介绍</h3><p>知识蒸馏（Knowledge Distillation，简记为 KD）是一种经典的模型压缩方法，核心思想是通过引导轻量化的学生模型“模仿”性能更好、结构更复杂的教师模型（或多模型的 ensemble），在不改变学生模型结构的情况下提高其性能。2015 年 Hinton 团队提出的基于“软标签”（<strong>response-based</strong>）的知识蒸馏技术（一般将该文算法称为<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1503.02531"><strong>vanilla-KD</strong></a>）掀起了相关研究热潮，其后基于“特征”（<strong>feature-based</strong>）和基于“关系”（<strong>relation-based</strong>）的KD算法被陆续提出。</p><p>由于知识蒸馏的过程可以理解为一个，获取学生网络和教师网络指定蒸馏位点的输出特征并计算蒸馏 loss 的过程。因此，实现一个蒸馏算法往往会有以下几点需求：</p><ol><li>获取学生网络和教师网络指定蒸馏位点的输出特征，例如某个 nn.Module，某个类方法或是某个函数的输入输出信息。在 MMRazor 中，我们通过 <strong>Recorder</strong> 组件实现。</li><li>在学生网络前向传播过程中，某一中间输出需要被教师网络对应输出覆盖。例如，在 LAD 中，学生网络训练过程中需要使用教师网络的 label assign 结果覆盖掉自身结果。在 MMRazor 中，我们通过 <strong>Deliver</strong> 组件实现。</li><li>一个蒸馏算法中可能会有多个蒸馏 loss 联合作用。而某个蒸馏 loss 需要的输入可能来自于不同 recorder，也可能来自于某一个 recorder 获取的多个数据中的若干个。因此，我们需要利用 loss_forward_mappings 数据结构从 Recorder 获取的输出特征中筛选得到蒸馏 loss 需要的部分，并利用 connectors 模块进行后处理（例如，对于 feature-base 的方法，当学生和教师网络输出特征维度不同时，往往会对学生网络对应特征进行后处理以保证蒸馏 loss 正确计算）。在 MMRazor 中，这一系列功能我们通过 <strong>ConfigurableDistiller</strong> 来统一管理。</li><li>进一步，为了解决特定问题或面向特定场景，知识蒸馏算法本身又可以细分为 data-free KD、online KD、self KD（可视为一种特殊的 online KD）和比较经典的 offline KD 等等。在 MMRazor中，我们通过设计不同的high level 的 <strong>Algorithm</strong> 组件以支持不同类型的蒸馏算法对应的 pipeline。</li></ol><p>上述 4 个组件在 MMRazor 中的位置如下图所示。接下来，我们会详细介绍各个组件的设计动机和使用方法。</p><img src="/c980cb7e/1.webp"><hr><h4 id="Recorder"><a href="#Recorder" class="headerlink" title="Recorder"></a>Recorder</h4><p>如下图所示，Recorder 是一个上下文管理器，用于在模型前项传播过程中记录各种中间结果。同时，它还可以用来获取一些特定位点的数据，用于可视化分析或其他你想要的功能。为了适应更多的需求，我们在 MMRazor 中实现了多种类型的 Recorder 来获得不同类型的中间结果，它们由 RecorderManager 统一管理。</p><img src="/c980cb7e/2.webp"><p>目前，我们支持了 7 类 Recorder，如下表所示：</p><table><thead><tr><th>Recorder 名称</th><th>描述</th></tr></thead><tbody><tr><td>ModuleOutputsRecorder &#x2F; ModuleInputsRecorder</td><td>获取某个 torch.nn.Module 的 输出 &#x2F; 输入 结果</td></tr><tr><td>FunctionOutputsRecorder &#x2F; FunctionInputsRecorder</td><td>获取模型中使用到的某个函数的 输出 &#x2F; 输入 结果</td></tr><tr><td>MethodOutputsRecorder &#x2F; MethodInputsRecorder</td><td>获取模型中某个类的某个方法的 输出 &#x2F; 输入 结果</td></tr><tr><td>ParameterRecorder</td><td>获取某个 torch.nn.Module 的模型参数</td></tr></tbody></table><p>接下来我们以 ModuleOutputsRecorder 为例，为大家介绍下 Recorder 的使用方法。</p><hr><h5 id="ModuleOutputsRecorder"><a href="#ModuleOutputsRecorder" class="headerlink" title="ModuleOutputsRecorder"></a>ModuleOutputsRecorder</h5><p>获取 nn.Module 的输入输出相对会比较容易，因为可以通过为 nn.Module 挂上 PyTorch 原生的 forward hook 来实现。由于这两种 Recorder 的使用方法非常类似，我们以 ModuleOutputsRecorder 为例来介绍它们是如何工作的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> mmrazor.core <span class="keyword">import</span> ModuleOutputsRecorder</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ToyModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x1 = self.conv1(x)</span><br><span class="line">        x2 = self.conv1(x + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.conv2(x1 + x2)</span><br><span class="line"></span><br><span class="line">model = ToyModel()</span><br><span class="line"><span class="comment"># instantiate with specified module name.</span></span><br><span class="line">r1 = ModuleOutputsRecorder(<span class="string">&#x27;conv1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize is to make specified module can be recorded by </span></span><br><span class="line"><span class="comment"># registering customized forward hook.</span></span><br><span class="line">r1.initialize(model)</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">with</span> r1:</span><br><span class="line">    out = model(x)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(r1.data_buffer)</span><br><span class="line"><span class="comment"># [tensor([[[[0.0820]]]], grad_fn=&lt;ThnnConv2DBackward0&gt;), tensor([[[[-0.0894]]]], grad_fn=&lt;ThnnConv2DBackward0&gt;)]</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(torch.equal(r1.data_buffer[<span class="number">0</span>], model.conv1(x)))</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line"><span class="built_in">print</span>(torch.equal(r1.data_buffer[<span class="number">1</span>], model.conv1(x + <span class="number">1</span>)))</span><br><span class="line"><span class="comment"># True</span></span><br></pre></td></tr></table></figure><p><strong>注意，所有的 Recorder 在使用前都需要执行 initialize 方法</strong></p><hr><h5 id="RecorderManager"><a href="#RecorderManager" class="headerlink" title="RecorderManager"></a>RecorderManager</h5><p>RecorderManager 同样是上下文管理器，可用于管理各种类型的 Recorder。</p><p>在 RecorderManager 的帮助下，我们可以用尽可能少的代码管理几个不同的记录器，这减少了出错的可能性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> mmrazor.core <span class="keyword">import</span> RecorderManager</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Toy</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">toy_func</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> random.randint(<span class="number">0</span>, <span class="number">1000000</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ToyModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.toy = Toy()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.conv2(self.conv1(x)) + self.toy.toy_func()</span><br><span class="line"></span><br><span class="line"><span class="comment"># configure multi-recorders</span></span><br><span class="line">conv1_rec = ConfigDict(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;conv1&#x27;</span>)</span><br><span class="line">conv2_rec = ConfigDict(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;conv2&#x27;</span>)</span><br><span class="line">func_rec = ConfigDict(<span class="built_in">type</span>=<span class="string">&#x27;MethodOutputs&#x27;</span>, source=<span class="string">&#x27;toy_module.Toy.toy_func&#x27;</span>)</span><br><span class="line"><span class="comment"># instantiate RecorderManager with a dict that contains recorders&#x27; configs,</span></span><br><span class="line"><span class="comment"># you can customize their keys.</span></span><br><span class="line">manager = RecorderManager(</span><br><span class="line">    &#123;<span class="string">&#x27;conv1_rec&#x27;</span>: conv1_rec,</span><br><span class="line">     <span class="string">&#x27;conv2_rec&#x27;</span>: conv2_rec,</span><br><span class="line">     <span class="string">&#x27;func_rec&#x27;</span>: func_rec&#125;)</span><br><span class="line"></span><br><span class="line">model = ToyModel()</span><br><span class="line"><span class="comment"># initialize is to make specified module can be recorded by </span></span><br><span class="line"><span class="comment"># registering customized forward hook.</span></span><br><span class="line">manager.initialize(model)</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">with</span> manager:</span><br><span class="line">    out = model(x)</span><br><span class="line">    </span><br><span class="line">conv2_out = manager.get_recorder(<span class="string">&#x27;conv2_rec&#x27;</span>).get_record_data()</span><br><span class="line"><span class="built_in">print</span>(conv2_out)</span><br><span class="line"><span class="comment"># tensor([[[[0.5543]]]], grad_fn=&lt;ThnnConv2DBackward0&gt;)</span></span><br><span class="line">func_out = manager.get_recorder(<span class="string">&#x27;func_rec&#x27;</span>).get_record_data()</span><br><span class="line"><span class="built_in">print</span>(func_out)</span><br><span class="line"><span class="comment"># 313167</span></span><br></pre></td></tr></table></figure><hr><h4 id="Deliver"><a href="#Deliver" class="headerlink" title="Deliver"></a>Deliver</h4><p>Deliver 工具是 MMRazor 专门为处理蒸馏算法中涉及的一些特殊情况而设计的，它在教师模型和学生模型之间转移并覆盖掉一些中间结果，如下图所示：</p><img src="/c980cb7e/3.webp"><p>Deliver 并不像 Recorder 那样，基本在每个蒸馏算法中都会使用，但对于一些算法，它是必不可少的。例如，在 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2108.10520">LAD</a> 中，学生网络需要直接获取教师网络的 label assignment 信息，我们可以如下配置 Deliver：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">distill_deliveries = ConfigDict(</span><br><span class="line">    delivery1=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;MethodOutputs&#x27;</span>,</span><br><span class="line">        max_keep_data=<span class="number">100</span>,</span><br><span class="line">        method_path=<span class="string">&#x27;mmdet.models.dense_heads.paa_head.PAAHead.paa_reassign&#x27;</span>),</span><br><span class="line">    delivery2=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;MethodOutputs&#x27;</span>,</span><br><span class="line">        max_keep_data=<span class="number">100</span>,</span><br><span class="line">        method_path=<span class="string">&#x27;mmdet.models.dense_heads.paa_head.PAAHead.get_targets&#x27;</span>))</span><br></pre></td></tr></table></figure><p>Deliver 的可配置性，让我们可以不需要对源代码进行 hardcode 修改。</p><hr><h4 id="ConfigurableDistiller"><a href="#ConfigurableDistiller" class="headerlink" title="ConfigurableDistiller"></a>ConfigurableDistiller</h4><p>ConfigurableDistiller 是一个功能强大的工具，可以在不修改教师或学生模型代码的情况下实现大多数蒸馏算法。它可以通过 Recorder 以一种 hack 的方式获得模型的各种中间结果。同样，它可以使用 Delivery 以 hack 的方式使用老师的中间结果来覆盖学生的中间结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConfigurableDistiller</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">             student_recorders: <span class="type">Optional</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Dict</span>]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             teacher_recorders: <span class="type">Optional</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Dict</span>]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             distill_deliveries: <span class="type">Optional</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Dict</span>]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             connectors: <span class="type">Optional</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Dict</span>]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             distill_losses: <span class="type">Optional</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Dict</span>]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             loss_forward_mappings: <span class="type">Optional</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Dict</span>]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             **kwargs</span>):</span><br></pre></td></tr></table></figure><p>这里的 student_recorders、teacher_recordersdistill_deliveries 上文刚刚介绍。distill_losses 是蒸馏时用到的蒸馏损失函数，可以是一个或多个。</p><p>这里引入了两个新概念：connectors 和 loss_forward_mappings</p><hr><h5 id="Connectors"><a href="#Connectors" class="headerlink" title="Connectors"></a>Connectors</h5><p>知识蒸馏算法往往分为 reponse-based、feature-based 和 relation-based 三类。其中，feature-based 方法以教师模型特征提取器产生的中间层特征为学习对象，最简单的 L2 损失如下所示：</p><img src="/c980cb7e/4.webp"><p>实现特征对齐功能的模块（上面提到的 phi_t 和 phi_s ）是 feature-based KD 算法的核心模块（MMRazor 中称之为 connector），也是很多算法的重点研究对象。如针对教师 connector 进行预训练的 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.04977">Factor Transfer</a> 算法；以二值化形式筛选教师和学生原始特征的 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1811.03233">AB</a> 算法；将特征值转换为注意力值的 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1612.03928.pdf">AT</a> 算法等。<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.01866.pdf">OFD</a> 对各相关算法进行总结，研究了特征位置、connector 的构成、损失函数等因素对蒸馏性能、信息损失的影响，汇总表如下所示：</p><img src="/c980cb7e/5.webp"><p>上面提到的 FitNets、Factor Transfer、AB、AT Loss（AT 算法与蒸馏最相关的损失计算部分）、OFD 等算法均被集成到了 <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmrazor">MMRazor</a> 算法库中，且核心模块 connector 被单独抽象出来作为可配置组件，非常便于大家进行“算法魔改”（如为 FitNets 算法配置上 Factor Transfer 的 connector 并计算 AT Loss）。</p><hr><h5 id="loss-forward-mappings"><a href="#loss-forward-mappings" class="headerlink" title="loss_forward_mappings"></a>loss_forward_mappings</h5><p>通过 Recorder 组件获得模型中间结果后，可以通过配置 loss_forward_mappings 来进一步指定不同的蒸馏 loss 的输入参数是什么。</p><p>下面代码表示我们只使用一个蒸馏 loss，我们把它称为 loss_neck，它实际上是一个 L2Loss，loss weight&#x3D;5。我们分别设置 student_recorders 和 teacher_recorder 希望获取学生和教师网络的 ‘neck.gap’ 这一 module 的输出，输出特征命名为 feat。那么在配置 loss_forward_mappings 时可以看到 L2Loss 的 forward 方法有两个输入参数，分别为 s_feature 和 t_feature。而 s_feature 和 t_feature 又分别来自于名字为 feat 的学生和教师网络中间特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>distill_losses = <span class="built_in">dict</span>(</span><br><span class="line"><span class="meta">... </span>    loss_neck=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;L2Loss&#x27;</span>, loss_weight=<span class="number">5</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>student_recorders = <span class="built_in">dict</span>(</span><br><span class="line"><span class="meta">... </span>    feat = <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;neck.gap&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>teacher_recorders = <span class="built_in">dict</span>(</span><br><span class="line"><span class="meta">... </span>    feat = <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;neck.gap&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>loss_forward_mappings = <span class="built_in">dict</span>(</span><br><span class="line"><span class="meta">... </span>    loss_neck=<span class="built_in">dict</span>(</span><br><span class="line"><span class="meta">... </span>        s_feature=<span class="built_in">dict</span>(from_recorder=<span class="string">&#x27;feat&#x27;</span>, from_student=<span class="literal">True</span>,</span><br><span class="line"><span class="meta">... </span>                       connector=<span class="string">&#x27;loss_neck_sfeat&#x27;</span>),</span><br><span class="line"><span class="meta">... </span>        t_feature=<span class="built_in">dict</span>(from_recorder=<span class="string">&#x27;feat&#x27;</span>, from_student=<span class="literal">False</span>,</span><br><span class="line"><span class="meta">... </span>                       connector=<span class="string">&#x27;loss_neck_tfeat&#x27;</span>)))</span><br></pre></td></tr></table></figure><hr><h4 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h4><p>最后，Distill Algorithm 负责控制蒸馏的一整个 pipeline。MMRazor 实现了多类知识蒸馏算法，我们以最经典的，使用单个教师网络蒸馏单个学生网络的 SingleTeacherDistill 算法为例。下面代码展示了其在初始化时需要传入的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SingleTeacherDistill</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">        architecture,  <span class="comment"># 学生网络对应配置</span></span></span><br><span class="line"><span class="params">        distiller: <span class="built_in">dict</span>,  <span class="comment"># 蒸馏相关tools的配置文件</span></span></span><br><span class="line"><span class="params">        teacher: <span class="type">Union</span>[BaseModel, <span class="type">Dict</span>],  <span class="comment"># 教师网络对应配置文件</span></span></span><br><span class="line"><span class="params">        teacher_ckpt: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span>,  <span class="comment"># 教师网络的预训练权重路径</span></span></span><br><span class="line"><span class="params">        teacher_trainable: <span class="built_in">bool</span> = <span class="literal">False</span>,  <span class="comment"># 教师网络是否可以训练</span></span></span><br><span class="line"><span class="params">        teacher_norm_eval: <span class="built_in">bool</span> = <span class="literal">True</span>,  <span class="comment"># 教师网络的normalization 模块是否需要调成eval mode，若为eval mode，在学生网络训练过程中，教师网络的norm module的统计信息不会随着改变</span></span></span><br><span class="line"><span class="params">        student_trainable: <span class="built_in">bool</span> = <span class="literal">True</span>,  <span class="comment"># 学生网络是否可训练</span></span></span><br><span class="line"><span class="params">        calculate_student_loss: <span class="built_in">bool</span> = <span class="literal">True</span>,  <span class="comment"># 学生网络是否受ground truth标签监督</span></span></span><br></pre></td></tr></table></figure><hr><h3 id="基于-MMRazor-的知识蒸馏实战教程"><a href="#基于-MMRazor-的知识蒸馏实战教程" class="headerlink" title="基于 MMRazor 的知识蒸馏实战教程"></a>基于 MMRazor 的知识蒸馏实战教程</h3><p>我们首先以 KD 算法使用 ResNet34 蒸馏 ResNet18 为例，介绍如何使用 MMRazor 实现基础蒸馏算法。</p><h4 id="KD"><a href="#KD" class="headerlink" title="KD"></a>KD</h4><h5 id="步骤一：设计-Distiller-相关配置文件"><a href="#步骤一：设计-Distiller-相关配置文件" class="headerlink" title="步骤一：设计 Distiller 相关配置文件"></a>步骤一：设计 Distiller 相关配置文件</h5><p>传统 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1503.02531">KD</a> 算法的知识提取和 loss 计算过程非常简洁，只需获取学生网络和教师网络的输出 logits 并计算 KL 散度即可。Distiller 组件的配置文件主要分为四个部分，如下方代码所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">distiller=<span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">&#x27;ConfigurableDistiller&#x27;</span>,</span><br><span class="line">    student_recorders=<span class="built_in">dict</span>(</span><br><span class="line">        fc=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;head.fc&#x27;</span>)),</span><br><span class="line">    teacher_recorders=<span class="built_in">dict</span>(</span><br><span class="line">        fc=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;head.fc&#x27;</span>)),</span><br><span class="line">    distill_losses=<span class="built_in">dict</span>(</span><br><span class="line">        loss_kl=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;KLDivergence&#x27;</span>, tau=<span class="number">1</span>, loss_weight=<span class="number">3</span>)),</span><br><span class="line">    loss_forward_mappings=<span class="built_in">dict</span>(</span><br><span class="line">        loss_kl=<span class="built_in">dict</span>(</span><br><span class="line">            preds_S=<span class="built_in">dict</span>(from_student=<span class="literal">True</span>, recorder=<span class="string">&#x27;fc&#x27;</span>),</span><br><span class="line">            preds_T=<span class="built_in">dict</span>(from_student=<span class="literal">False</span>, recorder=<span class="string">&#x27;fc&#x27;</span>))))</span><br></pre></td></tr></table></figure><ol><li>student_recorders 和 teacher_recorders 表示我们需要分别记录学生和教师网络中某一个 nn.Module 的输出，这个 nn.Module 的 module name 是 head.fc，记录的数据我们将其命名为 fc。</li><li>在整个蒸馏过程中，我们只使用了一种损失函数，因此 distill_losses 中只包含一组 key 和 value。key 是 loss_kl ，表示将这个蒸馏 loss 命名为 loss_kl，value 则是蒸馏 loss 对应的配置文件，表示我们用的蒸馏 loss 是 KLDivergence，超参数 temperature 温度为 1，loss weigh 为 5。</li><li>loss_forward_mappings 指定每个 loss module 的输入数据是什么。在本示例中，loss module 有两个输入：preds_S 和 preds_T，分别表示学生和教师网络输出 logits，它们需要跟 KLDivergence loss module 中 forward 方法传入参数保持一致。另外，我们通过 from_student 和 recorder 两个字段判断从student_recorders 还是 teacher_recorders 中读取哪个值。dict(from_student&#x3D;True, recorder&#x3D;’fc’) 表示读取 student_recorders 中名字为 fc 的数据。</li></ol><h5 id="步骤二：设计-Algorithm-相关配置文件"><a href="#步骤二：设计-Algorithm-相关配置文件" class="headerlink" title="步骤二：设计 Algorithm 相关配置文件"></a>步骤二：设计 Algorithm 相关配置文件</h5><p>算法层面需要进行以下配置。architecture 和 teacher 指定了学生&#x2F;教师网络的网络配置，teacher_ckpt 指定教师网络的预训练权重的路径，如果使用 MMClassification 提供的预训练参数，也可直接在 teacher 对应的字典中的 pretrained 的值设为 True。其余配置只需按照默认设置，即：teacher_trainable&#x3D;False 表示蒸馏过程中教师网络是不可学习的；teacher_norm_eval&#x3D;True 表示蒸馏过程中教师网络的 norm module 全程都处在 eval 模式下；calculate_student_loss&#x3D;True 表示学生网络除了受教师网络监督外，还受到 ground truth 的监督。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model = <span class="built_in">dict</span>(</span><br><span class="line">    ...,</span><br><span class="line">    architecture=<span class="built_in">dict</span>(</span><br><span class="line">        cfg_path=<span class="string">&#x27;mmcls::resnet/resnet18_8xb32_in1k.py&#x27;</span>, pretrained=<span class="literal">False</span>),</span><br><span class="line">    teacher=<span class="built_in">dict</span>(</span><br><span class="line">        cfg_path=<span class="string">&#x27;mmcls::resnet/resnet34_8xb32_in1k.py&#x27;</span>, pretrained=<span class="literal">False</span>),</span><br><span class="line">    teacher_ckpt=teacher_ckpt,</span><br><span class="line">    teacher_trainable=<span class="literal">False</span>,</span><br><span class="line">    teacher_norm_eval=<span class="literal">True</span>,</span><br><span class="line">    student_trainable=<span class="literal">True</span>,</span><br><span class="line">    calculate_student_loss=<span class="literal">True</span>,</span><br><span class="line">    distiller=...</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h5 id="步骤三：设计其他配置文件"><a href="#步骤三：设计其他配置文件" class="headerlink" title="步骤三：设计其他配置文件"></a>步骤三：设计其他配置文件</h5><p>最后，我们还需要定义数据集、优化器等其他配置文件，这部分直接引入 MMClassification 定义好的配置文件即可，代码如下，其中 val_cfg 定义了蒸馏过程中 evaluation 的 pipeline：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">_base_ = [</span><br><span class="line">    <span class="string">&#x27;mmcls::_base_/datasets/imagenet_bs32.py&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;mmcls::_base_/schedules/imagenet_bs256.py&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;mmcls::_base_/default_runtime.py&#x27;</span></span><br><span class="line">]</span><br><span class="line">find_unused_parameters = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">val_cfg = <span class="built_in">dict</span>(_delete_=<span class="literal">True</span>, <span class="built_in">type</span>=<span class="string">&#x27;mmrazor.SingleTeacherDistillValLoop&#x27;</span>)</span><br></pre></td></tr></table></figure><hr><h4 id="OFD"><a href="#OFD" class="headerlink" title="OFD"></a>OFD</h4><p>接下来我们以 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.01866">OFD</a> 算法为例，介绍如何使用 MMRazor 实现稍微复杂一些的算法。</p><h5 id="步骤一：设计-Distiller-相关配置文件-1"><a href="#步骤一：设计-Distiller-相关配置文件-1" class="headerlink" title="步骤一：设计 Distiller 相关配置文件"></a>步骤一：设计 Distiller 相关配置文件</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">distiller=<span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">&#x27;OFDDistiller&#x27;</span>,</span><br><span class="line">    student_recorders=<span class="built_in">dict</span>(</span><br><span class="line">        bb_1=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;backbone.layer2.0.bn1&#x27;</span>),</span><br><span class="line">        bb_2=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;backbone.layer3.0.bn1&#x27;</span>),</span><br><span class="line">        bb_3=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;backbone.bn1&#x27;</span>)),</span><br><span class="line">    teacher_recorders=<span class="built_in">dict</span>(</span><br><span class="line">        bb_1=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;backbone.layer2.0.bn1&#x27;</span>),</span><br><span class="line">        bb_2=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;backbone.layer3.0.bn1&#x27;</span>),</span><br><span class="line">        bb_3=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;backbone.bn1&#x27;</span>)),</span><br><span class="line">    distill_losses=<span class="built_in">dict</span>(</span><br><span class="line">        loss_1=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;OFDLoss&#x27;</span>, loss_weight=<span class="number">0.25</span>),</span><br><span class="line">        loss_2=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;OFDLoss&#x27;</span>, loss_weight=<span class="number">0.5</span>),</span><br><span class="line">        loss_3=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;OFDLoss&#x27;</span>, loss_weight=<span class="number">1.0</span>)),</span><br><span class="line">    connectors=<span class="built_in">dict</span>(</span><br><span class="line">        loss_1_sfeat=<span class="built_in">dict</span>(</span><br><span class="line">            <span class="built_in">type</span>=<span class="string">&#x27;ConvModuleConncetor&#x27;</span>,</span><br><span class="line">            in_channel=<span class="number">32</span>,</span><br><span class="line">            out_channel=<span class="number">64</span>,</span><br><span class="line">            norm_cfg=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;BN&#x27;</span>),</span><br><span class="line">            act_cfg=<span class="literal">None</span>),</span><br><span class="line">        loss_1_tfeat=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;OFDTeacherConnector&#x27;</span>),</span><br><span class="line">        loss_2_sfeat=<span class="built_in">dict</span>(</span><br><span class="line">            <span class="built_in">type</span>=<span class="string">&#x27;ConvModuleConncetor&#x27;</span>,</span><br><span class="line">            in_channel=<span class="number">64</span>,</span><br><span class="line">            out_channel=<span class="number">128</span>,</span><br><span class="line">            norm_cfg=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;BN&#x27;</span>),</span><br><span class="line">            act_cfg=<span class="literal">None</span>),</span><br><span class="line">        loss_2_tfeat=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;OFDTeacherConnector&#x27;</span>),</span><br><span class="line">        loss_3_sfeat=<span class="built_in">dict</span>(</span><br><span class="line">            <span class="built_in">type</span>=<span class="string">&#x27;ConvModuleConncetor&#x27;</span>,</span><br><span class="line">            in_channel=<span class="number">128</span>,</span><br><span class="line">            out_channel=<span class="number">256</span>,</span><br><span class="line">            norm_cfg=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;BN&#x27;</span>),</span><br><span class="line">            act_cfg=<span class="literal">None</span>),</span><br><span class="line">        loss_3_tfeat=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;OFDTeacherConnector&#x27;</span>)),</span><br><span class="line">    loss_forward_mappings=<span class="built_in">dict</span>(</span><br><span class="line">        loss_1=<span class="built_in">dict</span>(</span><br><span class="line">            s_feature=<span class="built_in">dict</span>(</span><br><span class="line">                from_student=<span class="literal">True</span>,</span><br><span class="line">                recorder=<span class="string">&#x27;bb_1&#x27;</span>,</span><br><span class="line">                connector=<span class="string">&#x27;loss_1_sfeat&#x27;</span>),</span><br><span class="line">            t_feature=<span class="built_in">dict</span>(</span><br><span class="line">                from_student=<span class="literal">False</span>,</span><br><span class="line">                recorder=<span class="string">&#x27;bb_1&#x27;</span>,</span><br><span class="line">                connector=<span class="string">&#x27;loss_1_tfeat&#x27;</span>),</span><br><span class="line">        ),</span><br><span class="line">        loss_2=<span class="built_in">dict</span>(</span><br><span class="line">            s_feature=<span class="built_in">dict</span>(</span><br><span class="line">                from_student=<span class="literal">True</span>,</span><br><span class="line">                recorder=<span class="string">&#x27;bb_2&#x27;</span>,</span><br><span class="line">                connector=<span class="string">&#x27;loss_2_sfeat&#x27;</span>),</span><br><span class="line">            t_feature=<span class="built_in">dict</span>(</span><br><span class="line">                from_student=<span class="literal">False</span>,</span><br><span class="line">                recorder=<span class="string">&#x27;bb_2&#x27;</span>,</span><br><span class="line">                connector=<span class="string">&#x27;loss_2_tfeat&#x27;</span>),</span><br><span class="line">        ),</span><br><span class="line">        loss_3=<span class="built_in">dict</span>(</span><br><span class="line">            s_feature=<span class="built_in">dict</span>(</span><br><span class="line">                from_student=<span class="literal">True</span>,</span><br><span class="line">                recorder=<span class="string">&#x27;bb_3&#x27;</span>,</span><br><span class="line">                connector=<span class="string">&#x27;loss_3_sfeat&#x27;</span>),</span><br><span class="line">            t_feature=<span class="built_in">dict</span>(</span><br><span class="line">                from_student=<span class="literal">False</span>,</span><br><span class="line">                recorder=<span class="string">&#x27;bb_3&#x27;</span>,</span><br><span class="line">                connector=<span class="string">&#x27;loss_3_tfeat&#x27;</span>),</span><br><span class="line">        )))</span><br></pre></td></tr></table></figure><p>上方代码是 OFD 算法 distiller 部分对应的配置文件。student_recorders 和 teacher_recorders 与上述 KD 算法类似，分别获取学生和教师网络三个 nn.module 的输出并命名为 bb_1，bb_2，bb_3</p><p>distill_losses定义了三个蒸馏 loss，loss weight 分别为 0.25，0.5 和 1.0。与传统 KD 算法不同，connectors定义了 OFD 中用到的 connector 结构 —— convbn layer。前文介绍过，MMRazor 使用 connectors 模块实现特征对齐功能，即：在获取 loss module 所需输入数据后，输入 loss module 前，数据需要经过 connector 处理。</p><p>最后 loss_forward_mappings 也会比 KD 中复杂些，我们以下方代码为例。代码中 distill_losses定义了 名为 loss_1 的蒸馏损失函数对应的是 loss_weight&#x3D;0.25 的 OFDLoss。其中 OFDLoss loss module 的输入参数有两个，分别是 s_feature 和 t_feature。s_feature 来自名为 bb_1 的 student_recorders ，需要经过名为 loss_1_sfeat 的 connector 进行特征后处理。从下方 connectors 部分的定义可知，名为loss_1_sfeat 的 connector 是一个 ConvModule，输入输出通道数分别为 32 和 64。同理可得 t_feature。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">student_recorders=<span class="built_in">dict</span>(bb_1=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;backbone.layer2.0.bn1&#x27;</span>))</span><br><span class="line">teacher_recorders=<span class="built_in">dict</span>(bb_1=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ModuleOutputs&#x27;</span>, source=<span class="string">&#x27;backbone.layer2.0.bn1&#x27;</span>))</span><br><span class="line">distill_losses=<span class="built_in">dict</span>(loss_1=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;OFDLoss&#x27;</span>, loss_weight=<span class="number">0.25</span>))</span><br><span class="line">connectors=<span class="built_in">dict</span>(</span><br><span class="line">    loss_1_sfeat=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;ConvModuleConncetor&#x27;</span>,</span><br><span class="line">        in_channel=<span class="number">32</span>,</span><br><span class="line">        out_channel=<span class="number">64</span>,</span><br><span class="line">        norm_cfg=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;BN&#x27;</span>),</span><br><span class="line">        act_cfg=<span class="literal">None</span>),</span><br><span class="line">    loss_1_tfeat=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;OFDTeacherConnector&#x27;</span>))</span><br><span class="line">loss_forward_mappings=<span class="built_in">dict</span>(</span><br><span class="line">    loss_1=<span class="built_in">dict</span>(</span><br><span class="line">        s_feature=<span class="built_in">dict</span>(</span><br><span class="line">            from_student=<span class="literal">True</span>,</span><br><span class="line">            recorder=<span class="string">&#x27;bb_1&#x27;</span>,</span><br><span class="line">            connector=<span class="string">&#x27;loss_1_sfeat&#x27;</span>),</span><br><span class="line">        t_feature=<span class="built_in">dict</span>(</span><br><span class="line">            from_student=<span class="literal">False</span>,</span><br><span class="line">            recorder=<span class="string">&#x27;bb_1&#x27;</span>,</span><br><span class="line">            connector=<span class="string">&#x27;loss_1_tfeat&#x27;</span>),</span><br><span class="line">    ))</span><br></pre></td></tr></table></figure><h5 id="步骤二-x2F-三：设计-Algorithm-相关配置文件-x2F-设计其他配置文件"><a href="#步骤二-x2F-三：设计-Algorithm-相关配置文件-x2F-设计其他配置文件" class="headerlink" title="步骤二 &#x2F; 三：设计 Algorithm 相关配置文件 &#x2F; 设计其他配置文件"></a>步骤二 &#x2F; 三：设计 Algorithm 相关配置文件 &#x2F; 设计其他配置文件</h5><p>步骤二、三与传统 KD 算法类似。至此，我们通过修改配置文件实现了 OFD 算法。</p><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文介绍了 MMRazor 对知识蒸馏算法的设计框架，并列举了两个简单例子来介绍如何使用 MMRazor 开发知识蒸馏算法。</p><blockquote><p><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmrazor/tree/main">https://github.com/open-mmlab/mmrazor/tree/main</a></p></blockquote><hr><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/596582609">https://zhuanlan.zhihu.com/p/596582609</a></p></blockquote></div><div class="popular-posts-header">相关文章</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="\6e7b097f.html" rel="bookmark">深度学习-经典模型压缩方法：知识蒸馏系列（一）：三类基础蒸馏算法</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\b3cc94a2.html" rel="bookmark">深度学习-经典模型压缩方法：知识蒸馏系列（二）：知识蒸馏的迁移学习应用</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\c6bf908a.html" rel="bookmark">论文阅读-可解释性：通过量化知识来解释知识蒸馏-《Explaining Knowledge Distillation by Quantifying the Knowledge》in CVPR2020</a></div></li></ul><footer class="post-footer"><div class="post-tags"><a href="/tags/%E2%98%84%EF%B8%8F%E8%92%B8%E9%A6%8F%E5%AD%A6%E4%B9%A0-Knowledge-Distillation/" rel="tag"># ☄️蒸馏学习 Knowledge Distillation</a></div><div class="post-nav"><div class="post-nav-item"><a href="/6c9167ec.html" rel="prev" title="最优化方法-3.无约束优化方法【复习笔记】"><i class="fa fa-chevron-left"></i> 最优化方法-3.无约束优化方法【复习笔记】</a></div><div class="post-nav-item"><a href="/9dca7274.html" rel="next" title="数学基础-KKT条件，原来如此简单 | 理论+算例实践">数学基础-KKT条件，原来如此简单 | 理论+算例实践 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let t=CONFIG.comments["activeClass"];var e;(t=CONFIG.comments.storage?localStorage.getItem("comments_active")||t:t)&&(e=document.querySelector(`a[href="#comment-${t}"]`))&&e.click()}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#MMRazor-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">MMRazor 知识蒸馏框架介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Recorder"><span class="nav-number">1.1.</span> <span class="nav-text">Recorder</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#ModuleOutputsRecorder"><span class="nav-number">1.1.1.</span> <span class="nav-text">ModuleOutputsRecorder</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#RecorderManager"><span class="nav-number">1.1.2.</span> <span class="nav-text">RecorderManager</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Deliver"><span class="nav-number">1.2.</span> <span class="nav-text">Deliver</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ConfigurableDistiller"><span class="nav-number">1.3.</span> <span class="nav-text">ConfigurableDistiller</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Connectors"><span class="nav-number">1.3.1.</span> <span class="nav-text">Connectors</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#loss-forward-mappings"><span class="nav-number">1.3.2.</span> <span class="nav-text">loss_forward_mappings</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Algorithm"><span class="nav-number">1.4.</span> <span class="nav-text">Algorithm</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E-MMRazor-%E7%9A%84%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E5%AE%9E%E6%88%98%E6%95%99%E7%A8%8B"><span class="nav-number">2.</span> <span class="nav-text">基于 MMRazor 的知识蒸馏实战教程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#KD"><span class="nav-number">2.1.</span> <span class="nav-text">KD</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E8%AE%BE%E8%AE%A1-Distiller-%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">2.1.1.</span> <span class="nav-text">步骤一：设计 Distiller 相关配置文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E8%AE%BE%E8%AE%A1-Algorithm-%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">2.1.2.</span> <span class="nav-text">步骤二：设计 Algorithm 相关配置文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E8%AE%BE%E8%AE%A1%E5%85%B6%E4%BB%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">2.1.3.</span> <span class="nav-text">步骤三：设计其他配置文件</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#OFD"><span class="nav-number">2.2.</span> <span class="nav-text">OFD</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E8%AE%BE%E8%AE%A1-Distiller-%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-1"><span class="nav-number">2.2.1.</span> <span class="nav-text">步骤一：设计 Distiller 相关配置文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C-x2F-%E4%B8%89%EF%BC%9A%E8%AE%BE%E8%AE%A1-Algorithm-%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-x2F-%E8%AE%BE%E8%AE%A1%E5%85%B6%E4%BB%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">2.2.2.</span> <span class="nav-text">步骤二 &#x2F; 三：设计 Algorithm 相关配置文件 &#x2F; 设计其他配置文件</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">3.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">4.</span> <span class="nav-text">参考资料</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Aisaka Aoi" src="/images/manatsu.jpg"><p class="site-author-name" itemprop="name">Aisaka Aoi</p><div class="site-description" itemprop="description">逢坂葵的个人博客</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">840</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">50</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">9</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/AisakaAoi" title="GitHub 👨‍💻 → https:&#x2F;&#x2F;github.com&#x2F;AisakaAoi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👨‍💻</a> </span><span class="links-of-author-item"><a href="https://github.com/AisakaManatsu" title="GitHub 👩‍💻 → https:&#x2F;&#x2F;github.com&#x2F;AisakaManatsu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👩‍💻</a> </span><span class="links-of-author-item"><a href="mailto:chenzongnan@m.scnu.edu.cn" title="E-Mail 🏫 → mailto:chenzongnan@m.scnu.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 🏫</a> </span><span class="links-of-author-item"><a href="mailto:aisakaaoi@qq.com" title="E-Mail 📧 → mailto:aisakaaoi@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 📧</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/91560309" title="Bilibili 📺 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;91560309" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 📺</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/198562921" title="Bilibili 🎮 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;198562921" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 🎮</a> </span><span class="links-of-author-item"><a href="https://www.youtube.com/channel/UCALvyn5Cl76GCotO9pczvjg" title="YouTube 📺 → https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCALvyn5Cl76GCotO9pczvjg" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube 📺</a></span></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Aisaka Aoi</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">2.6m</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">109:26</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll(".pdfobject-container").forEach(e=>{var t=e.dataset.target,a="#"+Object.entries({navpanes:0,toolbar:0,statusbar:0,pagemode:"thumbs",view:"FitH"}).map(([e,t])=>e+"="+encodeURIComponent(t)).join("&"),r="/lib/pdf/web/viewer.html?file="+encodeURIComponent(t)+a;NexT.utils.supportsPDFs()?e.innerHTML=`<embed class="pdfobject" src="${t+a}" type="application/pdf" style="height: ${e.dataset.height};">`:e.innerHTML=`<iframe src="${r}" style="height: ${e.dataset.height};" frameborder="0"></iframe>`})</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//unpkg.com/valine/dist/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!0,notify:!0,appId:"UqjWdRYbIUEUQRXhBUUIh1QE-gzGzoHsz",appKey:"gj89JXC485PFbpdHLKVkz6dm",placeholder:"这里可以发送评论~（上面可以输入昵称、邮箱）",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{jsonPath:"/live2dw/assets/assets/haru02.model.json"},display:{position:"right",width:208,height:520},mobile:{show:!1},log:!1})</script></body></html>