<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><meta name="baidu-site-verification" content="code-KCMz4b3cnd"><meta name="google-site-verification" content="MTp8U7dJ1uzrfz8Mu6rgqX1CIm3HjqPWd0xaRcv1tFg"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png"><link rel="mask-icon" href="/images/favicon.png" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"aisakaaoi.github.io",root:"/",scheme:"Pisces",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="本文约6000字，建议阅读10分钟本篇文章将从一个更直观的角度对当前经典流行的GNN网络，包括GCN、GraphSAGE、GAT、GAE以及graph pooling策略DiffPool等等做一个简单的小结。  “近年来，深度学习领域关于图神经网络（Graph Neural Networks，GNN）的研究热情日益高涨，图神经网络已经成为各大深度学习顶会的研究热点。GNN处理非结构化数据时的出色"><meta property="og:type" content="article"><meta property="og:title" content="深度学习-图神经网络必读的5个基础模型: GCN, GAT, GraphSAGE, GAE, DiffPool"><meta property="og:url" content="https://aisakaaoi.github.io/a67192b0.html"><meta property="og:site_name" content="逢坂葵的个人博客"><meta property="og:description" content="本文约6000字，建议阅读10分钟本篇文章将从一个更直观的角度对当前经典流行的GNN网络，包括GCN、GraphSAGE、GAT、GAE以及graph pooling策略DiffPool等等做一个简单的小结。  “近年来，深度学习领域关于图神经网络（Graph Neural Networks，GNN）的研究热情日益高涨，图神经网络已经成为各大深度学习顶会的研究热点。GNN处理非结构化数据时的出色"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/1.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/2.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/3.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/4.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/5.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/6.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/7.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/8.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/9.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/10.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/11.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/12.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/13.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/14.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/15.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/16.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/17.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/18.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/19.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/20.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/21.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/22.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/23.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/24.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/25.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/26.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/27.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/28.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/29.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/30.webp"><meta property="og:image" content="https://aisakaaoi.github.io/a67192b0/31.webp"><meta property="article:published_time" content="2023-05-05T20:19:02.000Z"><meta property="article:modified_time" content="2026-01-23T11:02:51.727Z"><meta property="article:author" content="Aisaka Aoi"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://aisakaaoi.github.io/a67192b0/1.webp"><link rel="canonical" href="https://aisakaaoi.github.io/a67192b0.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>深度学习-图神经网络必读的5个基础模型: GCN, GAT, GraphSAGE, GAE, DiffPool | 逢坂葵的个人博客</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?7308ed05421777c301eefa3754da1b42",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="逢坂葵的个人博客" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">aoi学院</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">Aisaka's Blog, School of Aoi, Aisaka University</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">20</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">1017</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div><a href="https://github.com/AisakaAoi" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://aisakaaoi.github.io/a67192b0.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/manatsu.jpg"><meta itemprop="name" content="Aisaka Aoi"><meta itemprop="description" content="Aisaka's Blog, School of Aoi, Aisaka University"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="逢坂葵的个人博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">深度学习-图神经网络必读的5个基础模型: GCN, GAT, GraphSAGE, GAE, DiffPool</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-05-06 04:19:02" itemprop="dateCreated datePublished" datetime="2023-05-06T04:19:02+08:00">2023-05-06</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">🌙进阶学习</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%F0%9F%8C%99%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/%E2%AD%90%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">⭐人工智能 Artificial Intelligence</span></a> </span></span><span id="/a67192b0.html" class="post-meta-item leancloud_visitors" data-flag-title="深度学习-图神经网络必读的5个基础模型: GCN, GAT, GraphSAGE, GAE, DiffPool" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/a67192b0.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/a67192b0.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>8.3k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>21 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><blockquote><p>本文约6000字，建议阅读10分钟<br>本篇文章将从一个更直观的角度对当前经典流行的GNN网络，包括GCN、GraphSAGE、GAT、GAE以及graph pooling策略DiffPool等等做一个简单的小结。</p></blockquote><p>“近年来，深度学习领域关于图神经网络（Graph Neural Networks，GNN）的研究热情日益高涨，图神经网络已经成为各大深度学习顶会的研究热点。GNN处理非结构化数据时的出色能力使其在网络数据分析、推荐系统、物理建模、自然语言处理和图上的组合优化问题方面都取得了新的突破。”</p><p>图神经网络有很多比较好的综述[1][2][3]可以参考，更多的论文可以参考清华大学整理的GNN paper list[4] 。本篇文章将从一个更直观的角度对当前经典流行的GNN网络，包括GCN、GraphSAGE、GAT、GAE以及graph pooling策略DiffPool等等做一个简单的小结。</p><span id="more"></span><hr><h3 id="为什么需要图神经网络？"><a href="#为什么需要图神经网络？" class="headerlink" title="为什么需要图神经网络？"></a>为什么需要图神经网络？</h3><p>随着机器学习、深度学习的发展，语音、图像、自然语言处理逐渐取得了很大的突破，然而语音、图像、文本都是很简单的序列或者网格数据，是很结构化的数据，深度学习很善于处理该种类型的数据。</p><img src="/a67192b0/1.webp"><p>然而现实世界中并不是所有的事物都可以表示成一个序列或者一个网格，例如社交网络、知识图谱、复杂的文件系统等，也就是说很多事物都是非结构化的。</p><img src="/a67192b0/2.webp"><p>相比于简单的文本和图像，这种网络类型的非结构化的数据非常复杂，处理它的难点包括：</p><ul><li>图的大小是任意的，图的拓扑结构复杂，没有像图像一样的空间局部性；</li><li>图没有固定的节点顺序，或者说没有一个参考节点；</li><li>图经常是动态图，而且包含多模态的特征。</li></ul><p>那么对于这类数据我们该如何建模呢？能否将深度学习进行扩展使得能够建模该类数据呢？这些问题促使了图神经网络的出现与发展。</p><hr><h3 id="图神经网络是什么样子的？"><a href="#图神经网络是什么样子的？" class="headerlink" title="图神经网络是什么样子的？"></a>图神经网络是什么样子的？</h3><p>相比较于神经网络最基本的网络结构全连接层（MLP），特征矩阵乘以权重矩阵，图神经网络多了一个邻接矩阵。计算形式很简单，三个矩阵相乘再加上一个非线性变换。</p><img src="/a67192b0/3.webp"><p>因此一个比较常见的图神经网络的应用模式如下图，输入是一个图，经过多层图卷积等各种操作以及激活函数，最终得到各个节点的表示，以便于进行节点分类、链接预测、图与子图的生成等等任务。</p><img src="/a67192b0/4.webp"><p>上面是一个对图神经网络比较简单直观的感受与理解，实际其背后的原理逻辑还是比较复杂的，这个后面再慢慢细说，接下来将以几个经典的GNN models为线来介绍图神经网络的发展历程。</p><hr><h3 id="图神经网络的几个经典模型与发展"><a href="#图神经网络的几个经典模型与发展" class="headerlink" title="图神经网络的几个经典模型与发展"></a>图神经网络的几个经典模型与发展</h3><h4 id="Graph-Convolution-Networks-GCN-5"><a href="#Graph-Convolution-Networks-GCN-5" class="headerlink" title="Graph Convolution Networks(GCN)[5]"></a>Graph Convolution Networks(GCN)[5]</h4><p>GCN可谓是图神经网络的“开山之作”，它首次将图像处理中的卷积操作简单的用到图结构数据处理中来，并且给出了具体的推导，这里面涉及到复杂的谱图理论，具体推到可以参考[6][7]。推导过程还是比较复杂的，然而最后的结果却非常简单。</p><img src="/a67192b0/5.webp"><p>我们来看一下这个式子，天呐，这不就是聚合邻居节点的特征然后做一个线性变换吗？没错，确实是这样，同时为了使得GCN能够捕捉到K-hop的邻居节点的信息，作者还堆叠多层GCN layers，如堆叠K层有：</p><img src="/a67192b0/6.webp"><p>上述式子还可以使用矩阵形式表示如下</p><img src="/a67192b0/7.webp"><p>其中 是归一化之后的邻接矩阵， 相当于给 层的所有节点的embedding做了一次线性变换，左乘以邻接矩阵表示对每个节点来说，该节点的特征表示为邻居节点特征相加之后的结果。（注意将 换成矩阵 就是图3所说的三矩阵相乘）</p><p>那么GCN的效果如何呢？作者将GCN放到节点分类任务上，分别在Citeseer、Cora、Pubmed、NELL等数据集上进行实验，相比于传统方法提升还是很显著的，这很有可能是得益于GCN善于编码图的结构信息，能够学习到更好的节点表示。</p><img src="/a67192b0/8.webp"><p>当然，其实GCN的缺点也是很显然易见的，第一，GCN需要将整个图放到内存和显存，这将非常耗内存和显存，处理不了大图；第二，GCN在训练时需要知道整个图的结构信息(包括待预测的节点), 这在现实某些任务中也不能实现(比如用今天训练的图模型预测明天的数据，那么明天的节点是拿不到的)。</p><hr><h4 id="Graph-Sample-and-Aggregate-GraphSAGE-8"><a href="#Graph-Sample-and-Aggregate-GraphSAGE-8" class="headerlink" title="Graph Sample and Aggregate(GraphSAGE)[8]"></a>Graph Sample and Aggregate(GraphSAGE)[8]</h4><p>为了解决GCN的两个缺点问题，GraphSAGE被提了出来。在介绍GraphSAGE之前，先介绍一下Inductive learning和Transductive learning。注意到图数据和其他类型数据的不同，图数据中的每一个节点可以通过边的关系利用其他节点的信息。这就导致一个问题，GCN输入了整个图，训练节点收集邻居节点信息的时候，用到了测试和验证集的样本，我们把这个称为Transductive learning。然而，我们所处理的大多数的机器学习问题都是Inductive learning，因为我们刻意的将样本集分为训练&#x2F;验证&#x2F;测试，并且训练的时候只用训练样本。这样对图来说有个好处，可以处理图中新来的节点，可以利用已知节点的信息为未知节点生成embedding，GraphSAGE就是这么干的。</p><p>GraphSAGE是一个Inductive Learning框架，具体实现中，训练时它仅仅保留训练样本到训练样本的边，然后包含Sample和Aggregate两大步骤，Sample是指如何对邻居的个数进行采样，Aggregate是指拿到邻居节点的embedding之后如何汇聚这些embedding以更新自己的embedding信息。下图展示了GraphSAGE学习的一个过程：</p><img src="/a67192b0/9.webp"><p>第一步，对邻居采样；</p><p>第二步，采样后的邻居embedding传到节点上来，并使用一个聚合函数聚合这些邻居信息以更新节点的embedding；</p><p>第三步，根据更新后的embedding预测节点的标签。</p><p>接下来，我们详细的说明一个训练好的GrpahSAGE是如何给一个新的节点生成embedding的（即一个前向传播的过程），如下算法图：</p><img src="/a67192b0/10.webp"><p>首先，(line1)算法首先初始化输入的图中所有节点的特征向量，(line3)对于每个节点 ，拿到它采样后的邻居节点 后，(line4)利用聚合函数聚合邻居节点的信息，(line5)并结合自身embedding通过一个非线性变换更新自身的embedding表示。</p><p>注意到算法里面的 ，它是指聚合器的数量，也是指权重矩阵的数量，还是网络的层数，这是因为每一层网络中聚合器和权重矩阵是共享的。网络的层数可以理解为需要最大访问的邻居的跳数(hops)，比如在图7中，红色节点的更新拿到了它一、二跳邻居的信息，那么网络层数就是2。为了更新红色节点，首先在第一层(k&#x3D;1)，我们会将蓝色节点的信息聚合到红色解节点上，将绿色节点的信息聚合到蓝色节点上。在第二层(k&#x3D;2)红色节点的embedding被再次更新，不过这次用到的是更新后的蓝色节点embedding，这样就保证了红色节点更新后的embedding包括蓝色和绿色节点的信息，也就是两跳信息。</p><p>为了看的更清晰，我们将更新某个节点的过程展开来看，如图8分别为更新节点A和更新节点B的过程，可以看到更新不同的节点过程每一层网络中聚合器和权重矩阵都是共享的。</p><img src="/a67192b0/11.webp"><p>那么GraphSAGE Sample是怎么做的呢？GraphSAGE是采用定长抽样的方法，具体来说，定义需要的邻居个数 ，然后采用有放回的重采样&#x2F;负采样方法达到 。保证每个节点（采样后的）邻居个数一致，这样是为了把多个节点以及它们的邻居拼接成Tensor送到GPU中进行批训练。</p><p>那么GraphSAGE 有哪些聚合器呢？主要有三个：</p><img src="/a67192b0/12.webp"><p>这里说明的一点是Mean Aggregator和GCN的做法基本是一致的（GCN实际上是求和）。</p><p>到此为止，整个模型的架构就讲完了，那么GraphSAGE是如何学习聚合器的参数以及权重矩阵 呢？如果是有监督的情况下，可以使用每个节点的预测lable和真实lable的交叉熵作为损失函数。如果是在无监督的情况下，可以假设相邻的节点的embedding表示尽可能相近，因此可以设计出如下的损失函数：</p><img src="/a67192b0/13.webp"><p>那么GrpahSAGE的实际实验效果如何呢？作者在Citation、Reddit、PPI数据集上分别给出了无监督和完全有监督的结果，相比于传统方法提升还是很明显。</p><img src="/a67192b0/14.webp"><p>至此，GraphSAGE介绍完毕。我们来总结一下，GraphSAGE的一些优点：</p><ol><li>利用采样机制，很好的解决了GCN必须要知道全部图的信息问题，克服了GCN训练时内存和显存的限制，即使对于未知的新节点，也能得到其表示；</li><li>聚合器和权重矩阵的参数对于所有的节点是共享的；</li><li>模型的参数的数量与图的节点个数无关，这使得GraphSAGE能够处理更大的图</li><li>既能处理有监督任务也能处理无监督任务。<br>（就喜欢这样解决了问题，方法又简洁，效果还好的idea！！！）</li></ol><p>当然，GraphSAGE也有一些缺点，每个节点那么多邻居，GraphSAGE的采样没有考虑到不同邻居节点的重要性不同，而且聚合计算的时候邻居节点的重要性和当前节点也是不同的。</p><hr><h4 id="Graph-Attention-Networks-GAT-9"><a href="#Graph-Attention-Networks-GAT-9" class="headerlink" title="Graph Attention Networks(GAT)[9]"></a>Graph Attention Networks(GAT)[9]</h4><p>为了解决GNN聚合邻居节点的时候没有考虑到不同的邻居节点重要性不同的问题，GAT借鉴了Transformer的idea，引入masked self-attention机制，在计算图中的每个节点的表示的时候，会根据邻居节点特征的不同来为其分配不同的权值。</p><p>具体的，对于输入的图，一个graph attention layer如图所示：</p><img src="/a67192b0/15.webp"><p>其中采用了单层的前馈神经网络实现，计算过程如下（注意权重矩阵 对于所有的节点是共享的）：</p><img src="/a67192b0/16.webp"><p>计算完attention之后，就可以得到某个节点聚合其邻居节点信息的新的表示，计算过程如下：</p><img src="/a67192b0/17.webp"><p>为了提高模型的拟合能力，还引入了多头的self-attention机制，即同时使用多个 计算self-attention，然后将计算的结果合并（连接或者求和）：</p><img src="/a67192b0/18.webp"><p>此外，由于GAT结构的特性，GAT无需使用预先构建好的图，因此GAT既适用于Transductive Learning，又适用于Inductive Learning。</p><p>那么GAT的具体效果如何呢？作者分别在三个Transductive Learning和一个Inductive Learning任务上进行实验，实验结果如下：</p><img src="/a67192b0/19.webp"><p>无论是在Transductive Learning还是在Inductive Learning的任务上，GAT的效果都要优于传统方法的结果。</p><p>至此，GAT的介绍完毕，我们来总结一下，GAT的一些优点：</p><ol><li>训练GCN无需了解整个图结构，只需知道每个节点的邻居节点即可；</li><li>计算速度快，可以在不同的节点上进行并行计算；</li><li>既可以用于Transductive Learning，又可以用于Inductive Learning，可以对未见过的图结构进行处理。<br>（仍然是简单的idea，解决了问题，效果还好！！！）</li></ol><p>到此，我们就介绍完了GNN中最经典的几个模型GCN、GraphSAGE、GAT，接下来我们将针对具体的任务类别来介绍一些流行的GNN模型与方法。</p><hr><h3 id="无监督的节点表示学习（Unsupervised-Node-Representation）"><a href="#无监督的节点表示学习（Unsupervised-Node-Representation）" class="headerlink" title="无监督的节点表示学习（Unsupervised Node Representation）"></a>无监督的节点表示学习（Unsupervised Node Representation）</h3><p>由于标注数据的成本非常高，如果能够利用无监督的方法很好的学习到节点的表示，将会有巨大的价值和意义，例如找到相同兴趣的社区、发现大规模的图中有趣的结构等等。</p><img src="/a67192b0/20.webp"><p>这其中比较经典的模型有GraphSAGE、Graph Auto-Encoder（GAE）等，GraphSAGE就是一种很好的无监督表示学习的方法，前面已经介绍了，这里就不赘述，接下来将详细讲解后面两个。</p><h4 id="Graph-Auto-Encoder-GAE-10"><a href="#Graph-Auto-Encoder-GAE-10" class="headerlink" title="Graph Auto-Encoder(GAE)[10]"></a>Graph Auto-Encoder(GAE)[10]</h4><p>在介绍Graph Auto-Encoder之前，需要先了解自编码器(Auto-Encoder)、变分自编码器(Variational Auto-Encoder)，具体可以参考[11]，这里就不赘述。</p><p>理解了自编码器之后，再来理解变分图的自编码器就容易多了。如图输入图的邻接矩阵和节点的特征矩阵，通过编码器（图卷积网络）学习节点低维向量表示的均值μ和方差σ，然后用解码器（链路预测）生成图。</p><img src="/a67192b0/21.webp"><p>编码器（Encoder）采用简单的两层GCN网络，解码器（Encoder）计算两点之间存在边的概率来重构图，损失函数包括生成图和原始图之间的距离度量，以及节点表示向量分布和正态分布的KL-散度两部分。具体公式如图所示：</p><img src="/a67192b0/22.webp"><p>另外为了做比较，作者还提出了图自编码器(Graph Auto-Encoder)，相比于变分图的自编码器，图自编码器就简单多了，Encoder是两层GCN，Loss只包含Reconstruction Loss。</p><p>那么两种图自编码器的效果如何呢？作者分别在Cora、Citeseer、Pubmed数据集上做Link prediction任务，实验结果如下表，图自编码器（GAE）和变分图自编码器（VGAE）效果普遍优于传统方法，而且变分图自编码器的效果更好；当然，Pumed上GAE得到了最佳结果。可能是因为Pumed网络较大，在VGAE比GAE模型复杂，所以更难调参。</p><img src="/a67192b0/23.webp"><hr><h3 id="Graph-Pooling"><a href="#Graph-Pooling" class="headerlink" title="Graph Pooling"></a>Graph Pooling</h3><p>Graph pooling是GNN中很流行的一种操作，目的是为了获取一整个图的表示，主要用于处理图级别的分类任务，例如在有监督的图分类、文档分类等等。</p><img src="/a67192b0/24.webp"><p>Graph pooling的方法有很多，如简单的max pooling和mean pooling，然而这两种pooling不高效而且忽视了节点的顺序信息；这里介绍一种方法：Differentiable Pooling (DiffPool)。</p><h4 id="DiffPool-12"><a href="#DiffPool-12" class="headerlink" title="DiffPool[12]"></a>DiffPool[12]</h4><p>在图级别的任务当中，当前的很多方法是将所有的节点嵌入进行全局池化，忽略了图中可能存在的任何层级结构，这对于图的分类任务来说尤其成问题，因为其目标是预测整个图的标签。针对这个问题，斯坦福大学团队提出了一个用于图分类的可微池化操作模块——DiffPool，可以生成图的层级表示，并且可以以端到端的方式被各种图神经网络整合。</p><p>DiffPool的核心思想是通过一个可微池化操作模块去分层的聚合图节点，具体的，这个可微池化操作模块基于GNN上一层生成的节点嵌入 以及分配矩阵 ，以端到端的方式分配给下一层的簇，然后将这些簇输入到GNN下一层，进而实现用分层的方式堆叠多个GNN层的想法。</p><img src="/a67192b0/25.webp"><p>那么这个节点嵌入和分配矩阵是怎么算的？计算完之后又是怎么分配给下一层的？这里就涉及到两部分内容，一个是分配矩阵的学习，一个是池化分配矩阵。</p><ul><li>分配矩阵的学习</li></ul><p>这里使用两个分开的GNN来生成分配矩阵 和每一个簇节点新的嵌入 ，这两个GNN都是用簇节点特征矩阵 和粗化邻接矩阵 作为输入</p><img src="/a67192b0/26.webp"><ul><li>池化分配矩阵</li></ul><p>计算得到分配矩阵 和每一个簇节点新的嵌入 之后，DiffPool层根据分配矩阵，对于图中的每个节点&#x2F;簇生成一个新的粗化的邻接矩阵 与新的嵌入矩阵</p><img src="/a67192b0/27.webp"><p>总的来看，每层的DiffPool其实就是更新每一个簇节点的嵌入和簇节点的特征矩阵，如下公式：</p><img src="/a67192b0/28.webp"><p>至此，DiffPool的基本思想就讲完了。那么效果如何呢？作者在多种图分类的基准数据集上进行实验，如蛋白质数据集（ENZYMES，PROTEINS，D&amp;D），社交网络数据集（REDDIT-MULTI-12K），科研合作数据集（COLLAB），实验结果如下：</p><img src="/a67192b0/29.webp"><p>其中，GraphSAGE是采用全局平均池化；DiffPool-DET是一种DiffPool变体，使用确定性图聚类算法生成分配矩阵；DiffPool-NOLP是DiffPool的变体，取消了链接预测目标部分。总的来说，DiffPool方法在GNN的所有池化方法中获得最高的平均性能。</p><p>为了更好的证明DiffPool对于图分类十分有效，论文还使用了其他GNN体系结构（Structure2Vec(s2v)），并且构造两个变体，进行对比实验，如下表：</p><img src="/a67192b0/30.webp"><p>可以看到DiffPool的显著改善了S2V在ENZYMES和D&amp;D数据集上的性能。</p><img src="/a67192b0/31.webp"><p>而且DiffPool可以自动的学习到恰当的簇的数量。</p><p>至此，我们来总结一下DiffPool的优点：</p><ol><li>可以学习层次化的pooling策略</li><li>可以学习到图的层次化表示</li><li>可以以端到端的方式被各种图神经网络整合</li></ol><p>然而，注意到，DiffPool也有其局限性，分配矩阵需要很大的空间去存储，所以无法处理很大的图。</p><hr><h3 id="重点总结"><a href="#重点总结" class="headerlink" title="重点总结"></a>重点总结</h3><ol><li><p>GCN的缺点也是很显然易见的，第一，GCN需要将整个图放到内存和显存，这将非常耗内存和显存，处理不了大图；第二，GCN在训练时需要知道整个图的结构信息(包括待预测的节点)。</p></li><li><p>GraphSAGE的优点：</p><ol><li>利用采样机制，很好的解决了GCN必须要知道全部图的信息问题，克服了GCN训练时内存和显存的限制，即使对于未知的新节点，也能得到其表示；</li><li>聚合器和权重矩阵的参数对于所有的节点是共享的；</li><li>模型的参数的数量与图的节点个数无关，这使得GraphSAGE能够处理更大的图</li><li>既能处理有监督任务也能处理无监督任务。</li></ol></li><li><p>GAT的优点：</p><ol><li>训练GCN无需了解整个图结构，只需知道每个节点的邻居节点即可；</li><li>计算速度快，可以在不同的节点上进行并行计算；</li><li>既可以用于Transductive Learning，又可以用于Inductive Learning，可以对未见过的图结构进行处理。</li></ol></li></ol><hr><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzI1MjQ2OTQ3Ng==&amp;mid=2247601989&amp;idx=1&amp;sn=83284c3324a0583a0bbb719764311d5c">https://mp.weixin.qq.com/s?__biz=MzI1MjQ2OTQ3Ng==&amp;mid=2247601989&amp;idx=1&amp;sn=83284c3324a0583a0bbb719764311d5c</a><br>[1] Graph Neural Networks: A Review of Methods and Applications. arxiv 2018 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1812.08434.pdf">https://arxiv.org/pdf/1812.08434.pdf</a><br>[2] A Comprehensive Survey on Graph Neural Networks. arxiv 2019. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1901.00596.pdf">https://arxiv.org/pdf/1901.00596.pdf</a><br>[3] Deep Learning on Graphs: A Survey. arxiv 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1812.04202.pdf">https://arxiv.org/pdf/1812.04202.pdf</a><br>[4] GNN papers <a target="_blank" rel="noopener" href="https://github.com/thunlp/GNNPapers/blob/master/README.md">https://github.com/thunlp/GNNPapers/blob/master/README.md</a><br>[5] Semi-Supervised Classification with Graph Convolutional Networks(ICLR2017) <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1609.02907">https://arxiv.org/pdf/1609.02907</a><br>[6] 如何理解 Graph Convolutional Network（GCN）？<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/54504471">https://www.zhihu.com/question/54504471</a><br>[7] GNN 系列：图神经网络的“开山之作”CGN模型 <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/jBQOgP-I4FQT1EU8y72ICA">https://mp.weixin.qq.com/s/jBQOgP-I4FQT1EU8y72ICA</a><br>[8] Inductive Representation Learning on Large Graphs(2017NIPS) <a target="_blank" rel="noopener" href="https://cs.stanford.edu/people/jure/pubs/graphsage-nips17.pdf">https://cs.stanford.edu/people/jure/pubs/graphsage-nips17.pdf</a><br>[9] Graph Attention Networks(ICLR2018) <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1710.10903">https://arxiv.org/pdf/1710.10903</a><br>[10] Variational Graph Auto-Encoders（NIPS2016） <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.07308">https://arxiv.org/pdf/1611.07308</a><br>[11] VGAE（Variational graph auto-encoders）论文详解 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/78340397">https://zhuanlan.zhihu.com/p/78340397</a><br>[12] Hierarchical Graph Representation Learning withDifferentiable Pooling(NIPS2018) <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1806.08">https://arxiv.org/pdf/1806.08</a></p></blockquote></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-item"><a href="/f1872f1b.html" rel="prev" title="一种应用于睡眠监测的非侵入式脑机接口设备"><i class="fa fa-chevron-left"></i> 一种应用于睡眠监测的非侵入式脑机接口设备</a></div><div class="post-nav-item"><a href="/8bb0dc3c.html" rel="next" title="为什么鼓励你读计算机专业博士">为什么鼓励你读计算机专业博士 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let t=CONFIG.comments["activeClass"];var e;(t=CONFIG.comments.storage?localStorage.getItem("comments_active")||t:t)&&(e=document.querySelector(`a[href="#comment-${t}"]`))&&e.click()}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9F"><span class="nav-number">1.</span> <span class="nav-text">为什么需要图神经网络？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%98%AF%E4%BB%80%E4%B9%88%E6%A0%B7%E5%AD%90%E7%9A%84%EF%BC%9F"><span class="nav-number">2.</span> <span class="nav-text">图神经网络是什么样子的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%87%A0%E4%B8%AA%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%8F%91%E5%B1%95"><span class="nav-number">3.</span> <span class="nav-text">图神经网络的几个经典模型与发展</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Graph-Convolution-Networks-GCN-5"><span class="nav-number">3.1.</span> <span class="nav-text">Graph Convolution Networks(GCN)[5]</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Graph-Sample-and-Aggregate-GraphSAGE-8"><span class="nav-number">3.2.</span> <span class="nav-text">Graph Sample and Aggregate(GraphSAGE)[8]</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Graph-Attention-Networks-GAT-9"><span class="nav-number">3.3.</span> <span class="nav-text">Graph Attention Networks(GAT)[9]</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E7%9A%84%E8%8A%82%E7%82%B9%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0%EF%BC%88Unsupervised-Node-Representation%EF%BC%89"><span class="nav-number">4.</span> <span class="nav-text">无监督的节点表示学习（Unsupervised Node Representation）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Graph-Auto-Encoder-GAE-10"><span class="nav-number">4.1.</span> <span class="nav-text">Graph Auto-Encoder(GAE)[10]</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Graph-Pooling"><span class="nav-number">5.</span> <span class="nav-text">Graph Pooling</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DiffPool-12"><span class="nav-number">5.1.</span> <span class="nav-text">DiffPool[12]</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%87%8D%E7%82%B9%E6%80%BB%E7%BB%93"><span class="nav-number">6.</span> <span class="nav-text">重点总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">7.</span> <span class="nav-text">参考资料</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Aisaka Aoi" src="/images/manatsu.jpg"><p class="site-author-name" itemprop="name">Aisaka Aoi</p><div class="site-description" itemprop="description">逢坂葵的个人博客</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">1017</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">20</span> <span class="site-state-item-name">分类</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/AisakaAoi" title="GitHub 👨‍💻 → https:&#x2F;&#x2F;github.com&#x2F;AisakaAoi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👨‍💻</a> </span><span class="links-of-author-item"><a href="https://github.com/Aisakaorz" title="GitHub 👩‍💻 → https:&#x2F;&#x2F;github.com&#x2F;Aisakaorz" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub 👩‍💻</a> </span><span class="links-of-author-item"><a href="mailto:aisakaaoi@qq.com" title="E-Mail 📧 → mailto:aisakaaoi@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 📧</a> </span><span class="links-of-author-item"><a href="mailto:chenzongnan@m.scnu.edu.cn" title="E-Mail 🏫 → mailto:chenzongnan@m.scnu.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail 🏫</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/91560309" title="Bilibili 📺 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;91560309" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 📺</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/198562921" title="Bilibili 🎮 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;198562921" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>Bilibili 🎮</a> </span><span class="links-of-author-item"><a href="https://www.youtube.com/channel/UCALvyn5Cl76GCotO9pczvjg" title="YouTube 📺 → https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCALvyn5Cl76GCotO9pczvjg" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube 📺</a></span></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2026</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Aisaka Aoi</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">3.8m</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">160:09</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll(".pdfobject-container").forEach(e=>{var t=e.dataset.target,a="#"+Object.entries({navpanes:0,toolbar:0,statusbar:0,pagemode:"thumbs",view:"FitH"}).map(([e,t])=>e+"="+encodeURIComponent(t)).join("&"),r="/lib/pdf/web/viewer.html?file="+encodeURIComponent(t)+a;NexT.utils.supportsPDFs()?e.innerHTML=`<embed class="pdfobject" src="${t+a}" type="application/pdf" style="height: ${e.dataset.height};">`:e.innerHTML=`<iframe src="${r}" style="height: ${e.dataset.height};" frameborder="0"></iframe>`})</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//unpkg.com/valine/dist/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!0,notify:!0,appId:"UqjWdRYbIUEUQRXhBUUIh1QE-gzGzoHsz",appKey:"gj89JXC485PFbpdHLKVkz6dm",placeholder:"这里可以发送评论~（上面可以输入昵称、邮箱）",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{jsonPath:"/live2dw/assets/assets/haru02.model.json"},display:{position:"right",width:208,height:520},mobile:{show:!1},log:!1})</script></body></html>